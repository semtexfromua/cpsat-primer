*A book-style version of this primer is available at [https://d-krupke.github.io/cpsat-primer/](https://d-krupke.github.io/cpsat-primer/).*

<!-- This file was generated by the `build.py` script. Do not edit it manually. -->
<!-- ./chapters/00_intro.md -->
<!-- EDIT THIS PART VIA 00_intro.md -->

# Праймер CP-SAT: використання та розуміння розв’язувача CP-SAT з Google OR-Tools


_Автор: [Dominik Krupke](https://krupke.cc), TU Braunschweig, за участі Leon Lan, Michael Perk та
[інших](https://github.com/d-krupke/cpsat-primer/graphs/contributors)._ 

<!-- Introduction Paragraph --->

Багато [комбінаторно складних](https://en.wikipedia.org/wiki/NP-hardness)
задач оптимізації, попри доведену теоретичну складність, на практиці можна
розв’язувати достатньо добре. Найуспішніший підхід — застосувати
[змішане цілочисельне лінійне програмування](https://en.wikipedia.org/wiki/Integer_programming)
(MIP) для моделювання задачі, а потім скористатися розв’язувачем для пошуку
розв’язку. Найуспішніші MIP-розв’язувачі, наприклад
[Gurobi](https://www.gurobi.com/),
[CPLEX](https://www.ibm.com/analytics/cplex-optimizer),
[COPT Cardinal Solver](https://www.copt.de/) та
[FICO Xpress Optimization](https://www.fico.com/en/products/fico-xpress-optimization),
є комерційними і дорогими (хоча здебільшого безплатними для академічної спільноти).
Існують також деякі розв’язувачі з відкритим кодом (наприклад, [SCIP](https://www.scipopt.org/)
і [HiGHS](https://highs.dev/)), але вони часто ще не такі потужні, як комерційні.
Втім, навіть інвестуючи у такий розв’язувач, базові техніки
([гілок і меж](https://en.wikipedia.org/wiki/Branch_and_bound) та
[відтинань](https://en.wikipedia.org/wiki/Branch_and_cut) на
[лінійних релаксаціях](https://en.wikipedia.org/wiki/Linear_programming_relaxation))
не завжди справляються з певними задачами оптимізації, особливо якщо задача містить
багато логічних обмежень, яким має відповідати розв’язок. У такому випадку
підхід [програмування з обмеженнями](https://en.wikipedia.org/wiki/Constraint_programming)
(CP) може бути успішнішим. Для CP існує чимало розв’язувачів з відкритим кодом,
але вони зазвичай не масштабуються так добре, як MIP-розв’язувачі, і гірше
оптимізують цільові функції. Хоча MIP-розв’язувачі часто здатні оптимізувати задачі
з сотнями тисяч змінних і обмежень, класичні CP-розв’язувачі часто мають труднощі
з задачами, де змінних і обмежень більше кількох тисяч. Однак відносно новий
[CP-SAT](https://developers.google.com/optimization/cp/cp_solver) у складі
[OR-Tools](https://github.com/google/or-tools/) від Google демонструє, що може
подолати багато з цих слабких місць і є життєздатною альтернативою MIP-розв’язувачам,
конкуруючи з ними для багатьох задач і інколи навіть перевершуючи їх.

Як швидку демонстрацію можливостей CP-SAT — особливо для тих, хто менш
знайомий з оптимізаційними фреймворками — розв’яжімо екземпляр NP-складної
задачі про рюкзак (Knapsack). Ця класична оптимізаційна задача вимагає вибрати
підмножину предметів, кожен із певною вагою та цінністю, щоб максимізувати
загальну цінність, не перевищивши обмеження на вагу. Хоча рекурсивний алгоритм
легко реалізувати, 100 предметів дають приблизно $2^{100} \approx 10^{30}$
можливих розв’язків. Навіть надпотужний комп’ютер, що виконує $10^{18}$ операцій
за секунду, потребував би понад 31 000 років, щоб перевірити всі можливості.

Ось як це можна розв’язати за допомогою CP-SAT:

```python
from ortools.sat.python import cp_model  # pip install -U ortools

# Задаємо вхідні дані
weights = [395, 658, 113, 185, 336, 494, 294, 295, 256, 530, 311, 321, 602, 855, 209, 647, 520, 387, 743, 26, 54, 420, 667, 971, 171, 354, 962, 454, 589, 131, 342, 449, 648, 14, 201, 150, 602, 831, 941, 747, 444, 982, 732, 350, 683, 279, 667, 400, 441, 786, 309, 887, 189, 119, 209, 532, 461, 420, 14, 788, 691, 510, 961, 528, 538, 476, 49, 404, 761, 435, 729, 245, 204, 401, 347, 674, 75, 40, 882, 520, 692, 104, 512, 97, 713, 779, 224, 357, 193, 431, 442, 816, 920, 28, 143, 388, 23, 374, 905, 942]
values = [71, 15, 100, 37, 77, 28, 71, 30, 40, 22, 28, 39, 43, 61, 57, 100, 28, 47, 32, 66, 79, 70, 86, 86, 22, 57, 29, 38, 83, 73, 91, 54, 61, 63, 45, 30, 51, 5, 83, 18, 72, 89, 27, 66, 43, 64, 22, 23, 22, 72, 10, 29, 59, 45, 65, 38, 22, 68, 23, 13, 45, 34, 63, 34, 38, 30, 82, 33, 64, 100, 26, 50, 66, 40, 85, 71, 54, 25, 100, 74, 96, 62, 58, 21, 35, 36, 91, 7, 19, 32, 77, 70, 23, 43, 78, 98, 30, 12, 76, 38]
capacity = 2000

# Тепер розв’язуємо задачу
model = cp_model.CpModel()
xs = [model.new_bool_var(f"x_{i}") for i in range(len(weights))]

accumulated_weight = sum(x * w for x, w in zip(xs, weights))
model.add(accumulated_weight <= capacity)
accumulated_value = sum(x * v for x, v in zip(xs, values))
model.maximize(accumulated_value)

solver = cp_model.CpSolver()
solver.solve(model)

print("Оптимальний вибір:", [i for i, x in enumerate(xs) if solver.value(x)])
print("Загальна цінність:", solver.objective_value)
```

```
Optimal selection: [2, 14, 19, 20, 29, 33, 52, 53, 54, 58, 66, 72, 76, 77, 81, 86, 93, 94, 96]
Total packed value: 1161.0
```

Скільки часу це зайняло? На моїй машині CP-SAT знайшов доведено найкращий
розв’язок серед $2^{100}$ можливостей лише за 0,01 секунди. Спробуйте й на
своїй. CP-SAT не перебирає всі розв’язки — він використовує просунуті техніки,
щоб робити висновки й обрізати простір пошуку. Хоча існують ефективніші підходи,
ніж наївний рекурсивний алгоритм, досягти продуктивності CP-SAT без значних
зусиль було б складно. І це лише початок — як побачимо в цьому праймері, CP-SAT
може розв’язувати значно складніші задачі.

> [!TIP]
>
> Ще не переконані, чому інструменти на кшталт CP-SAT — це круто? Можливо,
> Марко Люббеке переконає вас у 12-хвилинній доповіді TEDx
> [Anything you can do I can do better](https://www.youtube.com/watch?v=Dc38La-Xvog)
> про математичну оптимізацію.

### Зміст

Незалежно від того, чи ви прийшли зі спільноти MIP у пошуках альтернатив, чи
CP-SAT є вашим першим оптимізаційним розв’язувачем, ця книга проведе вас через
основи CP-SAT у першій частині, демонструючи всі його можливості. Друга частина
дасть вам навички, потрібні для побудови й розгортання оптимізаційних алгоритмів
з використанням CP-SAT.

Перша частина вводить у фундаментальні принципи CP-SAT, починаючи з розділу
про встановлення. У цьому розділі пояснюється, як налаштувати CP-SAT і які
апаратні вимоги потрібні. Далі наведено простий приклад використання CP-SAT,
із поясненням математичної нотації та її наближення в Python за допомогою
перевантажених операторів. Потім ви перейдете до базового моделювання — як
створювати змінні, цілі та фундаментальні обмеження в CP-SAT.

Далі розділ про просунуте моделювання навчить працювати зі складними обмеженнями,
наприклад обмеженнями на контури (circuit) і інтервали, із практичними прикладами.
Інший розділ пояснює, як задавати поведінку CP-SAT, зокрема встановлювати ліміти
часу та використовувати паралелізацію. Також є розділ про інтерпретацію логів
CP-SAT, який допомагає зрозуміти, наскільки добре CP-SAT керується з вашою задачею.
Крім того, подано огляд базових технік, використаних у CP-SAT. Перша частина
завершується розділом, що порівнює CP-SAT з іншими техніками та інструментами
оптимізації, розміщуючи його в ширшому контексті.

Друга частина заглиблюється в просунуті теми, зосереджуючись на загальних
навичках, таких як патерни кодування та бенчмаркінг, а не на конкретних функціях
CP-SAT. Розділ про патерни кодування пропонує базові шаблони проєктування для
створення підтримуваних алгоритмів із CP-SAT. Інший розділ пояснює, як надати
ваш оптимізаційний алгоритм як сервіс, побудувавши оптимізаційне API. Також є
розділ про розробку потужних евристик із використанням CP-SAT для особливо
складних або великих задач. Друга частина завершується розділом про бенчмаркінг
— як науково порівнювати моделі та інтерпретувати результати.

### Цільова аудиторія

Я написав цю книгу для студентів комп’ютерних наук TU Braunschweig, і вона
використовується як додатковий матеріал у моїх курсах з інженерії алгоритмів.
Спочатку ми зосереджувалися на змішаному цілочисельному програмуванні (MIP), а
CP-SAT розглядали як альтернативу. Однак нещодавно ми почали використовувати
CP-SAT як перший оптимізаційний розв’язувач завдяки його високорівневому
інтерфейсу, який значно легше засвоювати початківцям. Попри цю зміну, оскільки
MIP використовується частіше, книга містить багато порівнянь із MIP. Тож вона
дружня до початківців, але водночас враховує потреби користувачів MIP, які
шукають альтернативи.

На відміну від інших книг, орієнтованих на студентів математичної оптимізації
чи дослідження операцій, ця книга, адресована студентам комп’ютерних наук,
наголошує на коді більше, ніж на математиці чи бізнес-кейсах, пропонуючи
практичний підхід до навчання оптимізації. Друга частина книги також може бути
цікавою більш просунутим користувачам, оскільки містить те, чого мені бракувало
в інших книгах про оптимізацію.

### Зміст книги

**Частина 1: Основи**

1. [Встановлення](#01-installation): швидкий гайд зі встановлення.
2. [Приклад](#02-example): короткий приклад використання CP-SAT.
3. [Базове моделювання](#04-modelling): огляд змінних, цілей і обмежень.
4. [Просунуте моделювання](#04B-advanced-modelling): складніші обмеження, такі як
   обмеження на контури й інтервали.
5. [Параметри](#05-parameters): як задавати поведінку CP-SAT за потреби.
   Ліміти часу, підказки, припущення, паралелізація тощо.
6. [Розуміння логів](#understanding-the-log): як інтерпретувати лог.
7. [Як це працює?](#07-under-the-hood): після того як ми зрозуміємо, що можемо
   робити з CP-SAT, подивимося, як CP-SAT це реалізує.
8. [Альтернативи](#03-big-picture): огляд різних технік і інструментів
   оптимізації. Розміщення CP-SAT у контексті.
9. [MathOpt як шар моделювання](#chapters-mathopt): новий шар моделювання в
   OR-Tools, який дозволяє використовувати CP-SAT як бекенд-розв’язувач, а також
   MIP-розв’язувачі, такі як Gurobi або HiGHS.

**Частина 2: Просунуті теми**

7. [Патерни кодування](#06-coding-patterns): базові шаблони проєктування для
   створення підтримуваних алгоритмів.
8. [(Чернетка) Розробка через тести](#test-driven-optimization): як розробляти
   оптимізаційний алгоритм із застосуванням test-driven development.
9. [Побудова оптимізаційного API](#building_an_optimization_api) як створити
   масштабоване API для довготривалих оптимізаційних задач.
10. [CP-SAT vs. ML vs. QC](#chapters-machine-learning): порівняння CP-SAT з
    машинним навчанням та квантовими обчисленнями.
11. [Пошук у великій околиці](#09-lns): використання CP-SAT для створення
    потужніших евристик.
12. [Бенчмаркінг вашої моделі](#08-benchmarking): як порівнювати вашу модель та
    інтерпретувати результати.

### Передумови

<!-- Background --->

Ця книга передбачає, що ви вільно володієте Python і вже знайомі з комбінаторними
задачами оптимізації. Якщо ж ви лише починаєте вивчати комбінаторну оптимізацію
самостійно, рекомендую почати з безкоштовного курсу Coursera
[Discrete Optimization](https://www.coursera.org/learn/discrete-optimization),
який читають Pascal Van Hentenryck та Carleton Coffrin. Цей курс дає
всебічний вступ у стислому форматі.

Для захопливого занурення в класичну задачу цієї галузі дуже рекомендую
[In Pursuit of the Traveling Salesman від Bill Cook](https://press.princeton.edu/books/paperback/9780691163529/in-pursuit-of-the-traveling-salesman).
Ця книга разом із
[YouTube-доповіддю](https://www.youtube.com/watch?v=5VjphFYQKj8) автора,
що триває близько години, пропонує практичний кейс із добре відомою задачею
комівояжера. Вона не лише знайомить з базовими техніками, а й заглиблюється в
спільноту та історичний контекст цієї сфери.

Крім того, стаття
[Mathematical Programming](https://www.gurobi.com/resources/math-programming-modeling-basics/)
від конкурента CP-SAT — Gurobi — дає змістовний вступ до математичного
програмування та моделювання. У цьому контексті слово «Programming» не означає
написання коду; воно походить від раннього значення слова «program», що
означало план дій або розклад. Якщо ця відмінність для вас нова, це сильний
сигнал, що вам варто прочитати цю статтю.

> **Про головного автора:** [д-р Dominik Krupke](https://krupke.cc) —
> постдокторський дослідник у
> [Algorithms Division](https://www.ibr.cs.tu-bs.de/alg) TU Braunschweig. Він
> спеціалізується на практичних рішеннях NP-складних задач. Починав у
> теоретичній інформатиці, а нині застосовує свою експертизу для розв’язання
> того, що раніше вважали неможливим, часто за допомогою CP-SAT. Цей праймер
> по CP-SAT спершу був створений як навчальний матеріал для його студентів, а
> згодом у вільний час розширений для ширшої аудиторії.
>
> **Учасники:** цей праймер збагатили внески
> [кількох людей](https://github.com/d-krupke/cpsat-primer/graphs/contributors).
> Зокрема, Leon Lan відіграв ключову роль у реструктуризації матеріалу та
> наданні критичного зворотного зв’язку, а Michael Perk суттєво покращив
> розділ про обмеження reservoir. Також дякую всім іншим учасникам, які
> знаходили й виправляли помилки, покращували текст і ділилися цінними ідеями.

> **Знайшли помилку?** Будь ласка, відкрийте issue або pull request. Можна
> також просто написати мені листа на `krupked@gmail.com`.

> **Хочете долучитися?** Якщо ви зацікавлені у внеску, будь ласка, відкрийте
> issue або напишіть мені email із коротким описом вашої пропозиції. Тоді ми
> зможемо обговорити деталі. Я вітаю будь-яку допомогу і відкритий до
> розширення контенту. Учасники будь-якого розділу чи подібних внесків будуть
> визнані співавторами.

> **Хочете використати/поширювати цей контент?** Цей туторіал можна вільно
> використовувати за ліцензією
> [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/). Невеликі частини
> можна копіювати навіть без зазначення авторства для некомерційних
> освітніх цілей.


---

<!-- This file was generated by the `build.py` script. Do not edit it manually. -->
<!-- ./chapters/01_installation.md -->
<!-- EDIT THIS PART VIA 01_installation.md -->

# Частина 1: Основи

<a name="01-installation"></a>

## Встановлення

У цьому праймері ми використовуємо Python 3 і припускаємо, що у вас є робоча
інсталяція Python 3 та базові навички роботи з ним. Існують інтерфейси й для
інших мов, але Python 3, на мою думку, найзручніший, адже математичні вирази в
Python дуже близькі до математичної нотації (це дозволяє швидше помічати
математичні помилки). Лише для дуже великих моделей може знадобитися
скомпільована мова на кшталт C++ через питання продуктивності. Для менших
моделей ви не помітите різниці у швидкодії.

Встановити CP-SAT, який є частиною пакета OR-Tools, дуже просто — це можна
зробити через менеджер пакетів Python
[pip](https://pip.pypa.io/en/stable/).

```shell
pip3 install -U ortools
```

Ця команда також оновить наявну інсталяцію OR-Tools. Оскільки інструмент активно
розвивається, рекомендується часто оновлюватися. Ми навіть стикалися з
некоректною поведінкою (тобто багами) у ранніх версіях, які згодом виправили в
оновленнях (це стосувалося більш просунутих можливостей — не хвилюйтеся щодо
коректності базового використання).

Особисто я люблю використовувати [Jupyter Notebooks](https://jupyter.org/) для
експериментів із CP-SAT.

### Яке обладнання потрібне?

Важливо розуміти, що для використання CP-SAT вам не потрібні можливості
суперкомп’ютера. Стандартного ноутбука часто достатньо для розв’язання багатьох
задач. Основні вимоги — потужність CPU та пропускна здатність пам’яті; GPU не
потрібен.

Щодо процесорної потужності, ключовим є баланс між кількістю ядер і швидкодією
кожного окремого ядра. CP-SAT за замовчуванням використовує всі доступні ядра,
застосовуючи різні стратегії на кожному з них.
[Залежно від кількості ядер CP-SAT поводиться по-різному](https://github.com/google/or-tools/blob/main/ortools/sat/docs/troubleshooting.md#improving-performance-with-multiple-workers).
Однак ефективність цих стратегій може відрізнятися, і заздалегідь зазвичай
незрозуміло, яка буде найкращою. Вища продуктивність одного ядра означає, що
ваша основна стратегія працюватиме швидше. Я рекомендую мінімум 4 ядра та 16 ГБ
оперативної пам’яті.

Хоча CP-SAT доволі ощадний щодо пам’яті, обсяг доступної оперативної пам’яті все
одно може бути обмежувальним фактором для розміру задач. Коли ми налаштовували
лабораторію для масштабного бенчмаркінгу в TU Braunschweig, постало питання
вибору між настільними ПК і дорожчими робочими станціями чи серверами. Ми
обрали настільні машини з процесорами AMD Ryzen 9 7900 (Intel теж підійшов би)
та 96 ГБ DDR5, керовані через Slurm. Це рішення було зумовлене тим, що приріст
продуктивності від дорожчих робочих станцій або серверів був відносно невеликим
порівняно зі значно вищою ціною. У дорозі я часто й досі можу працювати на
своєму старому Intel Macbook Pro 2018 року з i7 і лише 16 ГБ RAM, але великі
моделі його перевантажують. Натомість моя домашня робоча станція з AMD Ryzen 7
5700X і 32 ГБ RAM рідко має проблеми з моделями, над якими я працюю.

Для додаткових рекомендацій зверніть увагу на
[апаратні рекомендації для розв’язувача Gurobi](https://support.gurobi.com/hc/en-us/articles/8172407217041-What-hardware-should-I-select-when-running-Gurobi-),
які, ймовірно, будуть схожими. Оскільки ми часто використовуємо Gurobi поряд із
CP-SAT, наші апаратні рішення також були частково зумовлені їхніми
рекомендаціями.

<!-- This file was generated by the `build.py` script. Do not edit it manually. -->
<!-- ./chapters/02_example.md -->
<!-- EDIT THIS PART VIA 02_example.md -->

<a name="02-example"></a>

## Простий приклад


Перш ніж заглиблюватися у внутрішні деталі, швидко погляньмо на просте
застосування CP-SAT. Приклад настільки простий, що його можна розв’язати вручну,
але пам’ятайте, що CP-SAT (ймовірно) нормально впорається, якщо ви додасте
тисячу (а можливо й десятки чи сотні тисяч) змінних і обмежень більше. Базова
ідея використання CP-SAT, подібно до MIP, — визначити оптимізаційну задачу через
змінні, обмеження й цільову функцію, а потім дозволити розв’язувачу знайти
розв’язок. Таку формалізацію, яку відповідний розв’язувач може зрозуміти,
називають _моделлю_ задачі. Для тих, хто не знайомий із
[декларативним підходом](https://programiz.pro/resources/imperative-vs-declarative-programming/),
можна провести аналогію з SQL: ви описуєте, які дані хочете отримати, а не як
їх добути. Втім, це не суто декларативний підхід, адже те, _як_ ви моделюєте
задачу, може мати величезне (!) значення, і правильне моделювання потребує
досвіду та розуміння внутрішньої роботи. Для невеликих задач (скажімо, кілька
сотень або тисяч змінних) ви можете просто «пощастити» й отримати оптимальні
розв’язки, не маючи чіткого уявлення про те, що відбувається. Розв’язувачі
щороку все краще справляються з «поганими» моделями.

> [!NOTE]
>
> **Модель** у математичному програмуванні означає математичний опис задачі, що
> складається зі змінних, обмежень і, за потреби, цільової функції, яку може
> розуміти відповідний клас розв’язувачів. _Моделювання_ — це перетворення
> задачі (екземпляра) у відповідну форму, наприклад перетворення всіх обмежень
> у лінійні, як цього вимагає змішане цілочисельне лінійне програмування. Зауважте,
> що спільнота [SAT](https://en.wikipedia.org/wiki/SAT_solver) використовує
> термін _model_ для позначення (допустимого) присвоєння змінних, тобто розв’язку
> SAT-формули. Якщо ви плутаєтеся в термінах, можливо, варто прочитати короткий
> гайд
> [Math Programming Modelling Basics](https://www.gurobi.com/resources/math-programming-modeling-basics/).

Наша перша задача не має глибшого сенсу, окрім демонстрації базового робочого
процесу: створення змінних (x і y), додавання обмеження $x+y<=30$, задання цілі
(максимізувати $30x + 50y$) і отримання розв’язку:

```python
from ortools.sat.python import cp_model

model = cp_model.CpModel()

# Змінні
x = model.new_int_var(0, 100, "x")
y = model.new_int_var(0, 100, "y")

# Обмеження
model.add(x + y <= 30)

# Ціль
model.maximize(30 * x + 50 * y)

# Розв’язання
solver = cp_model.CpSolver()
status_code = solver.solve(model)
status_name = solver.status_name()

# Виводимо статус розв’язувача та оптимальний розв’язок.
print(f"{status_name} ({status_code})")
print(f"x={solver.value(x)},  y={solver.value(y)}")
```

    OPTIMAL (4)
    x=0,  y=30

Дуже просто, так? Для розв’язання загальної задачі, а не одного конкретного
екземпляра, ви, звісно, створите словник або список змінних і використаєте
щось на кшталт `model.add(sum(vars)<=n)`, адже ви не хочете вручну створювати
модель для великих екземплярів.

Розв’язувач може повертати п’ять різних статусів:

| Статус          | Код | Опис                                                                                                                                                                                         |
| --------------- | ---- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `UNKNOWN`       | 0    | Розв’язувач працював недостатньо довго.                                                                                                                                                       |
| `MODEL_INVALID` | 1    | Модель некоректна. Такий статус трапляється рідко.                                                                                                                                            |
| `FEASIBLE`      | 2    | Модель має допустимий, але не обов’язково оптимальний, розв’язок. Якщо цільова функція відсутня, кожна допустима модель повертає `OPTIMAL`, що може бути неочевидно.                        |
| `INFEASIBLE`    | 3    | Модель не має допустимого розв’язку. Це означає, що обмеження надто жорсткі.                                                                                                                   |
| `OPTIMAL`       | 4    | Модель має оптимальний розв’язок. Якщо цільова функція відсутня, повертається `OPTIMAL` замість `FEASIBLE`.                                                                                   |

> [!TIP]
>
> Статусу `UNBOUNDED` _немає_, оскільки в CP-SAT немає необмежених змінних.
> Класичні MIP-розв’язувачі дозволяють необмежені змінні, що може призводити до
> необмежених розв’язків, тобто цільова функція може необмежено зростати або
> спадати без досягнення максимуму чи мінімуму. У програмуванні з обмеженнями
> необмежені домени зазвичай не допускаються і не є корисними. Натомість у
> лінійному програмуванні вони важливі, наприклад при використанні двоїстості.

Для великих моделей CP-SAT, на жаль, не завжди зможе знайти оптимальний
розв’язок. Але гарна новина в тому, що розв’язувач, ймовірно, все одно знайде
задовільний розв’язок і надасть межу для оптимального значення. На цьому етапі
вміння інтерпретувати лог розв’язувача стає критично важливим для аналізу його
продуктивності. Про це ми поговоримо пізніше.

### Математична модель

Математична модель наведеного вище коду зазвичай записується експертами так:

```math
\max 30x + 50y
```

```math
\text{s.t. } x+y \leq 30
```

```math
\quad 0\leq x \leq 100
```

```math
\quad 0\leq y \leq 100
```

```math
x,y \in \mathbb{Z}
```

` s.t.` означає `subject to`, інколи також читають як `such that`.

### Перевантаження операторів

Один із аспектів використання CP-SAT, що часто викликає труднощі у новачків, —
це розуміння перевантаження операторів у Python і відмінностей між двома типами
змінних. У цьому контексті `x` і `y` — це математичні змінні. Тобто це
заглушки, яким конкретні значення будуть присвоєні лише під час розв’язання.
Щоб проілюструвати це точніше, розгляньмо приклад у Python-оболонці:

```pycon
>>> model = cp_model.CpModel()
>>> x = model.new_int_var(0, 100, "x")
>>> x
x(0..100)
>>> type(x)
<class 'ortools.sat.python.cp_model.IntVar'>
>>> x + 1
sum(x(0..100), 1)
>>> x + 1 <= 1
<ortools.sat.python.cp_model.BoundedLinearExpression object at 0x7d8d5a765df0>
```

У цьому прикладі `x` — не звичайне число, а заглушка, що потенційно може
приймати будь-яке значення між 0 і 100. Коли до `x` додаємо 1, результатом
стає нова заглушка, що представляє суму `x` і 1. Аналогічно, порівняння цієї
суми з 1 породжує ще одну заглушку, яка інкапсулює сам факт порівняння. На цьому
етапі ці заглушки не мають конкретних значень, але вони потрібні для опису
обмежень моделі. Спроба виконати операцію на кшталт `if x + 1 <= 1: print("True")`
викличе `NotImplementedError`, адже умова `x+1<=1` не може бути безпосередньо
оцінена.

Хоча такий спосіб опису моделей може спочатку здаватися дивним, він дозволяє
наблизитися до математичної нотації, що, у свою чергу, полегшує виявлення та
виправлення помилок у моделі.

### Більше прикладів

Якщо вам замало,
[ця папка містить багато Jupyter Notebook-прикладів від розробників](https://github.com/google/or-tools/tree/stable/examples/notebook/sat).
Наприклад:

- [multiple_knapsack_sat.ipynb](https://github.com/google/or-tools/blob/stable/examples/notebook/sat/multiple_knapsack_sat.ipynb)
  показує, як розв’язати задачу про кілька рюкзаків.
- [nurses_sat.ipynb](https://github.com/google/or-tools/blob/stable/examples/notebook/sat/nurses_sat.ipynb)
  показує, як складати графік змін медсестер.
- [bin_packing_sat.ipynb](https://github.com/google/or-tools/blob/stable/examples/notebook/sat/bin_packing_sat.ipynb)
  показує, як розв’язати задачу пакування в контейнери (bin packing).
- ... (якщо ви знаєте ще гарні приклади, які варто згадати тут — дайте знати!)

Крім того, є великий і дружній до початківців приклад розкладу працівників
[тут](https://pganalyze.com/blog/a-practical-introduction-to-constraint-programming-using-cp-sat).

Тепер, коли ви побачили мінімальну модель, давайте розглянемо різні варіанти
моделювання задач. Хоча досвідчений оптимізатор може впоратися з більшістю задач,
використовуючи лише щойно описані елементи, чітке формулювання ваших намірів
може допомогти CP-SAT ефективніше оптимізувати задачу.

> [!TIP]
>
> Оптимізаційні задачі всюди в реальному світі. Якщо вам потрібен швидкий
> огляд практичних застосувань, відео
> [Optimization 360 (Optimization Everywhere)](https://www.youtube.com/watch?v=bWbCjedszc0&list=PLHiHZENG6W8B7f6OEiDg5Gj0Jz35iZ17Z&index=3)
> з тренінгу Gurobi Opti 202 показує різноманітні домени, де
> оптимізація відіграє ключову роль.
>
> Ось підсумкова таблиця прикладів задач з відео:
>
> | **Задача / Домен**                      | **Оптимізаційний виклик**                                                                                                            |
> | --------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------ |
> | Переробка молока та молочної продукції  | Змішати сире молоко з різним вмістом жиру/білка, щоб отримати стабільні кінцеві продукти (молоко, масло, сир).                       |
> | Робота енергомережі                     | Планувати та диспетчеризувати генерацію електроенергії на кількох горизонтах часу, підтримуючи стабільність мережі та регуляторні вимоги. |
> | Формування кормів для тварин            | Обирати суміші інгредієнтів, що мінімізують вартість, дотримуючись харчових обмежень і лімітів доступності.                         |
> | Ланцюг постачання авто та запаси        | Визначати, які моделі та конфігурації авто тримати в дилерів, балансуючи попит, кастомізацію та витрати на запаси.                  |
> | Екологічна відповідність (Toyota)       | Розподіляти виробництво авто між ринками, щоб дотриматися норм викидів і паливної ефективності з мінімальною вартістю.              |
> | Логістика деталей і попереднє секвенсування (Audi) | Упорядковувати тисячі деталей авто в обмежених зонах і доставляти їх на конвеєр у правильному порядку.                      |
> | Перерозподіл шкільних округів           | Призначати учнів до шкіл з урахуванням місткості, відстані, цілісності спільноти та справедливості.                                |
> | Поповнення готівки в банкоматах          | Планувати доставки готівки до банкоматів, мінімізуючи простоювання капіталу та транспортні витрати, запобігаючи дефіциту.           |
> | Планування змін персоналу               | Призначати працівників на зміни, дотримуючись справедливості, лімітів навантаження, правових вимог і потреб організації.           |
> | Лісове господарство та стале вирубування | Планувати рубки та висадку протягом десятиліть, максимізуючи довгостроковий врожай і збереження вуглецю при сталому підході.        |
> | Доставка посилок (останній кілометр)    | Призначати посилки на маршрути та водіїв у великому масштабі, враховуючи географію й знайомість водія з місцевістю.                 |
> | Локації фудтраків                       | Обирати щоденні місця для автопарку фудтраків, максимізуючи очікуваний прибуток з огляду на просторовий попит.                      |
> | Спортивні розклади / розподіл команд    | Створювати збалансовані розклади матчів або чесні команди з урахуванням рівнів навичок і обмежень учасників.                       |
> | Ціноутворення супермаркетів             | Спільно встановлювати ціни на сотні взаємопов’язаних товарів, максимізуючи дохід із урахуванням ефектів заміщення.                  |
> | Платформи доставки їжі (Instacart)      | Зіставляти водіїв, клієнтів і ресторани за умов невизначеного попиту та доступності, щоб доставляти замовлення ефективно і надійно. |

<!-- This file was generated by the `build.py` script. Do not edit it manually. -->
<!-- ./chapters/04_modelling.md -->
<!--EDIT THIS PART VIA 04_modelling.md -->

<a name="04-modelling"></a>

## Базове моделювання


У цьому розділі ми занурюємося в базові можливості моделювання CP-SAT. CP-SAT
надає широкий набір обмежень, ближчий до високорівневих мов моделювання на кшталт
MiniZinc, ніж до традиційного змішаного цілочисельного програмування (MIP).
Наприклад, він пропонує обмеження `all_different` та
`add_multiplication_equality`. Такі просунуті можливості зменшують потребу
моделювати складну логіку виключно через лінійні обмеження, хоча й роблять
інтерфейс складнішим. Водночас не всі обмеження однаково ефективні: лінійні та
булеві обмеження зазвичай найефективніші, тоді як обмеження на кшталт
`add_multiplication_equality` можуть суттєво вимагати більше ресурсів.

> [!TIP]
>
> Якщо ви переходите зі змішаного цілочисельного програмування (MIP), ви можете
> бути звиклими вручну реалізовувати високорівневі обмеження і підбирати параметри
> Big-M для кращої продуктивності. У CP-SAT такі ручні налаштування зазвичай не
> потрібні. CP-SAT працює інакше, ніж типові MIP-розв’язувачі, менше спираючись
> на лінійну релаксацію і більше — на внутрішній SAT-розв’язувач та пропагатори,
> які ефективно керують логічними обмеженнями. Користуйтеся високорівневими
> обмеженнями — вони часто ефективніші в CP-SAT.

Цей праймер розширено так, щоб охопити всі обмеження в двох розділах, із різними
прикладами, які ілюструють контексти їхнього застосування. Однак майстерність
моделювання — це значно більше, ніж знання обмежень. Вона вимагає глибокого
розуміння принципів і технік, що роблять моделі ефективними та застосовними до
реальних задач.

Для детальнішого вивчення моделювання варто звернутися до книги
«Model Building in Mathematical Programming» автора H. Paul Williams, яка
дає ґрунтовне уявлення про предмет і містить практичні приклади. Хоча ця книга
не специфічна для CP-SAT, базові техніки та концепції є універсальними. Також
тим, хто лише знайомиться з темою або переходить з MIP-рішень, може бути корисно
вивчити підхід до моделювання в Gurobi через цей
[відеокурс](https://www.youtube.com/playlist?list=PLHiHZENG6W8CezJLx_cw9mNqpmviq3lO9).
Хоча багато принципів збігаються, деякі стратегії, специфічні для CP-SAT, краще
покривають випадки, де традиційні MIP-розв’язувачі мають труднощі.

Додаткові ресурси з математичного моделювання (не специфічні для CP-SAT):

- [Math Programming Modeling Basics від Gurobi](https://www.gurobi.com/resources/math-programming-modeling-basics/):
  ресурс дає міцний вступ до основ математичного моделювання.
- [Modeling with Gurobi Python](https://www.youtube.com/playlist?list=PLHiHZENG6W8CezJLx_cw9mNqpmviq3lO9):
  комплексний відеокурс із моделювання в Gurobi, який підкреслює концепції,
  що також застосовні до CP-SAT.
- [Model Building in Mathematical Programming від H. Paul Williams](https://www.wiley.com/en-us/Model+Building+in+Mathematical+Programming%2C+5th+Edition-p-9781118443330):
  докладний путівник із технік математичного моделювання.

> [!TIP]
>
> Для старту з побудови оптимізаційних моделей загалом я дуже рекомендую допис
> [The Art Of Not Making It An Art](https://www.gurobi.com/resources/optimization-modeling-the-art-of-not-making-it-an-art/).
> Він чудово підсумовує фундаментальні принципи успішного ведення
> оптимізаційного проєкту незалежно від конкретної мови чи розв’язувача.

---

**Елементи:**

- [Змінні](#04-modelling-variables): `new_int_var`, `new_bool_var`,
  `new_constant`, `new_int_var_series`, `new_bool_var_series`
  - [Змінні з користувацьким доменом](#04-modelling-domain-variables):
    `new_int_var_from_domain`
- [Цілі](#04-modelling-objectives): `minimize`, `maximize`
- [Лінійні обмеження](#04-modelling-linear-constraints): `add`,
  `add_linear_constraint`
- [Логічні обмеження (пропозиційна логіка)](#04-modelling-logic-constraints):
  `add_implication`, `add_bool_or`, `add_at_least_one`, `add_at_most_one`,
  `add_exactly_one`, `add_bool_and`, `add_bool_xor`
- [Умовні обмеження (реїфікація)](#04-modelling-conditional-constraints):
  `only_enforce_if`
- [Абсолютні значення та Max/Min](#04-modelling-absmaxmin): `add_min_equality`,
  `add_max_equality`, `add_abs_equality`
- [Множення, ділення і модуль](#04-modelling-multdivmod):
  `add_modulo_equality`, `add_multiplication_equality`, `add_division_equality`
- [All Different](#04-modelling-alldifferent): `add_all_different`
- [Домени та комбінації](#04-modelling-table): `add_allowed_assignments`,
  `add_forbidden_assignments`
- [Масиви/обмеження елемента](#04-modelling-element): `add_element`,
  `add_inverse`

Більш просунуті обмеження `add_circuit`, `add_multiple_circuit`,
`add_automaton`,`add_reservoir_constraint`,
`add_reservoir_constraint_with_active`, `new_interval_var`,
`new_interval_var_series`, `new_fixed_size_interval_var`,
`new_optional_interval_var`, `new_optional_interval_var_series`,
`new_optional_fixed_size_interval_var`,
`new_optional_fixed_size_interval_var_series`, `add_no_overlap`,
`add_no_overlap_2d` та `add_cumulative` розглянуто в наступному розділі.

---

<a name="04-modelling-variables"></a>

### Змінні

У CP-SAT є два важливі типи змінних: булеві та цілочисельні
(які насправді перетворюються на булеві, але про це пізніше). Є також, наприклад,
[інтервальні змінні](https://developers.google.com/optimization/reference/python/sat/python/cp_model#intervalvar),
але це радше комбінація цілочисельних змінних, і їх розглянуто
[пізніше](#04-modelling-intervals). Для цілочисельних змінних потрібно задати
нижню та верхню межі.

```python
model = cp_model.CpModel()

# Цілочисельна змінна z з межами -100 <= z <= 100
z = model.new_int_var(-100, 100, "z")  # новий синтаксис
z_ = model.NewIntVar(-100, 100, "z_")  # старий синтаксис

# Булева змінна b
b = model.new_bool_var("b")  # новий синтаксис
b_ = model.NewBoolVar("b_")  # старий синтаксис

# Неявне заперечення b:
not_b = ~b  # буде 1, якщо b = 0, і 0, якщо b = 1
not_b_ = b.Not()  # старий синтаксис
```

Додатково можна використовувати `model.new_int_var_series` і
`model.new_bool_var_series`, щоб створювати кілька змінних одразу з pandas Index.
Це особливо зручно, якщо дані подані в pandas DataFrame. Проте з точки зору
продуктивності виграшу немає — це лише зручніше.

```python
model = cp_model.CpModel()

# Створюємо Index від 0 до 9
index = pd.Index(range(10), name="index")

# Створюємо pandas Series з 10 цілочисельних змінних відповідно до індексу
xs = model.new_int_var_series("x", index, 0, 100)

# Список булевих змінних
df = pd.DataFrame(
    data={"weight": [1 for _ in range(10)], "value": [3 for _ in range(10)]},
    index=["A", "B", "C", "D", "E", "F", "G", "H", "I", "J"],
)
bs = model.new_bool_var_series("b", df.index)  # noqa: F841

# Використання добутку для pandas DataFrame — доволі зручний спосіб
# створювати типові лінійні вирази.
model.add(bs @ df["weight"] <= 100)
model.maximize(bs @ df["value"])
```

Також існує метод `new_constant`, який дозволяє створити змінну зі сталим
значенням. Це дає змогу безпечно замінювати змінні на константи. Це насамперед
корисно для булевих змінних, адже константні цілочисельні змінні в більшості
випадків можна просто замінити звичайними цілими числами.

> [!TIP]
>
> У старому проєкті я помітив, що підтримання тісних меж для цілочисельних
> змінних може суттєво впливати на продуктивність. Використання евристики для
> пошуку прийнятного початкового розв’язку, що дало змогу звузити межі,
> виявилося виправданим, навіть якщо межі були всього на кілька відсотків
> тіснішими. Хоча це було кілька років тому, і CP-SAT значно розвинувся, я й
> досі рекомендую тримати межі значень змінних якомога більш тісними.

У CP-SAT немає неперервних/дійсних змінних (і навіть констант): якщо вам потрібні
дійсні числа, їх треба апроксимувати цілими числами з певною роздільною здатністю.
Наприклад, можна просто помножити всі значення на 100 для кроку 0,01. Значення
2,35 тоді буде представлене як 235. Це, ймовірно, можна було б реалізувати
безпосередньо в CP-SAT, але явна реалізація не складна і має числові наслідки,
про які варто пам’ятати.

Відсутність неперервних змінних може здаватися суттєвим обмеженням, особливо для
тих, хто має досвід у лінійній оптимізації, де неперервні змінні зазвичай
вважаються простішою частиною. Проте, якщо ваша задача містить лише кілька
неперервних змінних, які потрібно апроксимувати великими цілими числами, і
містить складні обмеження, як-от абсолютні значення, тоді як більшість задачі
домінована логічними обмеженнями, CP-SAT часто може перевершити розв’язувачі
змішаного цілочисельного програмування. Лише тоді, коли задача має значну
кількість неперервних змінних і суттєво виграє від сильної лінійної релаксації,
MIP-розв’язувачі матимуть виражену перевагу, попри те, що CP-SAT має пропагатор
на основі двоїстого симплекс-методу.

Я аналізував вплив роздільної здатності (тобто множника, на який множаться
дійсні числа) на час виконання CP-SAT і виявив, що ефект залежить від задачі.
Для однієї задачі час виконання зростав лише логарифмічно з роздільною
здатністю, що дозволило використовувати дуже високу роздільну здатність 100 000x
без значних проблем. Натомість для іншої задачі
час виконання зростав приблизно лінійно з роздільною здатністю, що робило високі
роздільні здатності непрактичними. Час виконання для різних множників у цьому
випадку був таким: 1x: 0,02 с, 10x: 0,7 с, 100x: 7,6 с, 1000x: 75 с, 10 000x:
понад 15 хвилин, хоча розв’язок залишався тим самим, лише масштабованим. Тому,
хоча високі роздільні здатності можуть бути прийнятними для деяких задач у
CP-SAT, важливо перевіряти їхній вплив на час виконання, оскільки він може бути
значним.

З мого досвіду, булеві змінні є критично важливими в багатьох комбінаторних
оптимізаційних задачах. Наприклад, відома задача комівояжера складається лише з
булевих змінних. Тому реалізація розв’язувача, що спеціалізується на булевих
змінних і базується на SAT-розв’язувачі (як CP-SAT), є логічним підходом. CP-SAT
використовує сильні сторони SAT-технік, які дуже ефективні для задач, де
домінують булеві змінні.

Ви можете запитати, чому в CP-SAT потрібно явно задавати імена змінних. Хоча
технічної необхідності для цього, здається, немає, іменування змінних може бути
надзвичайно корисним для налагодження. Розуміння схеми імен дозволяє легше
інтерпретувати внутрішнє представлення моделі і швидше знаходити проблеми. Якщо
чесно, лише кілька разів мені справді доводилося уважно дивитися на внутрішнє
представлення, і в більшості випадків я б волів не витрачати час на іменування
змінних.

<a name="04-modelling-domain-variables"></a>

#### Змінні з користувацьким доменом

Коли ви працюєте з цілочисельними змінними, які, як ви знаєте, можуть набувати
лише певних значень, або хочете обмежити їх можливі значення, змінні з
користувацьким доменом можуть бути цікавими. На відміну від звичайних
цілочисельних змінних, які мають домен у вигляді інтервалу (наприклад, $[1, 100]$),
змінні з доменом можуть задавати конкретний набір значень (наприклад,
$\{1, 31, 57\}$). Це може підвищити ефективність, якщо допустимі значення змінної
суттєво зменшені. Однак це також має недоліки, які ми розглянемо нижче.

CP-SAT працює шляхом перетворення всіх цілочисельних змінних на булеві
(увага: спрощення). Для кожного можливого значення він створює дві булеві
змінні: одна позначає, що цілочисельна змінна дорівнює цьому значенню, а інша
— що вона менша або дорівнює йому. Це називається _order encoding_. На перший
погляд, це може свідчити, що доменні змінні завжди кращі, адже вони зменшують
кількість необхідних булевих змінних.

Однак CP-SAT використовує стратегію лінивого створення цих булевих змінних. Це
означає, що вони генеруються лише за потреби, залежно від процесу прийняття
рішень розв’язувачем. Тому цілочисельна змінна з широким діапазоном — скажімо,
від 0 до 100 — не призведе одразу до створення 200 булевих змінних. Може бути
створено лише кілька, залежно від потреб розв’язувача.

Обмеження домену змінної може мати недоліки. По-перше, якщо припущення щодо
допустимих значень помилкові, це може спричинити тонкі й важковиявні баги. Тому
варто спершу забезпечити коректність, а оптимізації застосовувати вже потім.
По-друге, явне задання домену може суттєво збільшити розмір моделі, адже
розв’язувач має працювати зі списком дискретних значень, а не просто з нижньою
і верхньою межами. Наприклад, якщо змінна має приймати лише парні значення,
неефективно визначати домен, що складається з усіх парних чисел. Краще замінити
змінну $x$ на $2x'$, а в кінцевому розв’язку помножити $x'$ на 2. По-третє, у
деяких випадках використання користувацьких доменів може відкласти знаходження
першого допустимого розв’язку. Оскільки CP-SAT покладається на потужний пошук у
околицях для покращення розв’язків після знаходження першого допустимого, така
затримка може погіршити продуктивність. Якщо обмеження домену не є суттєвою
частиною моделювання, зазвичай краще відкласти його до етапу оптимізації
продуктивності.

Якщо ви все ж вирішите використовувати доменні змінні, ось як їх визначити:

```python
from ortools.sat.python import cp_model

model = cp_model.CpModel()

# Визначаємо домен із вибраних значень
domain = cp_model.Domain.from_values([2, 5, 8, 10, 20, 50, 90])

# Це також можна зробити через інтервали
domain_2 = cp_model.Domain.from_intervals([[8, 12], [14, 20]])

# Доступні деякі операції з доменами
domain_3 = domain.union_with(domain_2)

# Створюємо доменну змінну в межах цього домену
x = model.new_int_var_from_domain(domain, "x")
```

Цей приклад демонструє створення доменної змінної `x`, яка може набувати лише
значень, заданих у `domain`. Це особливо корисно, коли в контексті задачі
змінні мають сенс лише в обмеженому наборі значень.

<a name="04-modelling-objectives"></a>

### Цілі

Не кожна задача потребує цілі; іноді достатньо знайти допустимий розв’язок.
CP-SAT відмінно знаходить допустимі розв’язки — це те, де MIP-розв’язувачі часто
працюють гірше. Водночас CP-SAT також здатен ефективно оптимізувати, що є
слабким місцем для старіших CP-розв’язувачів, якщо судити з мого досвіду.

CP-SAT дозволяє мінімізувати або максимізувати лінійний вираз. Складніші вирази
можна змоделювати за допомогою допоміжних змінних і додаткових обмежень. Щоб
задати цільову функцію, використовуйте `model.minimize` або `model.maximize` з
лінійним виразом. Така гнучкість робить CP-SAT надійним інструментом для
різноманітних оптимізаційних задач.

```python
# Базова модель зі змінними та обмеженнями
model = cp_model.CpModel()
x = model.new_int_var(-100, 100, "x")
y = model.new_int_var(-100, 100, "y")
model.add(x + 10 * y <= 100)

# Мінімізуємо 30x + 50y
model.maximize(30 * x + 50 * y)
```

Подивімося, як моделювати складніші вирази, використовуючи булеві змінні та
генератори.

```python
model = cp_model.CpModel()
x_vars = [model.new_bool_var(f"x{i}") for i in range(10)]
model.minimize(sum(i * x_vars[i] if i % 2 == 0 else i * ~x_vars[i] for i in range(10)))
```

Ця ціль дорівнює

```math
\min \sum_{i=0}^{9} i\cdot x_i \text{ якщо } i \text{ парне, інакше } i\cdot \neg x_i
```

Щоб реалізувати
[лексикографічну оптимізацію](https://en.wikipedia.org/wiki/Lexicographic_optimization),
можна робити кілька раундів, кожного разу фіксуючи попередню ціль як обмеження.

```python
# базова модель
model = cp_model.CpModel()
x = model.new_int_var(-100, 100, "x")
y = model.new_int_var(-100, 100, "y")
z = model.new_int_var(-100, 100, "z")
model.add(x + 10 * y - 2 * z <= 100)

# Визначаємо цілі
first_objective = 30 * x + 50 * y
second_objective = 10 * x + 20 * y + 30 * z

# Оптимізуємо першу ціль
model.maximize(first_objective)
solver = cp_model.CpSolver()
solver.solve(model)

# Фіксуємо першу ціль і оптимізуємо другу
model.add(first_objective == int(solver.objective_value))  # фіксуємо попередню ціль
model.minimize(second_objective)  # оптимізуємо другу ціль
solver.solve(model)
```

> [!TIP]
>
> Більш ефективну реалізацію лексикографічної оптимізації можна знайти в
> розділі _Coding Patterns_.

Щоб працювати з нелінійними цілями в CP-SAT, використовуйте допоміжні змінні та
обмеження. Наприклад, щоб включити абсолютне значення змінної в ціль, спершу
створіть нову змінну, яка представляє це абсолютне значення. Незабаром ми
детальніше розглянемо, як задавати такі обмеження. Нижче — приклад того, як
змоделювати та мінімізувати абсолютне значення змінної `x`:

```python
# Припустимо, x вже визначено в моделі
abs_x = model.new_int_var(
    0, 100, "|x|"
)  # Створюємо змінну, що представляє абсолютне значення x
model.add_abs_equality(target=abs_x, expr=x)  # Визначаємо abs_x як |x|
model.minimize(abs_x)  # Мінімізуємо abs_x
```

Обмеження, доступні для визначення допустимої області розв’язків, обговорюються
в наступному розділі.

<a name="04-modelling-linear-constraints"></a>

### Лінійні обмеження

Це класичні обмеження, які використовуються і в лінійній оптимізації. Пам’ятайте,
що ви все ще не можете використовувати дійсні числа. Як і в лінійній оптимізації,
не дозволено множити змінну на щось, окрім константи, і не можна застосовувати
інші математичні операції.

```python
model.add(10 * x + 15 * y <= 10)
model.add(x + z == 2 * y)

# Це насправді не лінійне, але все одно працює.
model.add(x + y != z)

# Оскільки ми працюємо з цілими числами, строгі нерівності легко реалізувати:
# x < z еквівалентне x <= z-1
model.add(x < y + z)
model.add(y > 300 - 4 * z)
```

Зверніть увагу, що `!=` може бути повільнішим за інші (`<=`, `>=`, `==`)
обмеження, адже це не лінійне обмеження. Якщо у вас є набір змінних, які
взаємно не дорівнюють (`!=`), краще використати `all_different` (див. нижче),
ніж явні `!=` обмеження.

> [!WARNING]
>
> Якщо ви використовуєте перетинні лінійні обмеження, можуть виникати проблеми,
> бо точка перетину повинна бути цілою. Тут немає поняття допуску допустимості,
> як у MIP-розв’язувачах, де дозволяються невеликі відхилення. Допуск у MIP
> дозволяє, наприклад, вважати 0,763445 == 0,763439 через числові похибки
> плаваючої арифметики. У CP-SAT потрібно, щоб значення збігалися точно.

Розгляньмо приклад із двома лінійними рівностями:

```math
x - y = 0
```

```math
4-x = 2y
```

```math
x, y \geq 0
```

Можна перевірити, що $x=4/3$ і $y=4/3$ — допустимий розв’язок. Однак кодування
цього в CP-SAT призводить до недопустимої моделі:

```python
model = cp_model.CpModel()
x = model.new_int_var(-100, 100, "x")
y = model.new_int_var(-100, 100, "y")

model.add(x - y == 0)
model.add(4 - x == 2 * y)

solver = cp_model.CpSolver()
status = solver.solve(model)
assert status == cp_model.INFEASIBLE
```

Навіть масштабування, наприклад множення змінних на 1 000 000 для підвищення
роздільної здатності, не зробить модель допустимою. Хоча типові LP-розв’язувачі
опрацювали б цю модель без проблем, CP-SAT має труднощі, якщо не усунути дроби,
наприклад, помноживши всі члени на 3. Це вимагає ручного втручання, що суперечить
ідеї використання розв’язувача. Такі обмеження важливо враховувати, хоча вони
рідко трапляються в практичних застосуваннях.

> [!TIP]
>
> Якщо у вас довгі суми змінних із коефіцієнтами, може бути ефективніше
> використовувати методи sum у LinearExpr, ніж Python-функцію sum. Зверніть
> увагу, що ця функція зараз не підтримує генератори.
>
> ```python
> xs = [model.new_int_var(0, 10, f"x{i}") for i in range(5)]
> weights = [i for i in range(5)]
> model.add(cp_model.LinearExpr.sum(xs) >= 1)
> model.minimize(cp_model.LinearExpr.weighted_sum(xs, weights))
> ```

Якщо у вас є нижня та верхня межі для лінійного виразу, можна використати метод
`add_linear_constraint`, який дозволяє задати обидві межі одразу.

```python
model.add_linear_constraint(linear_expr=10 * x + 15 * y, lb=-100, ub=10)
```

Схожий за назвою метод `AddLinearExpressionInDomain` розглянуто пізніше.

<a name="04-modelling-logic-constraints"></a>

### Логічні обмеження (пропозиційна логіка)

Пропозиційна логіка дозволяє описувати взаємозв’язки між істинними або хибними
твердженнями за допомогою логічних операторів. Розгляньмо простий сценарій, де
ми визначаємо три булеві змінні:

```python
b1 = model.new_bool_var("b1")
b2 = model.new_bool_var("b2")
b3 = model.new_bool_var("b3")
```

Ці змінні `b1`, `b2` і `b3` представляють окремі пропозиції, істинні значення
яких мають бути визначені моделлю.

Отримати заперечення булевої змінної можна через `~` або метод `.Not()`. Отриману
змінну можна використовувати так само, як і оригінальну:

```python
not_b1 = ~b1  # Заперечення b1
not_b2 = b2.Not()  # Альтернативний запис заперечення
```

Зверніть увагу: у всіх наведених прикладах можна використовувати більше ніж
три змінні, окрім `add_implication`, яке визначене лише для двох змінних.

> [!WARNING]
>
> Булеві змінні — це фактично спеціальні цілочисельні змінні з доменом 0 і 1.
> Тому їх можна включати в лінійні обмеження. Водночас цілочисельні змінні, на
> відміну від булевих, не можна використовувати в булевих обмеженнях. Це
> відрізняється від деяких мов програмування, як-от Python, де цілі числа
> іноді можуть замінювати булеві.

#### Додавання логічних OR-обмежень

Операція логічного OR гарантує, що принаймні одна з умов істинна. Для цього
можна використати:

```python
model.add_bool_or(b1, b2, b3)  # b1 або b2 або b3 має бути істинним
model.add_at_least_one([b1, b2, b3])  # Альтернативний запис
model.add(b1 + b2 + b3 >= 1)  # Альтернатива як лінійне обмеження
```

Усі рядки гарантують, що принаймні одна з `b1`, `b2`, `b3` істинна.

#### Додавання логічних AND-обмежень

Логічне AND вимагає, щоб усі умови були істинними одночасно. Щоб змоделювати
умови, де `b1` істинна, а `b2` і `b3` — хибні, можна використати:

```python
model.add_bool_and(b1, b2.Not(), b3.Not())  # b1 і не b2 і не b3 мають бути істинними
model.add_bool_and(b1, ~b2, ~b3)  # Альтернативний запис із '~'
```

Метод `add_bool_and` найефективніше використовувати разом з `only_enforce_if`
(див. [Умовні обмеження (реїфікація)](#04-modelling-conditional-constraints)).
У випадках без `only_enforce_if` проста AND-умова
$\left( b_1 \land \neg b_2 \land \neg b_3 \right)$ стає зайвою, якщо
підставити $b_1 = 1$ та $b_2, b_3 = 0$. У простих сценаріях варто замінювати
ці змінні константами, щоб зменшити зайву складність, особливо у великих моделях.
У невеликих моделях CP-SAT ефективно обробляє такі надлишковості, тож можна
зосередитися на зрозумілості й читабельності моделі.

#### Додавання логічних XOR-обмежень

Операція XOR (виключне OR) гарантує, що істинна непарна кількість операндів.
Важливо правильно розуміти це визначення, особливо для більш ніж двох змінних:

- Для двох змінних, наприклад `b1 XOR b2`, операція істинна, якщо істинна рівно
  одна з цих змінних, що збігається з обмеженням «рівно одна» для цього випадку.
- Для трьох і більше змінних, наприклад `b1 XOR b2 XOR b3`, операція істинна,
  якщо непарна кількість змінних істинна (тобто одна або три, якщо змінних три).

Ця властивість XOR може бути неочевидною, але вона важлива для моделювання
сценаріїв, де кількість істинних умов має бути непарною:

```python
model.add_bool_xor(b1, b2)  # Істинно, якщо рівно одна з b1 або b2 істинна
model.add_bool_xor(
    b1, b2, b3
)  # Істинно, якщо непарна кількість b1, b2, b3 істинна (тобто 1 або 3)
```

#### Задання унікальних умов

Щоб задати, що істинна рівно одна або не більше ніж одна змінна, використовуйте:

```python
model.add_exactly_one([b1, b2, b3])  # Рівно одна змінна істинна
model.add_at_most_one([b1, b2, b3])  # Не більше ніж одна змінна істинна
```

Ці обмеження корисні для сценаріїв, де потрібно змоделювати взаємовиключні
вибори.

Альтернативно можна використати `add`:

```python
model.add(b1 + b2 + b3 == 1)  # Рівно одна змінна істинна
model.add(b1 + b2 + b3 <= 1)  # Не більше ніж одна змінна істинна
```

#### Моделювання імплікацій

Логічна імплікація `->` означає, що якщо перша умова істинна, то друга теж має
бути істинною. Це можна змоделювати так:

```python
model.add_implication(b1, b2)  # Якщо b1 істинна, то b2 теж має бути істинною
```

Також можна використати `add`:

```python
model.add(b2 >= b1)  # Якщо b1 істинна, то b2 теж має бути істинною
```

#### Еквівалентні перетворення логічних виразів

Логічні вирази часто записують у вкладеній формі, але CP-SAT потребує
плоскої структури. На щастя, будь-який вираз пропозиційної логіки можна
переписати у плоску структуру, яка використовує лише `and_bool_or`
(також відому як кон’юнктивна нормальна форма, CNF). Усі інші обмеження —
це лише синтаксичний цукор для більш природного моделювання. Хоча CP-SAT
було б легко підтримувати вкладені вирази, розробка фокусується на рушії, а
не на інтерфейсі. Тому наразі такі перетворення треба виконувати вручну
(або використовувати [CPMpy](https://cpmpy.readthedocs.io/en/latest/index.html)).

Найкорисніші перетворення:

1. Імплікація: `A -> B` еквівалентна `NOT A OR B`
2. `NOT (A AND B)` еквівалентне `NOT A OR NOT B` (закон де Моргана 1)
3. `NOT (A OR B)` еквівалентне `NOT A AND NOT B` (закон де Моргана 2)

Ці еквівалентності можна перевірити таблицею істинності. Оскільки є лише чотири
можливі комбінації істинності для `A` і `B`, достатньо перевірити, що обидві
колонки дають однакові результати:

| A   | B   | A -> B | NOT A OR B |
| --- | --- | ------ | ---------- |
| 0   | 0   | 1      | 1          |
| 0   | 1   | 1      | 1          |
| 1   | 0   | 0      | 0          |
| 1   | 1   | 1      | 1          |

Зауважте, що `A` і `B` можуть бути логічними виразами, а не лише окремими
змінними. Більш розширений список еквівалентностей можна знайти на
[Wikipedia](https://en.wikipedia.org/wiki/Propositional_logic#List_of_classically_valid_argument_forms).

> [!TIP]
>
> Логіка — типова бакалаврська дисципліна, і в мережі є записані курси на
> випадок, якщо хочете освіжити знання:
>
> - [Logic 101](https://www.youtube.com/playlist?list=PLKI1h_nAkaQq5MDWlKXu0jeZmLDt-51on)
>   від William Spaniel — серія коротких відео з основ логіки, також підходить
>   для людей без глибокої математичної підготовки.
> - [Logic Stanford CS221](https://youtube.com/playlist?list=PLh7QmcIRQB-uiOS4GMlBbq0jkvtqhqtq0&si=dyXebJW-nvW14pFp)
>   має більш виражений фокус на інформатиці і теж доволі компактний — легко
>   переглянути за день.

> [!NOTE]
>
> Також дуже рекомендую наступний
> [розділ](<https://eng.libretexts.org/Bookshelves/Computer_Science/Programming_and_Computation_Fundamentals/Mathematics_for_Computer_Science_(Lehman_Leighton_and_Meyer)/01:_Proofs/03:_Logical_Formulas>)
> відкритої книги _Mathematics for Computer Science_ авторів Lehman,
> Leighton і Meyer. Читається швидко і містить усі важливі еквівалентності.

Розгляньмо кілька прикладів:

1. Щоб змоделювати `b1 -> b2`, використовуйте `model.add_implication(b1, b2)`.
   Альтернативно перепишіть як `NOT b1 OR b2` і використайте
   `model.add_bool_or(~b1, b2)`.
2. Щоб змоделювати `NOT (b1 AND b2)`, перепишіть як `NOT b1 OR NOT b2` і
   використайте `model.add_bool_or(~b1, ~b2)`.
3. Щоб змоделювати `NOT (b1 OR b2)`, перепишіть як `NOT b1 AND NOT b2` і
   використайте `model.add_bool_and(~b1, ~b2)`. (Ще ефективніше — безпосередньо
   підставити `b1` і `b2` як 0, адже вони не можуть бути істинними.)
4. Щоб змоделювати `(b1 AND b2) -> b3`, перепишіть як `NOT (b1 AND b2) OR b3`,
   що еквівалентно `(NOT b1 OR NOT b2) OR b3`. Тоді використайте
   `model.add_bool_or(~b1, ~b2, b3)`.
5. Щоб змоделювати `(b1 OR b2) -> b3`, перепишіть як `(b1 -> b3) AND (b2 -> b3)`,
   що еквівалентно `(NOT b1 OR b3) AND (NOT b2 OR b3)`. Тоді використайте:
   ```python
   model.add_bool_or(~b1, b3)
   model.add_bool_or(~b2, b3)
   ```
6. Щоб змоделювати `b1 -> (b2 OR b3)`, перепишіть як `NOT b1 OR (b2 OR b3)`,
   що еквівалентно `NOT b1 OR b2 OR b3`. Тоді використайте
   `model.add_bool_or(~b1, b2, b3)`.
7. Вирази виду `(b1 AND b2) OR (b3 AND b4)` можна переписати за дистрибутивними
   законами у
   `(b1 OR b3) AND (b1 OR b4) AND (b2 OR b3) AND (b2 OR b4)`. Однак для довших
   виразів це може призводити до експоненційного зростання кількості клауз.
   У таких випадках часто ефективніше вводити допоміжні змінні за допомогою
   [перетворення Тсейтіна](https://en.wikipedia.org/wiki/Tseytin_transformation).

> [!WARNING]
>
> Розуміння цих еквівалентностей допомагає моделювати складні логічні вирази і
> в деяких випадках покращувати продуктивність, замінюючи дорогі конструкції на
> простіші (короткі `add_bool_or` клаузи зазвичай найефективніші; довжина 2 —
> тривіальна для пропагації CP-SAT). Водночас CP-SAT виконує багато
> перетворень автоматично. Наприклад, `add_implication` напряму перетворюється
> у `add_bool_or` всередині
> [(див. вихідний код)](https://github.com/google/or-tools/blob/7ee639cf6981a9beeba908cf543a50f4ee7413ad/ortools/sat/cp_model.h#L807).
> Також існують складніші автоматичні перетворення, які точно не варто робити
> вручну. Див. розділ
> [Preprocessing in SAT Solving](https://cca.informatik.uni-freiburg.de/papers/BiereJarvisaloKiesl-SAT-Handbook-2021-Preprocessing-Chapter-Manuscript.pdf),
> якщо цікавлять деталі. Як завжди, спершу пріоритет — коректність, а вже потім
> продуктивність.

<a name="04-modelling-conditional-constraints"></a>

### Умовні обмеження (реїфікація)

У практичних застосуваннях часто виникають сценарії, коли умови визначають
застосування певних обмежень. Наприклад, «якщо ця умова істинна, тоді має
застосуватися конкретне обмеження» або «якщо обмеження порушене, встановити
штрафну змінну, що активує інше обмеження». Крім того, реальні обмеження іноді
можна обійти фінансовими або іншими поступками, наприклад орендувати дорожчу
вантажівку, щоб перевищити ліміт, або дозволити працівнику відпочити після
подвійної зміни.

> У програмуванні з обмеженнями **реїфікація** — це пов’язування булевої змінної
> з обмеженням, щоб зафіксувати його істинність і перетворити задоволення
> обмеження на змінну, яку можна використовувати в інших обмеженнях. Повна
> реїфікація пов’язує булеву змінну так, що вона `True`, якщо обмеження
> задоволене, і `False` — інакше, що дозволяє безпосередньо використовувати цю
> змінну в інших рішеннях або обмеженнях. Натомість половинна реїфікація або
> імпліковані обмеження встановлює односторонній зв’язок, коли `True` для
> булевої змінної означає, що обмеження має виконуватися, але `False` не дає
> інформації про задоволення обмеження. Це особливо корисно для вираження
> складної умовної логіки та моделювання сценаріїв, де треба явно обробляти лише
> задоволення, а не порушення обмеження.

Для ефективної роботи з такими умовними сценаріями CP-SAT має метод
`only_enforce_if` для лінійних і деяких булевих обмежень, який активує
обмеження лише за виконання певної умови. Цей метод зазвичай ефективніший за
класичні підходи на кшталт
[методу Big-M](https://en.wikipedia.org/wiki/Big_M_method) і спрощує модель,
усуваючи потребу підбирати значення Big-M.

```python
# Значення вантажу, який потрібно перевезти
load_value = model.new_int_var(0, 100, "load_value")

# ... деяка логіка, що визначає значення вантажу ...

# Змінні для вибору вантажівки
truck_a = model.new_bool_var("truck_a")
truck_b = model.new_bool_var("truck_b")
truck_c = model.new_bool_var("truck_c")

# Орендуємо лише одну вантажівку
model.add_at_most_one([truck_a, truck_b, truck_c])

# Залежно від вибору вантажівки, обмежуємо вантаж
model.add(load_value <= 50).only_enforce_if(truck_a)
model.add(load_value <= 80).only_enforce_if(truck_b)
model.add(load_value <= 100).only_enforce_if(truck_c)

# Додаткова логіка
driver_has_big_truck_license = model.new_bool_var("driver_has_big_truck_license")
driver_has_special_license = model.new_bool_var("driver_has_special_license")
# Лише водії з великою ліцензією або спеціальною можуть орендувати truck_c
model.add_bool_or(
  driver_has_big_truck_license, driver_has_special_license
).only_enforce_if(truck_c)

# Мінімізуємо вартість оренди
model.minimize(30 * truck_a + 40 * truck_b + 80 * truck_c)
```

У `only_enforce_if` можна використовувати заперечення:

```python
model.add(x + y == 10).only_enforce_if(~b1)
```

Також можна передати список булевих змінних, і тоді обмеження буде
застосовано лише тоді, коли всі змінні зі списку істинні.

```python
model.add(x + y == 10).only_enforce_if([b1, ~b2])  # застосувати лише якщо b1 І НЕ b2
```

> [!WARNING]
>
> Хоча `only_enforce_if` у CP-SAT часто ефективніший за аналогічні концепції в
> класичних MIP-розв’язувачах, він усе одно може суттєво впливати на
> продуктивність CP-SAT. Виконавши додаткові міркування, часто можна знайти
> ефективніший спосіб змоделювати задачу без використання `only_enforce_if`;
> див. попередній розділ про логічні обмеження. Оскільки `only_enforce_if`
> часто є більш природним способом моделювання, його варто застосувати для
> першого прототипу, а про «розумніші» способи подумати згодом.

<a name="04-modelling-absmaxmin"></a>

### Абсолютні значення та функції максимуму/мінімуму з цілочисельними змінними

Працюючи з цілочисельними змінними в CP-SAT, операції на кшталт абсолютного
значення, максимуму й мінімуму не можна напряму виразити за допомогою базових
Python-операцій `abs`, `max` чи `min`. Натомість потрібно використовувати
допоміжні змінні та спеціальні обмеження, що зв’язують ці змінні з потрібними
значеннями. Потім допоміжні змінні можна використовувати в інших обмеженнях,
представляючи бажаний підвираз.

```python
model = cp_model.CpModel()
x = model.new_int_var(-100, 100, "x")
y = model.new_int_var(-100, 100, "y")
z = model.new_int_var(-100, 100, "z")

# Допоміжна змінна для абсолютного значення x+z
abs_xz = model.new_int_var(0, 200, "|x+z|")
model.add_abs_equality(target=abs_xz, expr=x + z)

# Змінні для максимуму та мінімуму x, (y-1) і z
max_xyz = model.new_int_var(0, 100, "max(x, y-1, z)")
# Зміна в ortools 9.15: було add_max_equality(target=max_xyz, exprs=[x, y - 1, z])
model.add_max_equality(max_xyz, x, y - 1, z)

min_xyz = model.new_int_var(-100, 100, "min(x, y-1, z)")
# Зміна в ortools 9.15: було add_min_equality(target=min_xyz, exprs=[x, y - 1, z])
model.add_min_equality(min_xyz, x, y - 1, z)
```

Хоча деякі практики повідомляють, що ці методи ефективніші за аналоги в
класичних MIP-розв’язувачах, такі висновки здебільшого ґрунтуються на
емпіричних спостереженнях у конкретних сценаріях. Варто також пам’ятати, що
доволі часто ці обмеження можна замінити більш ефективними лінійними
обмеженнями. Ось приклад більш ефективного моделювання максимуму:

```python
x = model.new_int_var(0, 100, "x")
y = model.new_int_var(0, 100, "y")
z = model.new_int_var(0, 100, "z")

# Забезпечуємо, що max_xyz не менше максимуму з x, y, z
max_xyz = model.new_int_var(0, 100, "max_xyz")
model.add(max_xyz >= x)
model.add(max_xyz >= y)
model.add(max_xyz >= z)

# Мінімізуємо max_xyz, щоб він точно дорівнював максимуму
model.minimize(max_xyz)
```

Такий підхід використовує мінімізацію для «затягування» межі, завдяки чому
`max_xyz` точно відображає максимум із `x`, `y` і `z`. Використання лінійних
обмежень часто дає швидше розв’язання порівняно з `add_max_equality`. Подібні
техніки існують і для абсолютних значень, мінімумів та складних сценаріїв, де
пряме забезпечення рівності через цільову функцію неможливе.

<a name="04-modelling-multdivmod"></a>

### Множення, ділення і модуль

У практичних задачах може знадобитися виконувати складніші арифметичні операції,
ніж просто додавання. Наприклад, орендна вартість вантажівок може обчислюватися
як добуток кількості вантажівок, кількості днів і добової ставки. Тут перші два
множники — змінні, тож вираз квадратичний. Спроба напряму перемножити дві
змінні в CP-SAT дасть помилку, адже метод `add` приймає лише лінійні вирази.
Втім, CP-SAT підтримує множення, ділення та модульні операції. Як і з `abs`,
`max` і `min`, потрібно створити допоміжну змінну, що представляє результат.

```python
model = cp_model.CpModel()
x = model.new_int_var(-100, 100, "x")
y = model.new_int_var(-100, 100, "y")
z = model.new_int_var(-100, 100, "z")

xyz = model.new_int_var(-(100**3), 100**3, "x*y*z")
model.add_multiplication_equality(xyz, [x, y, z])  # xyz = x*y*z

model.add_modulo_equality(x, y, 3)  # x = y % 3
model.add_division_equality(x, y, z)  # x = y // z
```

Під час використання цих операцій ви часто переходите від лінійної до нелінійної
оптимізації, що загалом складніше. У випадку ділення важливо пам’ятати, що
операції цілочисельні: `5 // 2` дорівнює `2`, а не `2.5`.

Багато задач спочатку містять нелінійні вирази, які часто можна переформулювати
або апроксимувати лінійними. Це може зробити задачу легшою для розв’язання та
прискорити її. Хоча важливо моделювати задачу якомога ближче до реальності, не
менш важливо балансувати точність і розв’язуваність. Надто точна модель марна,
якщо розв’язувач не здатен ефективно її оптимізувати. Може бути корисно
застосовувати кілька фаз оптимізації — почати з простішої, менш точної моделі,
а потім поступово її уточнювати.

Деякі нелінійні вирази все ще можна ефективно обробляти, якщо вони опуклі.
Наприклад, обмеження другого порядку (second-order cone) можна розв’язувати
за поліноміальний час методами внутрішніх точок. Gurobi, наприклад, підтримує
такі обмеження нативно. CP-SAT має LP-пропагатор, але він спирається на метод
Dual Simplex, який для таких обмежень не підходить, і змушений використовувати
простішi методи. Аналогічно, більшість open-source MIP-розв’язувачів теж мають
труднощі з цими обмеженнями.

Складно визначити, чи зможе CP-SAT ефективно впоратися з нелінійними виразами,
або який розв’язувач найкраще підходить для вашої задачі. Нелінійні вирази
завжди складні, тому їх варто уникати, якщо можливо.

Ось один із улюблених прикладів моїх студентів про нелінійний вираз, якого
можна уникнути. Коли вони вперше знайомляться з нотацією
$\sum_{e \in E} cost(e)\cdot x_e$, і якщо термін залежить від комбінації двох
бінарних змінних, вони часто використовують квадратний вираз
$\sum_{e,e'\in E} concost(e, e')\cdot x_e\cdot x_{e'}$. Однак такі випадки
часто можна змоделювати лінійно через допоміжну змінну, уникнувши складнощів
нелінійного моделювання.

```python
model = cp_model.CpModel()

b1 = model.new_bool_var("b1")
b2 = model.new_bool_var("b2")

b1b2 = model.new_bool_var("b1b2")
model.add_implication(~b1, ~b1b2)
model.add_implication(~b2, ~b1b2)
model.add_bool_or(~b1, ~b2, b1b2)  # опційно, для штрафного терміна в цілі.
```

Існує багато інших випадків, коли нелінійні вирази можна спростити за допомогою
допоміжних змінних або перенесення нелінійних компонентів у константи. Однак
вивчення цих технік найкорисніше, коли ви стикаєтеся з конкретними труднощами
у ваших моделях.

Далі ми повернемося до нелінійних виразів і їхнього перетворення на кусочно-
лінійні апроксимації. Це дасть базове розуміння, необхідне для більш складних
сценаріїв моделювання.

<a name="04-modelling-alldifferent"></a>

### All Different

У багатьох задачах призначення та планування важливо, щоб усі змінні мали
різні значення. Наприклад, у призначенні частот жодні два передавачі в одній
зоні не повинні працювати на однаковій частоті, або в розкладі жодні дві задачі
не повинні займати один і той самий слот. Зазвичай цю вимогу можна змоделювати
квадратичною кількістю нерівностей (`!=`). Однак більш елегантне рішення —
використати обмеження `add_all_different`, яке безпосередньо забезпечує, що всі
змінні в списку мають унікальні значення. Це обмеження особливо корисне при
розв’язанні судоку чи
[задачі N-ферзів](https://developers.google.com/optimization/cp/queens).

```python
model = cp_model.CpModel()
x = model.new_int_var(-100, 100, "x")
y = model.new_int_var(-100, 100, "y")
z = model.new_int_var(-100, 100, "z")

# Додаємо обмеження all-different
model.add_all_different([x, y, z])

# Просунуте використання з перетвореннями
vars = [model.new_int_var(0, 10, f"v_{i}") for i in range(10)]
model.add_all_different([x + i for i, x in enumerate(vars)])
```

Використання `add_all_different` не лише спрощує моделювання, але й задіює
спеціалізований доменний пропагатор у CP-SAT, що підвищує ефективність порівняно
з багатьма `!=` обмеженнями. Однак якщо ви змішуєте `!=` з `add_all_different`,
будьте обережні: CP-SAT вимикає автоматичне виведення `add_all_different` з
груп `!=` обмежень, і це може погіршити продуктивність.

Для практичної демонстрації дивіться
[приклад задачі розфарбування графа](https://github.com/d-krupke/cpsat-primer/blob/main/examples/add_all_different.ipynb)
у репозиторії. Там `!=` обмеження розв’язали задачу за секунди, тоді як
`add_all_different` зайняло значно більше часу, що ілюструє важливість вибору
методу залежно від масштабу і складності задачі.

Альтернативно можна моделювати булевими змінними з обмеженнями типу
`add_at_most_one` або попарними запереченнями (`add_boolean_or(~b1, ~b2)`).
Такий підхід виграє від ефективної обробки булевої логіки в CP-SAT і дозволяє
легко інтегрувати додаткові обмеження або цілі, наприклад ліцензійні витрати
для певних частот. Хоча CP-SAT робить щось подібне всередині, він створює ці
конструкції ліниво й лише за потреби, тоді як явне моделювання в Python може
бути менш ефективним.

Вибір між цими методами — або іншим підходом — залежить від конкретних вимог
моделі й розуміння поведінки CP-SAT. Якщо сумніваєтеся, почніть із найбільш
інтуїтивного методу й коригуйте підхід на основі спостережень за
продуктивністю.

<a name="04-modelling-table"></a>

### Домени та комбінації

Під час оптимізації сценаріїв із наперед визначеними допустимими значеннями або
комбінаціями змінних — часто заданими у таблиці — корисно безпосередньо
обмежувати домен виразу або набору змінних.

Розгляньмо приклад оптимізації графіка змін для команди працівників, де є
таблиця допустимих комбінацій для кожної зміни:

| Працівник 1 | Працівник 2 | Працівник 3 | Працівник 4 |
| ---------- | ---------- | ---------- | ---------- |
| 1          | 0          | 1          | 0          |
| 0          | 1          | 1          | 0          |
| 1          | 0          | 0          | 1          |
| 0          | 1          | 0          | 1          |

У CP-SAT це можна ефективно змоделювати за допомогою `add_allowed_assignments`:

```python
model = cp_model.CpModel()
x_employee_1 = model.new_bool_var("x_employee_1")
x_employee_2 = model.new_bool_var("x_employee_2")
x_employee_3 = model.new_bool_var("x_employee_3")
x_employee_4 = model.new_bool_var("x_employee_4")

# Визначаємо дозволені призначення
allowed_assignments = [
    [1, 0, 1, 0],
    [0, 1, 1, 0],
    [1, 0, 0, 1],
    [0, 1, 0, 1],
]

model.add_allowed_assignments(
    [x_employee_1, x_employee_2, x_employee_3, x_employee_4], allowed_assignments
)
```

Альтернативно, заборонені комбінації можна вказати через
`add_forbidden_assignments`:

```python
prohibit_assignments = [
    [1, 0, 1, 0],
    [0, 1, 1, 0],
    [1, 0, 0, 1],
    [0, 1, 0, 1],
]
model.add_forbidden_assignments(
    [x_employee_1, x_employee_2, x_employee_3, x_employee_4], prohibit_assignments
)
```

Користь `add_allowed_assignments` найбільш помітна тоді, коли його
поєднують з іншими обмеженнями в моделі, а не коли він охоплює всі змінні. Якщо
таблиця охоплювала б усі змінні, теоретично можна було б просто перебрати рядки
та знайти найкраще рішення без складних оптимізаційних технік. Однак
розгляньмо сценарій, де обмеження інтегруються між різними змінами:

```python
NUM_SHIFTS = 7

model = cp_model.CpModel()
x_employee_1 = [model.new_bool_var(f"x_employee_1_{i}") for i in range(NUM_SHIFTS)]
x_employee_2 = [model.new_bool_var(f"x_employee_2_{i}") for i in range(NUM_SHIFTS)]
x_employee_3 = [model.new_bool_var(f"x_employee_3_{i}") for i in range(NUM_SHIFTS)]
x_employee_4 = [model.new_bool_var(f"x_employee_4_{i}") for i in range(NUM_SHIFTS)]

for i in range(NUM_SHIFTS):
    model.add_allowed_assignments(
        [x_employee_1[i], x_employee_2[i], x_employee_3[i], x_employee_4[i]],
        allowed_assignments,
    )

# ... деякі додаткові обмеження та цілі, що пов’язують дні ...
# ... якби дні були незалежні, ви б розв’язували кожен день окремо ...
```

Метод `add_allowed_assignments` у CP-SAT дозволяє безпосередньо включати
конкретні допустимі комбінації в модель оптимізації, гарантує, що в просторі
розв’язків розглядаються лише дозволені конфігурації. Метод фактично
«зашиває» ці конфігурації, спрощуючи модель шляхом попереднього визначення
допустимих комбінацій змінних, подібно до правил для змін персоналу чи
розподілу ресурсів.

> [!NOTE]
>
> Жорстке кодування конкретних комбінацій у моделі — це попередній крок до
> просунутих технік декомпозиції на кшталт декомпозиції Данцига–Вулфа. У цьому
> методі складну оптимізаційну задачу спрощують, замінюючи групу корельованих
> змінних складовими змінними. Така складова змінна представляє розв’язок
> підзадачі. Оптимізація цих складових змінних у майстер-задачі істотно зменшує
> складність моделі та підвищує ефективність розв’язання великомасштабних задач.

Схожий метод для керування лінійними виразами (а не прямими призначеннями) —
`add_linear_expression_in_domain`. Припустимо, що певний лінійний вираз,
\(10x + 5y\), має дорівнювати 20, 50 або 100:

```python
model = cp_model.CpModel()
x = model.new_int_var(-100, 100, "x")
y = model.new_int_var(-100, 100, "y")

domain = cp_model.Domain.from_values([20, 50, 100])
model.add_linear_expression_in_domain(10 * x + 5 * y, domain)
```

> [!WARNING]
>
> Переконайтеся, що обчислення коректні, особливо при роботі з цілими числами,
> щоб не створити недопустиму або надто жорстку модель. Розгляньте варіант
> використання допоміжної змінної з обмеженим доменом і м’якшими обмеженнями
> (`<=`, `>=`), щоб отримати більш гнучку постановку.

<a name="04-modelling-element"></a> <a name="04-modelling-array"></a>

### Обмеження елементів/масивів

Перш ніж перейти до спеціалізованих обмежень, розгляньмо останнє загальне.
Обмеження елемента дозволяє звертатися до значення змінної (або з ortools 9.12 —
до лінійного виразу) в масиві, використовуючи іншу змінну як індекс. Звернення
до елемента масиву з константним індексом тривіальне; натомість індекс як
змінна додає складності. Це обмеження також можна використати, щоб змусити
змінну дорівнювати значенню в певній позиції масиву.

```python
model = cp_model.CpModel()
x = model.new_int_var(-100, 100, "x")
y = model.new_int_var(-100, 100, "y")
z = model.new_int_var(-100, 100, "z")
var_array = [x, y, z]

# Змінна для індексу та змінна для значення за цим індексом.
index_var = model.new_int_var(0, len(var_array) - 1, "index")
value_at_index_var = model.new_int_var(-100, 100, "value_at_index")

# Застосовуємо обмеження елемента, щоб зв’язати індекс і значення.
model.add_element(expressions=var_array, index=index_var, target=value_at_index_var)
# УВАГА: до ortools 9.12 було `variables=` замість `expressions=`.
```

Приклади допустимих призначень:

| `x` | `y` | `z` | `index_var` | `value_at_index` |
| --- | --- | --- | ----------- | ---------------- |
| 3   | 4   | 5   | 0           | 3                |
| 3   | 4   | 5   | 1           | 4                |
| 3   | 4   | 5   | 2           | 5                |
| 7   | 3   | 4   | 0           | 7                |

Наступне обмеження нагадує стабільне зіставлення у вигляді масивів. Для двох
масивів змінних $v$ і $w$ однакової довжини $|v|$ воно накладає бієктивний
зв’язок: $v[i]=j \Leftrightarrow w[j]=i$ для всіх
$i,j \in 0,\ldots,|v|-1$. Це обмеження обмежує значення змінних до
$0,\ldots, |v|-1$.

```python
model = cp_model.CpModel()
v = [model.new_int_var(0, 5, f"v_{i}") for i in range(6)]
w = [model.new_int_var(0, 5, f"w_{i}") for i in range(6)]

model.add_inverse(v, w)
```

Приклади допустимих призначень:

| масив | 0   | 1   | 2   | 3   | 4   | 5   |
| ----- | --- | --- | --- | --- | --- | --- |
| v     | 0   | 1   | 2   | 3   | 4   | 5   |
| w     | 0   | 1   | 2   | 3   | 4   | 5   |

| масив | 0   | 1   | 2   | 3   | 4   | 5   |
| ----- | --- | --- | --- | --- | --- | --- |
| v     | 1   | 2   | 3   | 4   | 5   | 0   |
| w     | 5   | 0   | 1   | 2   | 3   | 4   |

| масив | 0   | 1   | 2   | 3   | 4   | 5   |
| ----- | --- | --- | --- | --- | --- | --- |
| v     | 1   | 0   | 3   | 5   | 2   | 4   |
| w     | 1   | 0   | 4   | 2   | 5   | 3   |

| ![Example Matching](https://raw.githubusercontent.com/d-krupke/cpsat-primer/main/images/inverse.png) |
| :--------------------------------------------------------------------------------------------------: |
|               Візуалізація стабільного зіставлення, яке задає обмеження `add_inverse`.               |

> [!WARNING]
>
> Зазвичай я не рекомендую використовувати `add_element` і `add_inverse`
> обмеження. Хоча CP-SAT може мати ефективні техніки пропагації для них, ці
> обмеження можуть виглядати неприродними й складними. Часто простіше
> змоделювати стабільне зіставлення через бінарні змінні $x_{ij}$, які
> позначають, чи зіставлено $v_i$ з $w_j$, і застосувати `add_exactly_one` для
> кожної вершини, щоб забезпечити унікальні відповідності. Якщо ваша модель має
> враховувати певні атрибути або витрати, пов’язані зі з’єднаннями, бінарні
> змінні необхідні. Покладатися лише на індекси означає додаткову логіку для
> коректного представлення. Крім того, використовуйте небінарні змінні лише
> тоді, коли числове значення справді має семантичний зміст, який не можна
> просто переіндексувати.

<!-- This file was generated by the `build.py` script. Do not edit it manually. -->
<!-- ./chapters/04B_advanced_modelling.md -->
<a name="04B-advanced-modelling"></a>

## Просунуте моделювання


Після знайомства з базовими елементами CP-SAT у цьому розділі ми перейдемо до
складніших обмежень. Вони вже орієнтовані на конкретні задачі — наприклад,
маршрутизацію чи планування — але всередині свого домену дуже універсальні й
потужні. Водночас вони потребують більш детального пояснення щодо правильного
використання.

- [Обмеження турів](#04-modelling-circuit): `add_circuit`,
  `add_multiple_circuit`, `add_reservoir_constraint_with_active`
- [Інтервали](#04-modelling-intervals): `new_interval_var`,
  `new_interval_var_series`, `new_fixed_size_interval_var`,
  `new_optional_interval_var`, `new_optional_interval_var_series`,
  `new_optional_fixed_size_interval_var`,
  `new_optional_fixed_size_interval_var_series`,
  `add_no_overlap`,`add_no_overlap_2d`, `add_cumulative`
- [Обмеження автомата](#04-modelling-automaton): `add_automaton`
- [Обмеження резервуара](#04-modelling-reservoir): `add_reservoir_constraint`
- [Кусково-лінійні обмеження](#04-modelling-pwl): офіційно не частина CP-SAT,
  але ми надаємо безкоштовний код для копіювання.

<a name="04-modelling-circuit"></a>

### Обмеження circuit/турів

Маршрути й тури важливі для розв’язання оптимізаційних задач у багатьох сферах,
далеко за межами класичної маршрутизації. Наприклад, у секвенуванні ДНК
оптимізація порядку збирання фрагментів критична, а в наукових дослідженнях
методичне впорядкування переналаштувань експериментів може суттєво зменшити
операційні витрати та простої. Обмеження `add_circuit` і `add_multiple_circuit`
в CP-SAT дозволяють легко моделювати різні сценарії. Вони виходять за межі
класичної
[задачі комівояжера (TSP)](https://en.wikipedia.org/wiki/Travelling_salesman_problem),
дозволяючи розв’язки, де не потрібно відвідувати всі вершини, а також
підтримуючи кілька неперетинних підтурів. Така адаптивність робить їх
неоціненними для широкого кола практичних задач, де порядок і організація
операцій критично впливають на ефективність і результат.

|                         ![TSP Example](https://raw.githubusercontent.com/d-krupke/cpsat-primer/main/images/optimal_tsp.png)                         |
| :-------------------------------------------------------------------------------------------------------------------------------------------------: |
| Задача комівояжера (TSP) шукає найкоротший маршрут, який відвідує кожну вершину рівно один раз і повертається до стартової вершини. |

Задача комівояжера — одна з найвідоміших і найкраще досліджених комбінаторних
оптимізаційних задач. Це класичний приклад задачі, яку легко зрозуміти,
поширеної на практиці, але складної для розв’язання. Вона також займає особливе
місце в історії оптимізації, адже багато загальних технік спершу були розроблені
саме для TSP. Якщо ще не робили цього, рекомендую переглянути
[цю доповідь Bill Cook](https://www.youtube.com/watch?v=5VjphFYQKj8) або навіть
прочитати книгу
[In Pursuit of the Traveling Salesman](https://press.princeton.edu/books/paperback/9780691163529/in-pursuit-of-the-traveling-salesman).

> [!TIP]
>
> Якщо ваша задача — саме TSP, можливо, вам буде корисним
> [розв’язувач Concorde](https://www.math.uwaterloo.ca/tsp/concorde.html).
> Для задач, близьких до TSP, більш відповідним може бути MIP-розв’язувач,
> оскільки багато варіантів TSP дають сильні лінійні релаксації, які MIP
> ефективно використовують. Також зверніть увагу на
> [OR-Tools Routing](https://developers.google.com/optimization/routing), якщо
> маршрутизація — значна частина вашої задачі. Але коли варіанти TSP — лише
> компонент більшої задачі, CP-SAT із `add_circuit` або `add_multiple_circuit`
> може бути дуже корисним.

|                                                                                                                                                        ![TSP BnB Example](https://raw.githubusercontent.com/d-krupke/cpsat-primer/main/images/tsp_bnb_improved.png)                                                                                                                                                         |
| :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: |
| Цей приклад показує, чому MIP-розв’язувачі такі сильні для TSP. Лінійна релаксація (вгорі) вже дуже близька до оптимального розв’язку. Розгалужуючись, тобто пробуючи 0 і 1, лише для двох дробових змінних, ми не лише знаходимо оптимальний розв’язок, а й доводимо оптимальність. Приклад згенеровано за допомогою [DIY TSP Solver](https://www.math.uwaterloo.ca/tsp/D3/bootQ.html). |

#### `add_circuit`

Обмеження `add_circuit` використовується для розв’язання задач про цикли у
орієнтованих графах і навіть дозволяє петлі. Воно приймає список трійок
`(u,v,var)`, де `u` і `v` — початкова і кінцева вершини, а `var` — булева
змінна, яка показує, чи включене ребро в розв’язок. Обмеження гарантує, що
ребра з `True` формують один цикл, який відвідує кожну вершину рівно один раз,
за винятком вершин із петлею, встановленою в `True`. Індекси вершин мають
починатися з 0 і не можуть мати пропусків, інакше це призведе до ізоляції та
недопустимості циклу.

Ось приклад використання CP-SAT для орієнтованої задачі комівояжера:

```python
from ortools.sat.python import cp_model

# Орієнтований граф із вагами ребер
dgraph = {(0, 1): 13, (1, 0): 17, ...(2, 3): 27}

# Ініціалізуємо модель CP-SAT
model = cp_model.CpModel()

# Булеві змінні для кожного ребра
edge_vars = {(u, v): model.new_bool_var(f"e_{u}_{v}") for (u, v) in dgraph.keys()}

# Обмеження circuit для одного туру
model.add_circuit([(u, v, var) for (u, v), var in edge_vars.items()])

# Цільова функція — мінімізувати сумарну вартість
model.minimize(sum(dgraph[(u, v)] * x for (u, v), x in edge_vars.items()))

# Розв’язуємо модель
solver = cp_model.CpSolver()
status = solver.solve(model)
if status in (cp_model.OPTIMAL, cp_model.FEASIBLE):
    tour = [(u, v) for (u, v), x in edge_vars.items() if solver.value(x)]
    print("Tour:", tour)

# Output: [(0, 1), (2, 0), (3, 2), (1, 3)], тобто 0 -> 1 -> 3 -> 2 -> 0
```

Це обмеження можна адаптувати для шляхів, додавши віртуальне ребро, яке
замикає шлях у цикл, наприклад `(3, 0, 1)` для шляху від вершини 0 до вершини 3.

#### Креативне використання `add_circuit`

`add_circuit` можна творчо адаптувати для різних споріднених задач. Хоча для
задачі найкоротшого шляху існують ефективніші алгоритми, покажімо, як
адаптувати `add_circuit` в освітніх цілях.

```python
from ortools.sat.python import cp_model

# Задаємо зважений орієнтований граф із вартістю ребер
dgraph = {(0, 1): 13, (1, 0): 17, ...(2, 3): 27}

source_vertex = 0
target_vertex = 3

# Додаємо нульові петлі для вершин, які не є джерелом або ціллю
for v in [1, 2]:
    dgraph[(v, v)] = 0

# Ініціалізуємо модель CP-SAT і змінні
model = cp_model.CpModel()
edge_vars = {(u, v): model.new_bool_var(f"e_{u}_{v}") for (u, v) in dgraph}

# Визначаємо цикл із псевдоребром від цілі до джерела
circuit = [(u, v, var) for (u, v), var in edge_vars.items()] + [
    (target_vertex, source_vertex, 1)
]
model.add_circuit(circuit)

# Мінімізуємо сумарну вартість
model.minimize(sum(dgraph[(u, v)] * x for (u, v), x in edge_vars.items()))

# Розв’язуємо та отримуємо шлях
solver = cp_model.CpSolver()
status = solver.solve(model)
if status in (cp_model.OPTIMAL, cp_model.FEASIBLE):
    path = [(u, v) for (u, v), x in edge_vars.items() if solver.value(x) and u != v]
    print("Path:", path)

# Output: [(0, 1), (1, 3)], тобто 0 -> 1 -> 3
```

Цей підхід демонструє гнучкість `add_circuit` для різних задач турів і шляхів.
Ось ще приклад:

- [Budget constrained tours](https://github.com/d-krupke/cpsat-primer/blob/main/examples/add_circuit_budget.py):
  оптимізація найбільшого можливого туру в межах заданого бюджету.

#### `add_multiple_circuit`

Для задач із кількома поїздками з депо можна використати `add_multiple_circuit`.
Це обмеження схоже на `add_circuit`, але явно дозволяє відвідувати депо кілька
разів. Як і `add_circuit`, `add_multiple_circuit` підтримує опційні вершини
через петлі.

Це особливо корисно для задач маршрутизації транспорту (VRP), де кілька турів
починаються з одного депо. Зазвичай VRP має додаткові обмеження, бо інакше
повернення в депо без потреби є неоптимальним. Альтернативою є дублювання графа
та застосування `add_circuit` на кожній копії, але `add_multiple_circuit`
дозволяє уникнути копіювання графа і створення кількох наборів змінних, залишаючи
єдиний набір змінних та ребер.

Недоліком методу є те, що деякі обмеження, наприклад заборона відвідувати дві
вершини в одному турі, стають складнішими, адже всі тури спільно використовують
змінні. Водночас багато обмежень усе ще можна ефективно моделювати, наприклад
обмеження місткості в задачі CVRP. CVRP — класична задача в операційному
дослідженні та логістиці: потрібно знайти найкоротший набір маршрутів для
флоту однакових транспортів, що стартують і завершують у єдиному депо (це може
бути і той самий транспорт, що робить кілька поїздок). Кожного клієнта треба
відвідати рівно один раз, з обмеженням, що сумарний попит на кожному турі не
перевищує місткість транспортного засобу.

Нижче наведено приклад реалізації CVRP із `add_multiple_circuit` і додатковою
змінною для відстеження місткості на кожній вершині.

```python
from typing import Hashable
import networkx as nx
from ortools.sat.python import cp_model


class CvrpMultiCircuit:
    """CVRP через multi-circuit обмеження CP-SAT."""

    def __init__(
        self,
        graph: nx.Graph,
        depot: Hashable,
        capacity: int,
        demand_label: str = "demand",
        model: cp_model.CpModel | None = None,
    ):
        self.graph, self.depot = graph, depot
        self.model = model or cp_model.CpModel()
        self.capacity = capacity
        self.demand_label = demand_label

        # Список вершин з депо на початку
        self.vertices = [depot] + [v for v in graph.nodes() if v != depot]
        self.index = {v: i for i, v in enumerate(self.vertices)}

        # Булеві змінні дуг для обох напрямків
        self.arc_vars = {
            (i, j): self.model.new_bool_var(f"arc_{i}_{j}")
            for u, v in graph.edges
            for i, j in ((self.index[u], self.index[v]), (self.index[v], self.index[u]))
        }
        arcs = [(i, j, var) for (i, j), var in self.arc_vars.items()]

        # Обмеження multi-circuit
        self.model.add_multiple_circuit(arcs)

        # Змінні місткості та обмеження
        self.cap_vars = [
            self.model.new_int_var(0, capacity, f"cap_{i}")
            for i in range(len(self.vertices))
        ]
        for i, j, var in arcs:
            if j == 0:
                continue
            demand = graph.nodes[self.vertices[j]].get(demand_label, 0)
            self.model.add(
                self.cap_vars[j] >= self.cap_vars[i] + demand
            ).only_enforce_if(var)

    def is_arc_used(self, u, v) -> cp_model.BoolVarT:
        return self.arc_vars[(self.index[u], self.index[v])]

    def weight(self, label: str = "weight") -> cp_model.LinearExprT:
        return sum(
            var * self.graph[self.vertices[i]][self.vertices[j]][label]
            for (i, j), var in self.arc_vars.items()
        )

    def minimize_weight(self, label: str = "weight"):
        self.model.minimize(self.weight(label=label))

    def extract_tours(self, solver: cp_model.CpSolver) -> list[list]:
        # Будуємо орієнтований граф обраних дуг
        dg = nx.DiGraph(
            [
                (self.vertices[i], self.vertices[j])
                for (i, j), var in self.arc_vars.items()
                if solver.value(var)
            ]
        )

        # Ейлерів цикл і розбиття за депо
        euler = nx.eulerian_circuit(dg, source=self.depot)
        tours, curr = [], [self.depot]
        for u, v in euler:
            curr.append(v)
            if v == self.depot:
                tours.append(curr)
                curr = [self.depot]
        if len(curr) > 1:
            tours.append(curr)
        return tours
```

|                                                                                                                 ![CVRP Example](https://raw.githubusercontent.com/d-krupke/cpsat-primer/main/images/cvrp_example.png)                                                                                                                  |
| :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: |
| Задача CVRP шукає найкоротші маршрути, що відвідують кожну вершину рівно один раз і повертаються до стартової вершини. Депо є початком і кінцем кожного туру. Граф у прикладі зважений приблизною геометричною відстанню, а місткість транспортного засобу встановлена на 15. |

> [!WARNING]
>
> Хоча `add_multiple_circuit` дозволяє додаткові LNS-стратегії та може
> покращувати нижні межі, стандартна формулювання Miller-Tucker-Zemlin (MTZ)
> іноді ефективніша для CVRP. Обидва підходи кращі за використання `add_circuit`
> на кількох копіях графа. Реалізації всіх трьох підходів моделювання CVRP є
> [тут](https://github.com/d-krupke/cpsat-primer/blob/main/examples/cvrp/).

#### Продуктивність `add_circuit` для TSP

Таблиця нижче показує продуктивність CP-SAT на різних інстансах TSPLIB із
використанням `add_circuit` та лімітом 90 секунд. Продуктивність можна вважати
достатньою, але MIP-розв’язувач легко її перевершує.

| Instance | # vertices | runtime | lower bound | objective | opt. gap |
| :------- | ---------: | ------: | ----------: | --------: | -------: |
| att48    |         48 |    0.47 |       33522 |     33522 |        0 |
| eil51    |         51 |    0.69 |         426 |       426 |        0 |
| st70     |         70 |     0.8 |         675 |       675 |        0 |
| eil76    |         76 |    2.49 |         538 |       538 |        0 |
| pr76     |         76 |   54.36 |      108159 |    108159 |        0 |
| kroD100  |        100 |    9.72 |       21294 |     21294 |        0 |
| kroC100  |        100 |    5.57 |       20749 |     20749 |        0 |
| kroB100  |        100 |     6.2 |       22141 |     22141 |        0 |
| kroE100  |        100 |    9.06 |       22049 |     22068 |        0 |
| kroA100  |        100 |    8.41 |       21282 |     21282 |        0 |
| eil101   |        101 |    2.24 |         629 |       629 |        0 |
| lin105   |        105 |    1.37 |       14379 |     14379 |        0 |
| pr107    |        107 |     1.2 |       44303 |     44303 |        0 |
| pr124    |        124 |    33.8 |       59009 |     59030 |        0 |
| pr136    |        136 |   35.98 |       96767 |     96861 |        0 |
| pr144    |        144 |   21.27 |       58534 |     58571 |        0 |
| kroB150  |        150 |   58.44 |       26130 |     26130 |        0 |
| kroA150  |        150 |   90.94 |       26498 |     26977 |       2% |
| pr152    |        152 |   15.28 |       73682 |     73682 |        0 |
| kroA200  |        200 |   90.99 |       29209 |     29459 |       1% |
| kroB200  |        200 |   31.69 |       29437 |     29437 |        0 |
| pr226    |        226 |   74.61 |       80369 |     80369 |        0 |
| gil262   |        262 |   91.58 |        2365 |      2416 |       2% |
| pr264    |        264 |   92.03 |       49121 |     49512 |       1% |
| pr299    |        299 |   92.18 |       47709 |     49217 |       3% |
| linhp318 |        318 |   92.45 |       41915 |     52032 |      19% |
| lin318   |        318 |   92.43 |       41915 |     52025 |      19% |
| pr439    |        439 |   94.22 |      105610 |    163452 |      35% |

Існують дві основні формулювання для моделювання TSP без `add_circuit`:
[формулювання Данцига—Фалкерсона—Джонсона (DFJ)](https://en.wikipedia.org/wiki/Travelling_salesman_problem#Dantzig%E2%80%93Fulkerson%E2%80%93Johnson_formulation)
та
[формулювання Міллера—Такера—Земліна (MTZ)](https://en.wikipedia.org/wiki/Travelling_salesman_problem#Miller%E2%80%93Tucker%E2%80%93Zemlin_formulation[21]).
DFJ загалом ефективніше через сильнішу лінійну релаксацію. Однак воно потребує
«ледачих» обмежень, які CP-SAT не підтримує. Без них продуктивність DFJ у CP-SAT
порівнянна з MTZ. Попри це, обидва формулювання значно гірші за `add_circuit`.
Це підкреслює перевагу `add_circuit` для турів і шляхів. На відміну від
користувача, `add_circuit` може використовувати lazy constraints всередині,
що дає суттєву перевагу.

<a name="04-modelling-intervals"></a>

### Планування і пакування з інтервалами

Особливий тип змінних — інтервальні змінні, що дозволяють моделювати інтервали,
тобто відрізок певної довжини зі стартом і кінцем. Існують інтервали фіксованої
довжини, змінної довжини та опційні інтервали для різних сценаріїв. Вони
особливо корисні в поєднанні з обмеженнями відсутності перекриття у 1D та 2D.
Це підходить для задач геометричного пакування, планування й інших задач, де
потрібно уникати накладень інтервалів. Ці змінні особливі тим, що фактично це
не змінна, а контейнер, який обмежує окремо задані змінні старту, довжини й
кінця.

Є чотири типи інтервальних змінних: `new_interval_var`,
`new_fixed_size_interval_var`, `new_optional_interval_var` та
`new_optional_fixed_size_interval_var`. `new_optional_interval_var` є
найвиразнішим, але й найдорожчим, тоді як `new_fixed_size_interval_var` —
найпростішим і найефективнішим. Усі типи приймають `start=` змінну. Інтервали
з `fixed_size` вимагають константний `size=`, що задає довжину. Інакше `size=`
може бути змінною в парі з `end=`, що ускладнює розв’язання. Інтервали з
`optional` мають аргумент `is_present=`, булеву змінну, що показує, чи інтервал
присутній. Обмеження no-overlap застосовуються лише до присутніх інтервалів,
що дозволяє моделювати задачі з кількома ресурсами чи опційними задачами. Замість
цілочисельної змінної всі аргументи можуть приймати афінні вирази, наприклад
`start=5*start_var+3`.

```python
model = cp_model.CpModel()

start_var = model.new_int_var(0, 100, "start")
length_var = model.new_int_var(10, 20, "length")
end_var = model.new_int_var(0, 100, "end")
is_present_var = model.new_bool_var("is_present")

# інтервал із довжиною, яку можна змінювати (дорожчий)
flexible_interval = model.new_interval_var(
    start=start_var, size=length_var, end=end_var, name="flexible_interval"
)

# інтервал фіксованої довжини
fixed_interval = model.new_fixed_size_interval_var(
    start=start_var,
    size=10,  # має бути константою
    name="fixed_interval",
)

# опційний інтервал зі змінною довжиною (найдорожчий)
optional_interval = model.new_optional_interval_var(
    start=start_var,
    size=length_var,
    end=end_var,
    is_present=is_present_var,
    name="optional_interval",
)

# опційний інтервал фіксованої довжини
optional_fixed_interval = model.new_optional_fixed_size_interval_var(
    start=start_var,
    size=10,  # має бути константою
    is_present=is_present_var,
    name="optional_fixed_interval",
)
```

Ці інтервальні змінні самі по собі не корисні, адже те саме можна зробити
простими лінійними обмеженнями. Проте CP-SAT має спеціальні обмеження для
інтервалів, які важко моделювати вручну і які значно ефективніші.

CP-SAT пропонує три обмеження для інтервалів:
`add_no_overlap`, `add_no_overlap_2d`, `add_cumulative`. `add_no_overlap`
забороняє перекриття в одному вимірі (наприклад, час). `add_no_overlap_2d`
забороняє перекриття у двох вимірах (наприклад, пакування прямокутників).
`add_cumulative` моделює ресурсне обмеження, де сума попитів перекривних
інтервалів не перевищує місткість ресурсу.

`add_no_overlap` приймає список (опційних) інтервалів і гарантує, що жодні два
присутні інтервали не перекриваються.

```python
model.add_no_overlap(
    interval_vars=[
        flexible_interval,
        fixed_interval,
        optional_interval,
        optional_fixed_interval,
        # ...
    ]
)
```

`add_no_overlap_2d` приймає два списки (опційних) інтервалів і забезпечує, що для
кожної пари `i` та `j` інтервали `x_intervals[i]` і `x_intervals[j]` або
`y_intervals[i]` і `y_intervals[j]` не перекриваються. Отже, обидва списки мають
мати однакову довжину, а `x_intervals[i]` і `y_intervals[i]` вважаються парою.
Якщо `x_intervals[i]` або `y_intervals[i]` опційні, то весь об’єкт є опційним.

```python
model.add_no_overlap_2d(
    x_intervals=[
        flexible_interval,
        fixed_interval,
        optional_interval,
        optional_fixed_interval,
        # ...
    ],
    y_intervals=[
        flexible_interval,
        fixed_interval,
        optional_interval,
        optional_fixed_interval,
        # ...
    ],
)
```

`add_cumulative` використовується для ресурсних обмежень, де сума попитів
перекривних інтервалів не може перевищувати місткість ресурсу. Наприклад,
планування енергоємних машин, коли сумарне споживання не повинно перевищувати
потужність мережі. Обмеження приймає список інтервалів, список попитів і змінну
місткості. Попити мають ту саму довжину, що й інтервали, бо попит зіставляється
за індексом. Оскільки місткість і попити можуть бути змінними (або афінними
виразами), можна моделювати досить складні ресурсні обмеження.

```python
demand_vars = [model.new_int_var(1, 10, f"demand_{i}") for i in range(4)]
capacity_var = model.new_int_var(1, 100, "capacity")
model.add_cumulative(
    intervals=[
        flexible_interval,
        fixed_interval,
        optional_interval,
        optional_fixed_interval,
    ],
    demands=demand_vars,
    capacity=capacity_var,
)
```

> [!WARNING]
>
> Не переходьте одразу до інтервалів у задачах планування. Інтервали корисні,
> коли у вас є більш-менш неперервний час чи простір. Якщо задача більш
> дискретна, наприклад має фіксовану кількість слотів, часто ефективніше
> змоделювати її простими булевими змінними та обмеженнями. Особливо якщо можна
> використати доменні знання, щоб знайти кластери зустрічей, які не можуть
> перекриватися, це може бути значно ефективніше. Якщо планування домінують
> переходи, ваша задача може бути радше маршрутизаційною, і тоді більше підходить
> `add_circuit`.

Розгляньмо кілька прикладів використання цих обмежень.

#### Планування конференц-залу з інтервалами

Припустимо, у нас є конференц-зал і треба запланувати кілька зустрічей. Кожна
зустріч має фіксовану тривалість і діапазон можливих стартів. Слоти — по 5
хвилин від 8:00 до 18:00. Отже, є $10 \times 12 = 120$ слотів, і ми можемо
використовувати просту цілочисельну змінну для старту. Для фіксованих тривалостей
зручно використовувати `new_fixed_size_interval_var`. `add_no_overlap` гарантує
відсутність перекриття, а домени стартових змінних задають можливі часові вікна.

Для обробки даних введемо `namedtuple` для зустрічей і дві функції для
перетворення часу в індекс і назад.

```python
# Конвертуємо час у індекс і назад
def t_to_idx(hour, minute):
    return (hour - 8) * 12 + minute // 5


def idx_to_t(time_idx):
    hour = 8 + time_idx // 12
    minute = (time_idx % 12) * 5
    return f"{hour}:{minute:02d}"


# Опис зустрічі
MeetingInfo = namedtuple("MeetingInfo", ["start_times", "duration"])
```

Створімо кілька зустрічей.

```python
# Опис зустрічей
meetings = {
    "meeting_a": MeetingInfo(
        start_times=[
            [t_to_idx(8, 0), t_to_idx(12, 0)],
            [t_to_idx(16, 0), t_to_idx(17, 0)],
        ],
        duration=120 // 5,  # 2 години
    ),
    "meeting_b": MeetingInfo(
        start_times=[
            [t_to_idx(10, 0), t_to_idx(12, 0)],
        ],
        duration=30 // 5,  # 30 хвилин
    ),
    "meeting_c": MeetingInfo(
        start_times=[
            [t_to_idx(16, 0), t_to_idx(17, 0)],
        ],
        duration=15 // 5,  # 15 хвилин
    ),
    "meeting_d": MeetingInfo(
        start_times=[
            [t_to_idx(8, 0), t_to_idx(10, 0)],
            [t_to_idx(12, 0), t_to_idx(14, 0)],
        ],
        duration=60 // 5,  # 1 година
    ),
}
```

Тепер створимо модель CP-SAT і додамо інтервали та обмеження.

```python
# Створюємо модель CP-SAT
model = cp_model.CpModel()

# Створюємо змінні старту для кожної зустрічі
start_time_vars = {
    meeting_name: model.new_int_var_from_domain(
        cp_model.Domain.from_intervals(meeting_info.start_times),
        f"start_{meeting_name}",
    )
    for meeting_name, meeting_info in meetings.items()
}

# Створюємо інтервали для кожної зустрічі
interval_vars = {
    meeting_name: model.new_fixed_size_interval_var(
        start=start_time_vars[meeting_name],
        size=meeting_info.duration,
        name=f"interval_{meeting_name}",
    )
    for meeting_name, meeting_info in meetings.items()
}

# Гарантуємо, що зустрічі не перекриваються
model.add_no_overlap(list(interval_vars.values()))
```

І нарешті, розв’яжемо модель і витягнемо розклад.

```python
# Розв’язуємо модель
solver = cp_model.CpSolver()
status = solver.solve(model)

# Витягуємо та друкуємо розклад
scheduled_times = {}
if status in (cp_model.OPTIMAL, cp_model.FEASIBLE):
    for meeting_name in meetings:
        start_time = solver.value(start_time_vars[meeting_name])
        scheduled_times[meeting_name] = start_time
        print(f"{meeting_name} starts at {idx_to_t(start_time)}")
else:
    print("No feasible solution found.")
```

Трохи магії з matplotlib — і можемо візуалізувати розклад.

|                ![Schedule](https://raw.githubusercontent.com/d-krupke/cpsat-primer/main/images/scheduling_example.png)                |
| :-----------------------------------------------------------------------------------------------------------------------------------: |
| Можливий неперекривний розклад для цього прикладу. Інстанс простий, але можна спробувати додати ще зустрічей. |

#### Планування для кількох ресурсів з опційними інтервалами

Тепер уявімо, що у нас кілька ресурсів, наприклад кілька конференц-залів, і ми
потрібно запланувати зустрічі так, щоб у межах одного залу вони не перекривалися.
Це можна змоделювати опційними інтервалами, які існують лише якщо зустріч
призначено в конкретний зал. `add_no_overlap` гарантує відсутність перекриття
зустрічей у кожному залі.

Оскільки у нас два зали, зробимо задачу складнішою — інакше розв’язувач міг би
обійтися одним залом. Для цього просто додамо більше і довших зустрічей.

```python
# Опис зустрічей
meetings = {
    "meeting_a": MeetingInfo(
        start_times=[
            [t_to_idx(8, 0), t_to_idx(12, 0)],
            [t_to_idx(16, 0), t_to_idx(16, 0)],
        ],
        duration=120 // 5,
    ),
    "meeting_b": MeetingInfo(
        start_times=[[t_to_idx(10, 0), t_to_idx(12, 0)]], duration=240 // 5
    ),
    "meeting_c": MeetingInfo(
        start_times=[[t_to_idx(16, 0), t_to_idx(17, 0)]], duration=30 // 5
    ),
    "meeting_d": MeetingInfo(
        start_times=[
            [t_to_idx(8, 0), t_to_idx(10, 0)],
            [t_to_idx(12, 0), t_to_idx(14, 0)],
        ],
        duration=60 // 5,
    ),
    "meeting_e": MeetingInfo(
        start_times=[[t_to_idx(10, 0), t_to_idx(12, 0)]], duration=120 // 5
    ),
    "meeting_f": MeetingInfo(
        start_times=[[t_to_idx(14, 0), t_to_idx(14, 0)]], duration=240 // 5
    ),
    "meeting_g": MeetingInfo(
        start_times=[[t_to_idx(14, 0), t_to_idx(16, 0)]], duration=120 // 5
    ),
}
```

Тепер треба створити інтервал для кожного залу та зустрічі, а також булеву
змінну, яка показує, чи зустріч призначена в зал. Не можна використовувати
один інтервал для двох залів, інакше він буде присутній одночасно в обох.

```python
# Створюємо модель
model = cp_model.CpModel()

# Створюємо змінні старту та кімнат
start_time_vars = {
    name: model.new_int_var_from_domain(
        cp_model.Domain.from_intervals(info.start_times), f"start_{name}"
    )
    for name, info in meetings.items()
}

rooms = ["room_a", "room_b"]
room_vars = {
    name: {room: model.new_bool_var(f"{name}_in_{room}") for room in rooms}
    for name in meetings
}

# Створюємо інтервали та додаємо no-overlap
interval_vars = {
    name: {
        # Окремий інтервал для кожної кімнати
        room: model.new_optional_fixed_size_interval_var(
            start=start_time_vars[name],
            size=info.duration,
            is_present=room_vars[name][room],
            name=f"interval_{name}_in_{room}",
        )
        for room in rooms
    }
    for name, info in meetings.items()
}
```

Тепер гарантуємо, що кожна зустріч призначена рівно в один зал і що у кожному
залі немає перекриття.

```python
# Кожну зустріч призначаємо рівно в один зал
for name, room_dict in room_vars.items():
    model.add_exactly_one(room_dict.values())

for room in rooms:
    model.add_no_overlap([interval_vars[name][room] for name in meetings])
```

І знову візуалізуємо розклад.

| ![Schedule multiple rooms](https://raw.githubusercontent.com/d-krupke/cpsat-primer/main/images/scheduling_multiple_resources.png) |
| :-------------------------------------------------------------------------------------------------------------------------------: |
| Можливий неперекривний розклад для наведеного прикладу з кількома залами. |

> [!TIP]
>
> Цю модель легко розширити, щоб максимізувати кількість зустрічей через
> цільову функцію. Також можна максимізувати відстань між двома зустрічами,
> використавши інтервал зі змінною довжиною. Це хороша вправа.

#### Пакування прямокутників без перекриття

Розгляньмо, як перевірити, чи можна упакувати набір прямокутників у контейнер
без перекриття. Це поширена задача в логістиці або задачах розкрою.

Спочатку визначимо `namedtuple` для прямокутників і контейнера.

```python
from collections import namedtuple

# Визначаємо namedtuple для прямокутників і контейнера
Rectangle = namedtuple("Rectangle", ["width", "height"])
Container = namedtuple("Container", ["width", "height"])

# Приклад
rectangles = [Rectangle(width=2, height=3), Rectangle(width=4, height=5)]
container = Container(width=10, height=10)
```

Далі створимо змінні для нижніх лівих кутів прямокутників і обмежимо їх, щоб
прямокутники залишалися в межах контейнера.

```python
model = cp_model.CpModel()

# Змінні для нижніх лівих кутів
x_vars = [
    model.new_int_var(0, container.width - box.width, name=f"x1_{i}")
    for i, box in enumerate(rectangles)
]
y_vars = [
    model.new_int_var(0, container.height - box.height, name=f"y1_{i}")
    for i, box in enumerate(rectangles)
]
```

Створимо інтервали для кожного прямокутника. Початок — нижній лівий кут, розмір
— ширина або висота. Використаємо `add_no_overlap_2d`, щоб уникнути перекриттів.

```python
# Інтервали для ширини та висоти прямокутників
x_interval_vars = [
    model.new_fixed_size_interval_var(
        start=x_vars[i], size=box.width, name=f"x_interval_{i}"
    )
    for i, box in enumerate(rectangles)
]
y_interval_vars = [
    model.new_fixed_size_interval_var(
        start=y_vars[i], size=box.height, name=f"y_interval_{i}"
    )
    for i, box in enumerate(rectangles)
]

# Забороняємо перекриття
model.add_no_overlap_2d(x_interval_vars, y_interval_vars)
```

Опційні інтервали зі змінною довжиною дозволяють моделювати повороти та
знаходити найбільше можливе пакування. Код здається складним, але є досить
прямолінійним з огляду на складність задачі.

Спочатку визначимо `namedtuple` для прямокутників і контейнера.

```python
from collections import namedtuple
from ortools.sat.python import cp_model

# Визначаємо namedtuple для прямокутників і контейнера
Rectangle = namedtuple("Rectangle", ["width", "height", "value"])
Container = namedtuple("Container", ["width", "height"])

# Приклад
rectangles = [
    Rectangle(width=2, height=3, value=1),
    Rectangle(width=4, height=5, value=1),
]
container = Container(width=10, height=10)
```

Далі створимо змінні для координат прямокутників, включно з нижніми лівими та
верхніми правими кутами, а також булевою змінною, що показує, чи прямокутник
повернутий.

```python
model = cp_model.CpModel()

# Змінні для нижніх лівих і верхніх правих кутів
bottom_left_x_vars = [
    model.new_int_var(0, container.width, name=f"x1_{i}")
    for i, box in enumerate(rectangles)
]
bottom_left_y_vars = [
    model.new_int_var(0, container.height, name=f"y1_{i}")
    for i, box in enumerate(rectangles)
]
upper_right_x_vars = [
    model.new_int_var(0, container.width, name=f"x2_{i}")
    for i, box in enumerate(rectangles)
]
upper_right_y_vars = [
    model.new_int_var(0, container.height, name=f"y2_{i}")
    for i, box in enumerate(rectangles)
]

# Змінні, що показують поворот
rotated_vars = [model.new_bool_var(f"rotated_{i}") for i in range(len(rectangles))]
```

Тепер створимо змінні ширини та висоти з урахуванням повороту, і обмеження, що
зв’язують їх із поворотом.

```python
# Змінні ширини та висоти з урахуванням повороту
width_vars = []
height_vars = []
for i, box in enumerate(rectangles):
    domain = cp_model.Domain.from_values([box.width, box.height])
    width_vars.append(model.new_int_var_from_domain(domain, name=f"width_{i}"))
    height_vars.append(model.new_int_var_from_domain(domain, name=f"height_{i}"))
    # Два можливі варіанти присвоєння ширини/висоти
    model.add_allowed_assignments(
        [width_vars[i], height_vars[i], rotated_vars[i]],
        [(box.width, box.height, 0), (box.height, box.width, 1)],
    )
```

Далі створимо булеву змінну, що означає, чи прямокутник упакований, і інтервали,
що представляють його займаний простір. Їх використовуємо для `add_no_overlap_2d`.

```python
# Змінні, що вказують, чи прямокутник упакований
packed_vars = [model.new_bool_var(f"packed_{i}") for i in range(len(rectangles))]

# Інтервали для ширини та висоти
x_interval_vars = [
    model.new_optional_interval_var(
        start=bottom_left_x_vars[i],
        size=width_vars[i],
        is_present=packed_vars[i],
        end=upper_right_x_vars[i],
        name=f"x_interval_{i}",
    )
    for i, box in enumerate(rectangles)
]
y_interval_vars = [
    model.new_optional_interval_var(
        start=bottom_left_y_vars[i],
        size=height_vars[i],
        is_present=packed_vars[i],
        end=upper_right_y_vars[i],
        name=f"y_interval_{i}",
    )
    for i, box in enumerate(rectangles)
]

# Забороняємо перекриття
model.add_no_overlap_2d(x_interval_vars, y_interval_vars)
```

Нарешті, максимізуємо кількість упакованих прямокутників через цільову функцію.

```python
# Максимізуємо кількість упакованих прямокутників
model.maximize(sum(box.value * x for x, box in zip(packed_vars, rectangles)))
```

|                       ![./images/dense_packing.png](https://github.com/d-krupke/cpsat-primer/blob/main/images/dense_packing.png)                       |
| :----------------------------------------------------------------------------------------------------------------------------------------------------: |
| Це щільне пакування CP-SAT знайшов менш ніж за 0.3 с, що вражає і виглядає ефективнішим за наївну реалізацію в Gurobi. |

Повний код можна знайти тут:

|                           Варіант задачі                           |                                                                                Код                                                                                 |
| :------------------------------------------------------------------: | :-----------------------------------------------------------------------------------------------------------------------------------------------------------------: |
|     Перевірка здійсненності пакування без поворотів     |    [./evaluations/packing/solver/packing_wo_rotations.py](https://github.com/d-krupke/cpsat-primer/blob/main/evaluations/packing/solver/packing_wo_rotations.py)    |
| Пошук найбільшого пакування без поворотів |   [./evaluations/packing/solver/knapsack_wo_rotations.py](https://github.com/d-krupke/cpsat-primer/blob/main/evaluations/packing/solver/knapsack_wo_rotations.py)   |
|      Перевірка здійсненності пакування з поворотами       |  [./evaluations/packing/solver/packing_with_rotations.py](https://github.com/d-krupke/cpsat-primer/blob/main/evaluations/packing/solver/packing_with_rotations.py)  |
|  Пошук найбільшого пакування з поворотами   | [./evaluations/packing/solver/knapsack_with_rotations.py](https://github.com/d-krupke/cpsat-primer/blob/main/evaluations/packing/solver/knapsack_with_rotations.py) |

CP-SAT добре знаходить здійсненне пакування, але майже не здатен довести
недопустимість. У варіанті «рюкзака» він усе одно пакує більшість прямокутників
навіть для великих інстансів.

|                           ![./images/packing_plot_solved.png](https://github.com/d-krupke/cpsat-primer/blob/main/images/packing_plot_solved.png)                           |
| :------------------------------------------------------------------------------------------------------------------------------------------------------------------------: |
| Кількість розв’язаних інстансів для задачі пакування (ліміт 90 с). Повороти трохи ускладнюють задачу. Жоден з використаних інстансів не було доведено як недопустимий. |
|                            ![./images/packing_percentage.png](https://github.com/d-krupke/cpsat-primer/blob/main/images/packing_percentage.png)                            |
|                                           Однак CP-SAT здатен упакувати майже всі прямокутники навіть для найбільших інстансів.                                            |

#### Роздільна здатність і параметри

У ранніх версіях CP-SAT продуктивність обмежень no-overlap сильно залежала від
роздільної здатності. З часом це змінилося, але вплив залишається непослідовним.
У прикладі в ноутбуці я дослідив, як роздільна здатність впливає на час
виконання `add_no_overlap` у версіях 9.3 і 9.8. Для 9.3 час виконання
помітно зростає зі збільшенням роздільної здатності. Натомість у 9.8 час
виконання зменшується при більшій роздільній здатності, що підтвердили повторні
тести. Це несподіване спостереження свідчить, що продуктивність CP-SAT щодо
no-overlap ще не стабілізувалася і може змінюватися в майбутніх версіях.

| Resolution | Runtime (CP-SAT 9.3) | Runtime (CP-SAT 9.8) |
| ---------- | -------------------- | -------------------- |
| 1x         | 0.02s                | 0.03s                |
| 10x        | 0.7s                 | 0.02s                |
| 100x       | 7.6s                 | 1.1s                 |
| 1000x      | 75s                  | 40.3s                |
| 10_000x    | >15min               | 0.4s                 |

[Цей ноутбук](https://github.com/d-krupke/cpsat-primer/blob/main/examples/add_no_overlap_2d.ipynb)
використано для створення таблиці.

Втім, експериментуючи з менш документованими можливостями, я помітив, що
продуктивність у старішій версії можна суттєво покращити такими параметрами:

```python
solver.parameters.use_energetic_reasoning_in_no_overlap_2d = True
solver.parameters.use_timetabling_in_no_overlap_2d = True
solver.parameters.use_pairwise_reasoning_in_no_overlap_2d = True
```

У найновішій версії CP-SAT суттєвого приросту я не помітив.

<a name="04-modelling-automaton"></a>

### Обмеження автомата

Обмеження автомата моделюють скінченні автомати, тобто допустимі переходи між
станами. Це особливо корисно у верифікації ПЗ, де важливо, щоб програма
дотримувалася заданої послідовності станів. З огляду на важливість верифікації
в дослідженнях, ці обмеження мають свою аудиторію, але інші можуть перейти до
наступного розділу.

|                  ![Automaton Example](https://raw.githubusercontent.com/d-krupke/cpsat-primer/main/images/automaton.png)                   |
| :----------------------------------------------------------------------------------------------------------------------------------------: |
| Приклад скінченного автомата з чотирма станами і сімома переходами. Стан 0 — початковий, стан 3 — кінцевий. |

Автомат працює так: маємо список цілочисельних змінних `transition_variables`,
які представляють значення переходів. Починаючи зі `starting_state`, наступний
стан визначається трійкою `(state, transition_value, next_state)`, яка відповідає
першій змінній переходу. Якщо такої трійки немає — модель недопустима. Процес
повторюється для кожної наступної змінної. Важливо, щоб останній перехід вів у
кінцевий стан (можливо, через петлю); інакше модель недопустима.

Автомат із прикладу можна змоделювати так:

```python
model = cp_model.CpModel()

transition_variables = [model.new_int_var(0, 2, f"transition_{i}") for i in range(4)]
transition_triples = [
    (0, 0, 1),  # Якщо стан 0 і значення 0, переходимо в стан 1
    (1, 0, 1),  # Якщо стан 1 і значення 0, залишаємося в стані 1
    (1, 1, 2),  # Якщо стан 1 і значення 1, переходимо в стан 2
    (2, 0, 0),  # Якщо стан 2 і значення 0, переходимо в стан 0
    (2, 1, 1),  # Якщо стан 2 і значення 1, переходимо в стан 1
    (2, 2, 3),  # Якщо стан 2 і значення 2, переходимо в стан 3
    (3, 0, 3),  # Якщо стан 3 і значення 0, залишаємося в стані 3
]

model.add_automaton(
    transition_variables=transition_variables,
    starting_state=0,
    final_states=[3],
    transition_triples=transition_triples,
)
```

Присвоєння `[0, 1, 2, 0]` є допустимим, тоді як `[1, 0, 1, 2]` недопустиме, бо зі
стану 0 немає переходу для значення 1. Так само `[0, 0, 1, 1]` недопустиме, бо
не закінчується у кінцевому стані.

> [!NOTE]
>
> Обмеження автомата, наприклад, використано в цій
> [статті](https://arxiv.org/pdf/2410.11981) для моделювання Parallel Batch
> Scheduling With Incompatible Job Families.

<a name="04-modelling-reservoir"></a>

### Обмеження резервуара

Інколи потрібно підтримувати баланс між притоками та відтоками резервуара.
Найочевидніший приклад — водосховище, де рівень води має бути між мінімумом і
максимумом. Обмеження резервуара приймає список часових змінних, список зміни
рівня та мінімальний/максимальний рівень. Якщо афінний вираз `times[i]`
набуває значення `t`, тоді поточний рівень змінюється на `level_changes[i]`.
Зауважте, що змінні зміни рівня наразі не підтримуються — зміни сталі у момент
`t`. Обмеження гарантує, що рівень завжди між мінімумом і максимумом:
`sum(level_changes[i] if times[i] <= t) in [min_level, max_level]`.

Є багато прикладів, окрім водосховища, де потрібно балансувати попит і
пропозицію: підтримка запасів на складі або забезпечення рівня персоналу в
клініці. `add_reservoir_constraint` у CP-SAT дозволяє легко моделювати такі
задачі.

У наведеному прикладі `times[i]` — час застосування зміни `level_changes[i]`,
тому обидва списки мають однакову довжину. Рівень резервуара стартує з 0, і
мінімальний рівень має бути $\leq 0$, а максимальний — $\geq 0$.

```python
times = [model.new_int_var(0, 10, f"time_{i}") for i in range(10)]
level_changes = [1] * 10

model.add_reservoir_constraint(
    times=times,
    level_changes=level_changes,
    min_level=-10,
    max_level=10,
)
```

Додатково, `add_reservoir_constraint_with_active` дозволяє моделювати резервуар
з _опційними_ змінами. Тут маємо список булевих змінних `actives`, де
`actives[i]` означає, чи відбувається зміна `level_changes[i]`, тобто
`sum(level_changes[i] * actives[i] if times[i] <= t) in [min_level, max_level]`.
Якщо зміна не активна, це як якщо б її не існувало, і рівень залишається
незмінним незалежно від часу й значення зміни.

```python
times = [model.new_int_var(0, 10, f"time_{i}") for i in range(10)]
level_changes = [1] * 10
actives = [model.new_bool_var(f"active_{i}") for i in range(10)]

model.add_reservoir_constraint_with_active(
    times=times,
    level_changes=level_changes,
    actives=actives,
    min_level=-10,
    max_level=10,
)
```

Щоб проілюструвати використання, розгляньмо приклад планування медсестер у
клініці. Повний приклад — у
[ноутбуці](https://github.com/d-krupke/cpsat-primer/blob/main/examples/add_reservoir.ipynb).

Клініці потрібно, щоб завжди було достатньо медсестер без надлишку. Для 12-годинного
робочого дня змоделюємо попит як ціле число для кожної години.

```python
# додатне число означає, що потрібно більше медсестер, від’ємне — менше.
demand_change_at_t = [3, 0, 0, 0, 2, 0, 0, 0, -1, 0, -1, 0, -3]
demand_change_times = list(range(len(demand_change_at_t)))  # [0, 1, ..., 12]
```

Є список медсестер, кожна має власну доступність та максимальну тривалість зміни.

```python
max_shift_length = 5

# початок і кінець доступності кожної медсестри
nurse_availabilities = 2 * [
    (0, 7),
    (0, 4),
    (0, 8),
    (2, 9),
    (1, 5),
    (5, 12),
    (7, 12),
    (0, 12),
    (4, 12),
]
```

Ініціалізуємо змінні моделі: старт і кінець зміни кожної медсестри та булеву
змінну, що показує, чи вона працює.

```python
# булева змінна, що показує, чи медсестру заплановано
nurse_scheduled = [
    model.new_bool_var(f"nurse_{i}_scheduled") for i in range(len(nurse_availabilities))
]

# моделюємо початок і кінець кожної зміни
shifts_begin = [
    model.new_int_var(begin, end, f"begin_nurse_{i}")
    for i, (begin, end) in enumerate(nurse_availabilities)
]

shifts_end = [
    model.new_int_var(begin, end, f"end_nurse_{i}")
    for i, (begin, end) in enumerate(nurse_availabilities)
]
```

Додаємо базові обмеження, щоб зміни були валідними.

```python
for begin, end in zip(shifts_begin, shifts_end):
    model.add(end >= begin)  # кінець після початку
    model.add(end - begin <= max_shift_length)  # зміна не надто довга
```

Рівень резервуара — це кількість запланованих медсестер у будь-який момент
мінус попит до цього моменту. Додаємо обмеження резервуара, щоб завжди вистачало
персоналу, але не було надлишку (рівень між 0 і 2). Маємо три типи змін:

1. Попит змінюється на початку кожної години. Для цього використовуємо фіксовані
   моменти часу і активуємо всі зміни. Попит зі знаком мінус, бо зростання попиту
   знижує рівень резервуара.
2. Початок зміни медсестри підвищує рівень на 1. Час — `shifts_begin`, зміна
   активна лише якщо медсестра запланована.
3. Завершення зміни знижує рівень на 1. Час — `shifts_end`, зміна активна лише
   якщо медсестра запланована.

```python
times = demand_change_times
demands = [
    -demand for demand in demand_change_at_t
]  # зростання попиту знижує резервуар
actives = [1] * len(demand_change_times)

times += list(shifts_begin)
demands += [1] * len(shifts_begin)  # медсестра починає зміну
actives += list(nurse_scheduled)

times += list(shifts_end)
demands += [-1] * len(shifts_end)  # медсестра завершує зміну
actives += list(nurse_scheduled)

model.add_reservoir_constraint_with_active(
    times=times,
    level_changes=demands,
    min_level=0,
    max_level=2,
    actives=actives,
)
```

> [!NOTE]
>
> Обмеження резервуара дозволяють описувати умови, які важко змоделювати
> «вручну». Проте, хоча в мене небагато практики з ними, я не очікував би, що їх
> легко оптимізувати. Напишіть, якщо у вас є позитивний або негативний досвід
> використання та для яких масштабів задач вони працюють добре.

<a name="04-modelling-pwl"></a>

### Нелінійні обмеження / кусково-лінійні функції

На практиці часто трапляються функції витрат, які не є лінійними. Наприклад,
виробнича задача, де ви виробляєте три різні вироби. Кожен виріб має різні
компоненти, які потрібно купувати. Вартість компонентів спочатку зменшується зі
збільшенням обсягу, а потім зростає, коли постачальник вичерпує запаси і
доводиться купувати у дорожчого. Крім того, кількість клієнтів, готових платити
певну ціну, обмежена. Якщо хочете продавати більше, доведеться знижувати ціну,
що зменшить прибуток.

Припустімо, така функція має вигляд $y=f(x)$ на рисунку нижче. На жаль, це
досить складна функція, яку не можна напряму виразити в CP-SAT. Проте можна
наблизити її кусково-лінійною функцією (червона лінія). Такі апроксимації дуже
поширені, а деякі розв’язувачі навіть роблять це автоматично, наприклад Gurobi.
Роздільну здатність можна збільшувати довільно, але чим більше сегментів, тим
складніша модель. Тому зазвичай її роблять лише настільки високою, наскільки
потрібно.

|                                                                                                                     ![./images/pwla.png](https://github.com/d-krupke/cpsat-primer/blob/main/images/pwla.png)                                                                                                                      |
| :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: |
| Ми можемо змоделювати довільну неперервну функцію кусково-лінійною. Тут ми розбиваємо оригінал на кілька лінійних сегментів. Точність можна адаптувати під вимоги. Лінійні сегменти далі можна виразити в CP-SAT. Чим менше сегментів, тим простіше моделювати і розв’язувати. |

Використовуючи лінійні обмеження (`model.add`) та реїфікацію (`.only_enforce_if`),
можна змоделювати кусково-лінійну функцію в CP-SAT. Для цього використовуємо
булеві змінні, що вибирають сегмент, і активуємо відповідне лінійне обмеження
через реїфікацію. Однак у CP-SAT виникають дві проблеми, показані на рисунку.

|                                                                                                             ![./images/pwla_problems.png](https://github.com/d-krupke/cpsat-primer/blob/main/images/pwla_problems.png)                                                                                                              |
| :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: |
| Навіть якщо f(x) складається з лінійних сегментів, ми не можемо просто реалізувати $y=f(x)$ в CP-SAT. По-перше, для багатьох значень $x$ функція дає нецілі значення, отже модель стає недопустимою. По-друге, канонічне представлення лінійних сегментів часто потребує нецілих коефіцієнтів, що також заборонено в CP-SAT. |

- **Проблема A:** навіть якщо сегмент — лінійна функція, результат може бути
  нецілим. У прикладі $f(5)=3{,}5$, і якщо ми задаємо $y=f(x)$, то значення
  $x=5$ стає забороненим, що не є бажаним. Є два варіанти: або використовувати
  складнішу апроксимацію, яка гарантує цілі значення, або застосувати
  нерівності. Перший варіант може вимагати занадто багато сегментів і бути
  надто дорогим. Другий дає слабше обмеження, адже ми можемо задати лише
  $y<=f(x)$ або $y>=f(x)$, але не $y=f(x)$. Якщо спробувати обидві нерівності,
  отримаємо ту саму недопустимість. Але часто достатньо однієї нерівності.
  Якщо потрібно обмежити $y$ зверху — використовуємо $y<=f(x)$, якщо знизу —
  $y>=f(x)$. Якщо $f(x)$ представляє витрати, то використовуємо $y>=f(x)$ і
  мінімізуємо $y$.

- **Проблема B:** канонічна форма лінійної функції — $y=ax+b$. Часто потрібні
  нецілі коефіцієнти. Їх можна масштабувати до цілих, додаючи масштабний
  множник. Наприклад, нерівність $y=0.5x+0.5$ можна переписати як $2y=x+1$.
  Це робиться через НСК, але масштаб може стати великим і привести до
  переповнень.

Можлива реалізація:

```python
# Ми хочемо задати y=f(x)
x = model.new_int_var(0, 7, "x")
y = model.new_int_var(0, 5, "y")

# Булеві змінні для вибору сегмента
segment_active = [model.new_bool_var("segment_1"), model.new_bool_var("segment_2")]
model.add_at_most_one(segment_active)  # активний лише один сегмент

# Сегмент 1
# якщо 0<=x<=3, тоді y >= 0.5*x + 0.5
model.add(2 * y >= x + 1).only_enforce_if(segment_active[0])
model.add(x >= 0).only_enforce_if(segment_active[0])
model.add(x <= 3).only_enforce_if(segment_active[0])

# Сегмент 2
model.add(_SLIGHTLY_MORE_COMPLEX_INEQUALITY_).only_enforce_if(segment_active[1])
model.add(x >= 3).only_enforce_if(segment_active[1])
model.add(x <= 7).only_enforce_if(segment_active[1])

model.minimize(y)
# якщо б ми максимізували y, використовували б <= замість >=
```

Це може бути доволі громіздко, але я написав невеликий helper-клас, який робить
це автоматично. Він знаходиться в
[./utils/piecewise_functions](https://github.com/d-krupke/cpsat-primer/blob/main/utils/piecewise_functions/).
Просто скопіюйте у свій код.

Цей код робить додаткові оптимізації:

1. Розгляд кожного сегмента як окремого випадку може бути дорогим і
   неефективним. Тому суттєво допомагає, якщо ви можете об’єднати кілька
   сегментів в один випадок. Це можна зробити, виявляючи опуклі ділянки, адже
   обмеження опуклих областей не заважають одне одному.
2. Додавання опуклої оболонки сегментів як надлишкового обмеження, що не
   залежить від `only_enforce_if`, іноді допомагає розв’язувачу краще обмежити
   область. Обмеження з `only_enforce_if` зазвичай погано працюють для лінійної
   релаксації, а незалежна опукла оболонка одразу обмежує простір розв’язків без
   гілкування по випадках.

Застосуймо цей код до задачі вище.

У нас є два продукти, кожен вимагає три компоненти. Перший продукт потребує 3
компоненти 1, 5 компоненти 2 і 2 компоненти 3. Другий продукт потребує 2
компоненти 1, 1 компоненту 2 і 3 компоненти 3. Ми можемо купити до 1500 кожного
компонента за цінами з рисунка нижче. Виробляти можна до 300 одиниць кожного
продукту і продавати їх за цінами з рисунка.

| ![./images/production_example_cost_components.png](https://github.com/d-krupke/cpsat-primer/blob/main/images/production_example_cost_components.png) | ![./images/production_example_selling_price.png](https://github.com/d-krupke/cpsat-primer/blob/main/images/production_example_selling_price.png) |
| :--------------------------------------------------------------------------------------------------------------------------------------------------: | :----------------------------------------------------------------------------------------------------------------------------------------------: |
| Витрати на закупівлю компонентів для виробництва. | Ціни продажу продукції. |

Хочемо максимізувати прибуток, тобто дохід мінус витрати на компоненти. Модель:

```python
requirements_1 = (3, 5, 2)
requirements_2 = (2, 1, 3)

from ortools.sat.python import cp_model

model = cp_model.CpModel()
buy_1 = model.new_int_var(0, 1_500, "buy_1")
buy_2 = model.new_int_var(0, 1_500, "buy_2")
buy_3 = model.new_int_var(0, 1_500, "buy_3")

produce_1 = model.new_int_var(0, 300, "produce_1")
produce_2 = model.new_int_var(0, 300, "produce_2")

model.add(produce_1 * requirements_1[0] + produce_2 * requirements_2[0] <= buy_1)
model.add(produce_1 * requirements_1[1] + produce_2 * requirements_2[1] <= buy_2)
model.add(produce_1 * requirements_1[2] + produce_2 * requirements_2[2] <= buy_3)

# Код із ./utils!
from piecewise_functions import PiecewiseLinearFunction, PiecewiseLinearConstraint

# Функції витрат
costs_1 = [(0, 0), (1000, 400), (1500, 1300)]
costs_2 = [(0, 0), (300, 300), (700, 500), (1200, 600), (1500, 1100)]
costs_3 = [(0, 0), (200, 400), (500, 700), (1000, 900), (1500, 1500)]
# PiecewiseLinearFunction — pydantic модель і легко серіалізується
f_costs_1 = PiecewiseLinearFunction(
    xs=[x for x, y in costs_1], ys=[y for x, y in costs_1]
)
f_costs_2 = PiecewiseLinearFunction(
    xs=[x for x, y in costs_2], ys=[y for x, y in costs_2]
)
f_costs_3 = PiecewiseLinearFunction(
    xs=[x for x, y in costs_3], ys=[y for x, y in costs_3]
)

# Функції доходу
gain_1 = [(0, 0), (100, 800), (200, 1600), (300, 2_000)]
gain_2 = [(0, 0), (80, 1_000), (150, 1_300), (200, 1_400), (300, 1_500)]
f_gain_1 = PiecewiseLinearFunction(xs=[x for x, y in gain_1], ys=[y for x, y in gain_1])
f_gain_2 = PiecewiseLinearFunction(xs=[x for x, y in gain_2], ys=[y for x, y in gain_2])

# Обмеження y>=f(x) для витрат
x_costs_1 = PiecewiseLinearConstraint(model, buy_1, f_costs_1, upper_bound=False)
x_costs_2 = PiecewiseLinearConstraint(model, buy_2, f_costs_2, upper_bound=False)
x_costs_3 = PiecewiseLinearConstraint(model, buy_3, f_costs_3, upper_bound=False)

# Обмеження y<=f(x) для доходу
x_gain_1 = PiecewiseLinearConstraint(model, produce_1, f_gain_1, upper_bound=True)
x_gain_2 = PiecewiseLinearConstraint(model, produce_2, f_gain_2, upper_bound=True)

# Максимізуємо дохід мінус витрати
model.Maximize(x_gain_1.y + x_gain_2.y - (x_costs_1.y + x_costs_2.y + x_costs_3.y))

solver = cp_model.CpSolver()
solver.parameters.log_search_progress = True
status = solver.solve(model)
print(f"Buy {solver.value(buy_1)} of component 1")
print(f"Buy {solver.value(buy_2)} of component 2")
print(f"Buy {solver.value(buy_3)} of component 3")
print(f"Produce {solver.value(produce_1)} of product 1")
print(f"Produce {solver.value(produce_2)} of product 2")
print(f"Overall gain: {solver.objective_value}")
```

Отримаємо такий результат:

```
Buy 930 of component 1
Buy 1200 of component 2
Buy 870 of component 3
Produce 210 of product 1
Produce 150 of product 2
Overall gain: 1120.0
```

На жаль, такі задачі швидко стають дуже складними для моделювання і розв’язання.
Це лише доказ того, що теоретично такі задачі можна моделювати в CP-SAT. На
практиці без експертності можна втратити багато часу й нервів.

<!-- This file was generated by the `build.py` script. Do not edit it manually. -->
<!-- ./chapters/05_parameters.md -->
<!-- EDIT THIS PART VIA 05_parameters.md -->

<a name="05-parameters"></a>

## Параметри


CP-SAT має багато параметрів для керування своєю поведінкою. Ці параметри
реалізовані через
[Protocol Buffers](https://developers.google.com/protocol-buffers) і змінюються
через властивість `parameters`. Щоб переглянути всі доступні опції, дивіться
добре задокументований `proto`-файл в
[офіційному репозиторії](https://github.com/google/or-tools/blob/stable/ortools/sat/sat_parameters.proto).
Нижче я виділю найважливіші параметри, щоб ви могли отримати максимум від CP-SAT.

> :warning: Лише кілька параметрів, таких як `max_time_in_seconds`, підходять
> початківцям. Більшість інших параметрів, як-от стратегії рішень, краще
> залишати за замовчуванням, бо вони добре підібрані, і втручання може лише
> нашкодити оптимізаціям. Для кращої продуктивності зосередьтеся на покращенні
> моделі.

### Логування

Параметр `log_search_progress` особливо важливий на початку. Він вмикає лог
пошуку, що дає уявлення про те, як CP-SAT розв’язує вашу задачу. У продакшені
ви можете його вимкнути, але під час розробки він корисний для розуміння
процесу й реагування на проблеми.

```python
solver = cp_model.CpSolver()
solver.parameters.log_search_progress = True

# Власна функція логування, наприклад через Python logging замість stdout
# Корисно в Jupyter, де stdout може бути не видно
solver.log_callback = print  # (str)->None
# Якщо використовуєте власну функцію логування, можна вимкнути stdout
solver.parameters.log_to_stdout = False
```

Лог містить цінну інформацію для розуміння CP-SAT і вашої задачі. Він показує,
скільки змінних було видалено, які техніки найефективніше покращували нижні та
верхні межі, тощо.

Приклад логу:

```
Starting CP-SAT solver v9.10.4067
Parameters: max_time_in_seconds: 30 log_search_progress: true relative_gap_limit: 0.01
Setting number of workers to 16

Initial optimization model '': (model_fingerprint: 0x1d316fc2ae4c02b1)
#Variables: 450 (#bools: 276 #ints: 6 in objective)
  - 342 Booleans in [0,1]
  - 12 in [0][10][20][30][40][50][60][70][80][90][100]
  - 6 in [0][10][20][30][40][100]
  - 6 in [0][80][100]
  - 6 in [0][100]
  - 6 in [0,1][34][67][100]
  - 12 in [0,6]
  - 18 in [0,7]
  - 6 in [0,35]
  - 6 in [0,36]
  - 6 in [0,100]
  - 12 in [21,57]
  - 12 in [22,57]
#kBoolOr: 30 (#literals: 72)
#kLinear1: 33 (#enforced: 12)
#kLinear2: 1'811
#kLinear3: 36
#kLinearN: 94 (#terms: 1'392)

Starting presolve at 0.00s
  3.26e-04s  0.00e+00d  [DetectDominanceRelations]
  6.60e-03s  0.00e+00d  [PresolveToFixPoint] #num_loops=4 #num_dual_strengthening=3
  2.69e-05s  0.00e+00d  [ExtractEncodingFromLinear] #potential_supersets=44 #potential_subsets=12
[Symmetry] Graph for symmetry has 2'224 nodes and 5'046 arcs.
[Symmetry] Symmetry computation done. time: 0.000374304 dtime: 0.00068988
[Symmetry] #generators: 2, average support size: 12
[Symmetry] 12 orbits with sizes: 2,2,2,2,2,2,2,2,2,2,...
[Symmetry] Found orbitope of size 6 x 2
[SAT presolve] num removable Booleans: 0 / 309
[SAT presolve] num trivial clauses: 0
[SAT presolve] [0s] clauses:570 literals:1152 vars:303 one_side_vars:268 simple_definition:35 singleton_clauses:0
[SAT presolve] [3.0778e-05s] clauses:570 literals:1152 vars:303 one_side_vars:268 simple_definition:35 singleton_clauses:0
[SAT presolve] [4.6758e-05s] clauses:570 literals:1152 vars:303 one_side_vars:268 simple_definition:35 singleton_clauses:0
  1.10e-02s  9.68e-03d  [Probe] #probed=1'738 #new_bounds=12 #new_binary_clauses=1'111
  2.34e-03s  0.00e+00d  [MaxClique] Merged 602(1374 literals) into 506(1960 literals) at_most_ones.
  3.31e-04s  0.00e+00d  [DetectDominanceRelations]
  1.89e-03s  0.00e+00d  [PresolveToFixPoint] #num_loops=2 #num_dual_strengthening=1
  5.45e-04s  0.00e+00d  [ProcessAtMostOneAndLinear]
  8.19e-04s  0.00e+00d  [DetectDuplicateConstraints] #without_enforcements=306
  8.62e-05s  7.21e-06d  [DetectDominatedLinearConstraints] #relevant_constraints=114 #num_inclusions=42
  1.94e-05s  0.00e+00d  [DetectDifferentVariables]
  1.90e-04s  8.39e-06d  [ProcessSetPPC] #relevant_constraints=560 #num_inclusions=24
  2.01e-05s  0.00e+00d  [FindAlmostIdenticalLinearConstraints]
...
```

З огляду на складність логу, я розробив інструмент для візуалізації та
коментування. Ви можете просто вставити лог у цей інструмент — він автоматично
підсвітить найважливіші моменти. Обов’язково перегляньте приклади.

[![Streamlit App](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://cpsat-log-analyzer.streamlit.app/)
[![d-krupke - CP-SAT Log Analyzer](https://img.shields.io/badge/d--krupke-CP--SAT%20Log%20Analyzer-blue?style=for-the-badge&logo=github)](https://github.com/d-krupke/CP-SAT-Log-Analyzer)

|                                                                                                                       ![Search Progress](https://github.com/d-krupke/cpsat-primer/blob/main/images/search_progress.png)                                                                                                                       |
| :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: |
| Графік прогресу пошуку з часом, побудований аналізатором логів (інший лог, ніж вище). Він допомагає зрозуміти, що складніше: знайти гарний розв’язок чи довести його якість. На цій основі можна застосувати відповідні контрзаходи. |

Ми повернемося до логів у наступному розділі.

> [!TIP]
>
> З мого викладацького досвіду, я часто бачив, як студенти вважали, що CP-SAT
> «завис», і лише потім виявлялося, що в їхньому коді побудови моделі є
> зайвий вкладений цикл $O(n^5)$, який виконується днями. Логічно підозрювати
> CP-SAT, бо він розв’язує складну частину задачі. Але навіть «проста» частина
> побудови моделі може забрати багато часу, якщо реалізована невірно. Увімкнувши
> логування, студенти одразу бачили, що проблема у їхньому коді, а не в CP-SAT.
> Це може зберегти багато часу й нервів.

### Ліміт часу і статус

Працюючи з великими або складними моделями, CP-SAT може не знайти оптимальний
розв’язок за розумний час і потенційно працювати безкінечно. Тому важливо
встановлювати ліміт часу, особливо в продакшені. Навіть у межах ліміту CP-SAT
часто знаходить досить хороший розв’язок, хоча він може бути не доведено
оптимальним.

Вибір адекватного ліміту часу залежить від багатьох факторів і потребує
експериментів. Я зазвичай починаю з 60–300 секунд, щоб не чекати надто довго
під час тестування і водночас дати розв’язувачу шанс знайти хороший розв’язок.

Щоб встановити ліміт часу (у секундах), використайте:

```python
solver.parameters.max_time_in_seconds = 60  # 60с ліміт
```

Після запуску важливо перевіряти статус, щоб зрозуміти, чи знайдено оптимальний
або допустимий розв’язок, чи розв’язку немає:

```python
status = solver.solve(model)
if status == cp_model.OPTIMAL or status == cp_model.FEASIBLE:
    print("We have a solution.")
else:
    print("Help?! No solution available! :( ")
```

Можливі статуси:

- `OPTIMAL` (4): знайдено оптимальний розв’язок.
- `FEASIBLE` (2): знайдено допустимий розв’язок; можна оцінити його якість через
  `solver.best_objective_bound`.
- `INFEASIBLE` (3): жоден розв’язок не задовольняє всі обмеження.
- `MODEL_INVALID` (1): модель CP-SAT задана некоректно.
- `UNKNOWN` (0): розв’язок не знайдено і доказ недопустимості відсутній.
  Проте межа може бути доступна.

Щоб отримати назву статусу за кодом, використовуйте `solver.status_name(status)`.

Окрім ліміту часу, можна задавати допустиму якість розв’язку через
`absolute_gap_limit` та `relative_gap_limit`. Абсолютний ліміт зупиняє
розв’язувач, коли розв’язок у межах заданого значення від межі. Відносний
ліміт зупиняє, коли значення цілі (O) знаходиться у певному відсотку від межі
(B). Щоб зупинитися, коли розв’язок (доведено) в межах 5% від оптимуму:

```python
solver.parameters.relative_gap_limit = 0.05
```

Якщо прогрес зупинився або з інших причин, можна використати callback для
розв’язків, щоб зупиняти пошук за певних умов. З їхньою допомогою ви можете
перевіряти кожен новий розв’язок і вирішувати, чи достатньо він хороший. На
відміну від Gurobi, CP-SAT не підтримує додавання lazy constraints із callback
(і взагалі їх не підтримує), що є важливим обмеженням для задач з динамічними
корекціями моделі.

Щоб додати callback, потрібно успадкувати `CpSolverSolutionCallback`. Документація
доступна
[тут](https://developers.google.com/optimization/reference/python/sat/python/cp_model#cp_model.CpSolverSolutionCallback).

```python
class MySolutionCallback(cp_model.CpSolverSolutionCallback):
    def __init__(self, data):
        cp_model.CpSolverSolutionCallback.__init__(self)
        self.data = data  # Зберігаємо дані

    def on_solution_callback(self):
        obj = self.objective_value  # Найкраще значення
        bound = self.best_objective_bound  # Найкраща межа
        print(f"The current value of x is {self.Value(x)}")
        if abs(obj - bound) < 10:
            self.StopSearch()  # Зупиняємо пошук
        # ...


solver.solve(model, MySolutionCallback(None))
```

Офіційний приклад із callback:
[тут](https://github.com/google/or-tools/blob/stable/ortools/sat/samples/stop_after_n_solutions_sample_sat.py).

> [!WARNING]
>
> Межі — це палка з двома кінцями. З одного боку, вони показують, наскільки ви
> близько до оптимуму в межах обраної моделі, і дозволяють рано завершити
> оптимізацію. З іншого — вони можуть вводити в оману з двох причин. По-перше,
> межі стосуються моделі і можуть створити хибне відчуття якості, адже ні модель,
> ні дані зазвичай не ідеальні. По-друге, іноді отримати хороші межі за
> розумний час неможливо, хоча сам розв’язок може бути хорошим — ви просто цього
> не знаєте. Це може призвести до марних витрат ресурсів у гонитві за кращими
> межами чи підходами. Межі корисні, але важливо розуміти їхнє походження і
> обмеження.

Окрім значення цілі та межі, можна отримати й внутрішні метрики, як-от
`self.num_booleans`, `self.num_branches`, `self.num_conflicts`. Ці метрики
обговоримо пізніше.

Починаючи з версії 9.10, CP-SAT підтримує callbacks для меж (bound callbacks),
які викликаються, коли доведена межа покращується. На відміну від
solution callbacks, які спрацьовують при знаходженні нового розв’язку, bound
callbacks корисні для зупинки пошуку, коли межа достатньо хороша. Синтаксис
відрізняється: це вільні функції, які напряму працюють із solver.

```python
solver = cp_model.CpSolver()


def bound_callback(bound):
    print(f"New bound: {bound}")
    if bound > 100:
        solver.stop_search()


solver.best_bound_callback = bound_callback
```

Замість простої функції можна використати callable-об’єкт, щоб зберігати
посилання на solver. Це дозволяє винести callback за межі локальної області.

```python
class BoundCallback:
    def __init__(self, solver) -> None:
        self.solver = solver

    def __call__(self, bound):
        print(f"New bound: {bound}")
        if bound > 200:
            print("Abort search due to bound")
            self.solver.stop_search()
```

Цей метод гнучкіший і виглядає більш «пайтонічно».

Крім того, при кожному новому розв’язку або межі генерується лог-повідомлення.
Ви можете під’єднатися до логів і вирішувати, коли зупиняти пошук, через
log callback.

```python
solver.parameters.log_search_progress = True  # Увімкнути логування
solver.log_callback = lambda msg: print("LOG:", msg)  # (str) -> None
```

> [!WARNING]
>
> Будьте обережні з callbacks: вони можуть суттєво сповільнити розв’язувач.
> Вони викликаються часто і змушують повертатися до повільнішого Python-рівня.
> Я часто бачив, як студенти скаржилися на повільну роботу solver-а, а
> більшість часу витрачалася саме у callback. Навіть прості операції в
> callback можуть швидко накопичувати затрати часу.

### Паралелізація

CP-SAT — портфельний розв’язувач, який використовує різні техніки паралельно.
Є певний обмін інформацією між воркерами, але CP-SAT не ділить простір рішень
на частини, як це робить branch-and-bound у MIP. Це може призводити до певної
надлишковості пошуку, але паралельне використання різних технік підвищує шанси
знайти «правильну» стратегію. Передбачити, яка техніка найкраща для конкретної
задачі, часто складно, тому паралелізація може бути дуже корисною.

За замовчуванням CP-SAT використовує всі доступні ядра (включно з
гіпертредингом). Ви можете керувати паралелізацією, встановивши кількість
воркерів.

```python
solver.parameters.num_workers = 8  # використовувати 8 ядер
```

> [!TIP]
>
> Для багатьох моделей продуктивність можна підвищити, зменшивши кількість
> воркерів до кількості фізичних ядер або навіть менше. Це дає змогу іншим
> воркерам працювати на вищій частоті, отримати більше пропускної здатності
> пам’яті та зменшити взаємні перешкоди. Але майте на увазі: менше воркерів
> означає менше напрямків пошуку одночасно, що може знизити шанси прогресу.

Ось які сабсолвери використовує CP-SAT 9.9 на різних рівнях паралелізації для
оптимізаційної задачі без додаткових специфікацій (наприклад, стратегій рішень).
Кожен рядок описує додаткові сабсолвери порівняно з попереднім рядком. Зверніть
увагу, що деякі параметри/обмеження/цілі можуть змінювати стратегію
паралелізації. Також див. офіційну документацію:
[troubleshooting](https://github.com/google/or-tools/blob/main/ortools/sat/docs/troubleshooting.md#improving-performance-with-multiple-workers).

| # Workers | Full Problem Subsolvers                                                        | First Solution Subsolvers                                                                                                                                                                                                                                                                 | Incomplete Subsolvers                                                                                                                                                                                                                                                  | Helper Subsolvers                                                                 |
| --------- | ------------------------------------------------------------------------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------- |
| **1**     | `default_lp`                                                                   | No solver                                                                                                                                                                                                                                                                                 | No solver                                                                                                                                                                                                                                                              | No solver                                                                         |
| **2**     |                                                                                |                                                                                                                                                                                                                                                                                           | +13 solvers: `feasibility_pump`, `graph_arc_lns`, `graph_cst_lns`, `graph_dec_lns`, `graph_var_lns`, `packing_precedences_lns`, `packing_rectangles_lns`, `packing_slice_lns`, `rins/rens`, `rnd_cst_lns`, `rnd_var_lns`, `scheduling_precedences_lns`, `violation_ls` | +3 solvers: `neighborhood_helper`, `synchronization_agent`, `update_gap_integral` |
| **3**     | +1 solver: `no_lp`                                                             |                                                                                                                                                                                                                                                                                           |                                                                                                                                                                                                                                                                        |                                                                                   |
| **4**     | +1 solver: `max_lp`                                                            |                                                                                                                                                                                                                                                                                           |                                                                                                                                                                                                                                                                        |                                                                                   |
| **5**     |                                                                                | +1 solver: `fj_short_default`                                                                                                                                                                                                                                                             |                                                                                                                                                                                                                                                                        |                                                                                   |
| **6**     | +1 solver: `quick_restart`                                                     |                                                                                                                                                                                                                                                                                           |                                                                                                                                                                                                                                                                        |                                                                                   |
| **7**     | +1 solver: `reduced_costs`                                                     |                                                                                                                                                                                                                                                                                           |                                                                                                                                                                                                                                                                        |                                                                                   |
| **8**     | +1 solver: `quick_restart_no_lp`                                               |                                                                                                                                                                                                                                                                                           |                                                                                                                                                                                                                                                                        |                                                                                   |
| **12**    | +2 solvers: `lb_tree_search`, `pseudo_costs`                                   | +2 solvers: `fj_long_default`, `fs_random`                                                                                                                                                                                                                                                |                                                                                                                                                                                                                                                                        |                                                                                   |
| **16**    | +3 solvers: `objective_lb_search`, `objective_shaving_search_no_lp`, `probing` | +1 solver: `fs_random_quick_restart`                                                                                                                                                                                                                                                      |                                                                                                                                                                                                                                                                        |                                                                                   |
| **20**    | +2 solvers: `objective_shaving_search_max_lp`, `probing_max_lp`                | +1 solver: `fj_short_lin_default`                                                                                                                                                                                                                                                         |                                                                                                                                                                                                                                                                        |                                                                                   |
| **32**    | +2 solvers: `objective_lb_search_max_lp`, `objective_lb_search_no_lp`          | +8 solvers: `fj_long_lin_default`, `fj_long_lin_random`, `fj_long_random`, `fj_short_lin_random`, `fj_short_random`, `fs_random_no_lp`, `fs_random_quick_restart_no_lp`                                                                                                                   | +1 solver: `violation_ls(3)`                                                                                                                                                                                                                                           |                                                                                   |
| **64**    |                                                                                | +11 solvers: `fj_long_default(2)`, `fj_long_lin_default(2)`, `fj_long_lin_random(2)`, `fj_long_random(2)`, `fj_short_default(2)`, `fj_short_lin_default(2)`, `fj_short_random(2)`, `fs_random(6)`, `fs_random_no_lp(6)`, `fs_random_quick_restart(6)`, `fs_random_quick_restart_no_lp(5)` | +1 solver: `violation_ls(7)`                                                                                                                                                                                                                                           |                                                                                   |

Важливі моменти:

- З одним воркером використовується лише default сабсолвер.
- З двома і більше воркерами CP-SAT починає використовувати неповні сабсолвери,
  тобто евристики, як-от LNS.
- З п’ятьма воркерами CP-SAT також має сабсолвер для першого розв’язку.
- З 32 воркерами використовуються всі 15 повних сабсолверів.
- Понад 32 воркери здебільшого збільшують кількість сабсолверів першого розв’язку.

**Full problem subsolvers** — це сабсолвери, які шукають у повному просторі,
наприклад за допомогою branch-and-bound. Доступні:

- `default_lp`: пошук на базі LCG із типовою лінеаризацією.
  - `max_lp`: те саме, але з максимальною лінеаризацією.
  - `no_lp`: те саме, але без лінеаризації.
- `lb_tree_search`: зосереджений на покращенні доведеної межі, а не на пошуку
  кращих розв’язків. Він спростовує дешеві вузли дерева, поступово покращуючи
  межу, але має мало шансів знайти кращі розв’язки.
- `objective_lb_search`: також фокусується на покращенні межі через спростування
  поточної нижньої межі.
  - `objective_lb_search_max_lp`: із максимальною лінеаризацією.
  - `objective_lb_search_no_lp`: без лінеаризації.
  - `objective_shaving_search_max_lp`: має бути схожим на `objective_lb_search_max_lp`.
  - `objective_shaving_search_no_lp`: має бути схожим на `objective_lb_search_no_lp`.
- `probing`: фіксує змінні та дивиться, що відбувається.
  - `probing_max_lp`: те саме, але з максимальною лінеаризацією.
- `pseudo_costs`: використовує псевдовартість для вибору гілок на основі
  історичних змін меж.
- `quick_restart`: робить частіші перезапуски. Перезапуски перебудовують дерево
  з нуля, але зберігають навчений набір клауз. Це допомагає виходити з поганих
  рішень і зменшує дерево пошуку.
  - `quick_restart_no_lp`: те саме, але без лінеаризації.
- `reduced_costs`: використовує reduced costs лінійної релаксації для розгалуження.
- `core`: стратегія зі світу SAT, що витягує unsat cores.
- `fixed`: користувацька стратегія.

Використані сабсолвери можна змінювати через `solver.parameters.subsolvers`,
`solver.parameters.extra_subsolvers` та `solver.parameters.ignore_subsolvers`.
Це може бути цікаво, якщо ви використовуєте CP-SAT, бо лінійна релаксація
марна (і BnB працює погано). Є ще більше опцій, див. документацію:
[сат параметри](https://github.com/google/or-tools/blob/49b6301e1e1e231d654d79b6032e79809868a70e/ortools/sat/sat_parameters.proto#L513).
Пам’ятайте: тюнінг solver-а складний, і часто можна зробити гірше, ніж краще.
Втім, я помічав, що зменшення кількості воркерів іноді покращує час виконання.
Це означає, що підбір правильних сабсолверів може бути корисним. Наприклад,
`max_lp` — марна трата ресурсів, якщо ви знаєте, що у моделі слабка лінійна
релаксація. У цьому контексті рекомендую дивитися на релаксовані розв’язки
складних задач, щоб краще зрозуміти, де solver може «застрягати» (для цього
можна використовувати LP-розв’язувач, наприклад Gurobi).

Ефективність стратегій можна оцінювати через блоки `Solutions` і `Objective bounds`
в логах. Приклад:

```
Solutions (7)             Num   Rank
                'no_lp':    3  [1,7]
        'quick_restart':    1  [3,3]
  'quick_restart_no_lp':    3  [2,5]

Objective bounds                     Num
                  'initial_domain':    1
             'objective_lb_search':    2
       'objective_lb_search_no_lp':    4
  'objective_shaving_search_no_lp':    1
```

Для розв’язків перше число — кількість розв’язків, друге — діапазон рангів. [1,7]
означає, що знайдені розв’язки мали ранги від 1 до 7. У цьому прикладі
стратегія `no_lp` знайшла як найкращий, так і найгірший розв’язок.

Для меж число означає, скільки разів стратегія внесла вклад у найкращу межу.
У цьому прикладі виглядає, що найуспішніші — `no_lp`. Важливо також, які
стратегії взагалі відсутні у списку.

У логу пошуку також видно, коли і який сабсолвер щось зробив. Це включає
неповні та first-solution сабсолвери:

```
#1       0.01s best:43    next:[6,42]     no_lp (fixed_bools=0/155)
#Bound   0.01s best:43    next:[7,42]     objective_shaving_search_no_lp (vars=73 csts=120)
#2       0.01s best:33    next:[7,32]     quick_restart_no_lp (fixed_bools=0/143)
#3       0.01s best:31    next:[7,30]     quick_restart (fixed_bools=0/123)
#4       0.01s best:17    next:[7,16]     quick_restart_no_lp (fixed_bools=2/143)
#5       0.01s best:16    next:[7,15]     quick_restart_no_lp (fixed_bools=22/147)
#Bound   0.01s best:16    next:[8,15]     objective_lb_search_no_lp
#6       0.01s best:15    next:[8,14]     no_lp (fixed_bools=41/164)
#7       0.01s best:14    next:[8,13]     no_lp (fixed_bools=42/164)
#Bound   0.01s best:14    next:[9,13]     objective_lb_search
#Bound   0.02s best:14    next:[10,13]    objective_lb_search_no_lp
#Bound   0.04s best:14    next:[11,13]    objective_lb_search_no_lp
#Bound   0.06s best:14    next:[12,13]    objective_lb_search
#Bound   0.25s best:14    next:[13,13]    objective_lb_search_no_lp
#Model   0.26s var:125/126 constraints:162/162
#Model   2.24s var:124/126 constraints:160/162
#Model   2.58s var:123/126 constraints:158/162
#Model   2.91s var:121/126 constraints:157/162
#Model   2.95s var:120/126 constraints:155/162
#Model   2.97s var:109/126 constraints:140/162
#Model   2.98s var:103/126 constraints:135/162
#Done    2.98s objective_lb_search_no_lp
#Done    2.98s quick_restart_no_lp
#Model   2.98s var:66/126 constraints:91/162
```

**Неповні сабсолвери** — це евристики, які не шукають у повному просторі.
Приклади: large neighborhood search (LNS) і feasibility pumps. Перший шукає
кращий розв’язок, змінюючи лише кілька змінних, другий намагається зробити
недопустимі/неповні розв’язки допустимими. Можна запускати лише неповні
сабсолвери через `solver.parameters.use_lns_only = True`, але це потрібно
поєднувати з лімітом часу, бо вони не знають, коли зупинитися.

**Сабсолвери першого розв’язку** — стратегії, що намагаються швидко знайти
перший розв’язок. Вони часто використовуються для «прогріву» solver-а.

<!-- Source on Parallelization in Gurobi and general opportunities -->

Якщо цікавить, як Gurobi паралелізує пошук, є чудове відео
[тут](https://www.youtube.com/watch?v=FJz1UxaMWRQ). Ed Rothberg також пояснює
загальні можливості й виклики паралелізації solver-ів, що корисно і для
розуміння CP-SAT.

<!-- Give a disclaimer -->

> :warning: Цей розділ може потребувати допомоги: є ймовірність, що я
> переплутав деякі стратегії або зробив хибні висновки.

#### Імпорт/експорт моделей для порівняння на різному залізі

Якщо ви хочете порівняти продуктивність різних рівнів паралелізації або
обладнання, можна експортувати модель. Тоді не потрібно відтворювати її або
ділитися кодом — можна просто завантажити модель на іншій машині й запустити
solver.

```python
from ortools.sat.python import cp_model
from ortools.sat import cp_model_pb2
from google.protobuf import text_format
from pathlib import Path

def _detect_binary_mode(filename: str) -> bool:
    if filename.endswith((".txt", ".pbtxt", ".pb.txt")):
        return False
    if filename.endswith((".pb", ".bin", ".proto.bin", ".dat")):
        return True
    raise ValueError(f"Unknown extension for file: {filename}")

# Зміни в ortools 9.15: було model.Proto().SerializeToString() / text_format.MessageToString()
# Тепер використовуємо model.export_to_file(), який сам визначає формат
def export_model(model: cp_model.CpModel, filename: str, binary: bool | None = None):
    binary = _detect_binary_mode(filename) if binary is None else binary
    # export_to_file використовує .txt для текстового формату, інакше бінарний
    # Тому обробляємо невідповідності для деяких розширень
    if binary and filename.endswith(".txt"):
        # Примусово бінарний формат для .txt через тимчасовий файл
        temp_file = filename + ".pb"
        model.export_to_file(temp_file)
        Path(filename).write_bytes(Path(temp_file).read_bytes())
        Path(temp_file).unlink()
    elif not binary and not filename.endswith(".txt"):
        # Примусово текстовий формат без .txt
        temp_file = filename + ".txt"
        model.export_to_file(temp_file)
        Path(filename).write_text(Path(temp_file).read_text())
        Path(temp_file).unlink()
    else:
        model.export_to_file(filename)

# Зміни в ortools 9.15: було model.Proto().ParseFromString() / text_format.Parse()
# Тепер використовуємо model.Proto().parse_text_format() для тексту або cp_model_pb2 для бінарного
def import_model(filename: str, binary: bool | None = None) -> cp_model.CpModel:
    binary = _detect_binary_mode(filename) if binary is None else binary
    model = cp_model.CpModel()
    if binary:
        # Парсимо бінарний формат через protobuf, потім конвертуємо в текст
        proto = cp_model_pb2.CpModelProto()
        proto.ParseFromString(Path(filename).read_bytes())
        model.Proto().parse_text_format(text_format.MessageToString(proto))
    else:
        model.Proto().parse_text_format(Path(filename).read_text())
    return model
```

Бінарний формат ефективніший і має використовуватися для великих моделей.
Текстовий формат зручніший для читання й порівняння.

### Підказки (Hints)

Якщо ви маєте інтуїцію, яким може бути розв’язок — можливо, з подібної моделі
або доброї евристики — ви можете передати ці підказки CP-SAT. Деякі воркери
спробують слідувати цим підказкам, що може значно покращити продуктивність, якщо
підказки хороші. Якщо підказки представляють допустимий розв’язок, solver може
використати їх, щоб обрізати гілки з гіршими межами.

```python
model.add_hint(x, 1)  # Підказка: x, ймовірно, 1
model.add_hint(y, 2)  # Підказка: y, ймовірно, 2
```

Більше прикладів:
[official example](https://github.com/google/or-tools/blob/stable/ortools/sat/samples/solution_hinting_sample_sat.py).
Ми також побачимо використання hints для багатокритеріальної оптимізації в
розділі [Coding Patterns](#06-coding-patterns).

> [!TIP]
>
> Підказки можуть суттєво покращити продуктивність, особливо якщо solver не
> може швидко знайти хороший початковий розв’язок (видно в логах). Це часто
> називають **warm-starting**. Не потрібно давати підказки для всіх допоміжних
> змінних, але якщо ви використовуєте цілочисельні змінні для апроксимації
> неперервних, варто дати підказки і для них. CP-SAT може довго доводити
> допустимість підказки, і лише завершені розв’язки можна використовувати для
> обрізання пошуку. Якщо solver довго завершує підказку, він може даремно
> витратити час на гілки, які можна було б обрізати.

Щоб перевірити, чи підказки допустимі, можна тимчасово зафіксувати змінні на
підказаних значеннях і перевірити, чи модель не стає недопустимою:

```python
solver.parameters.fix_variables_to_their_hinted_value = True
status = solver.solve(model)
if status == cp_model.INFEASIBLE:
    print("Hints are conflicting or infeasible!")
```

Якщо підказки не використовуються, це може свідчити про логічну помилку в моделі
або баг у коді. Такий підхід надійно виявляє недопустимі підказки.

Також є `solver.parameters.debug_crash_on_bad_hint = True`, що падає solver
при неможливості завершити підказку. Але ця функція ненадійна: спрацьовує лише
в multi-worker режимі, залежить від гонки між воркерами, і контролюється
`hint_conflict_limit` (за замовчуванням 10). Підхід із
`fix_variables_to_their_hinted_value` простіший і детермінований.

> [!WARNING]
>
> У старих версіях CP-SAT підказки могли уповільнювати solver навіть якщо вони
> були правильні, але не оптимальні. У нових версіях ця проблема, здається,
> вирішена, але погані підказки все одно можуть вести solver у хибному напрямку.

Часто потрібно дослідити вплив фіксації змінних на певні значення. Щоб не
копіювати модель, можна використовувати hints і параметр
`fix_variables_to_their_hinted_value`.

```python
solver.parameters.fix_variables_to_their_hinted_value = True
```

Після цього підказки можна очистити через `model.clear_hints()` і тестувати інші
варіанти без дублювання моделі. Хоча складні вирази напряму додати не можна,
фіксація змінних дозволяє експериментувати зі складними обмеженнями без копій
моделі. Для тимчасових складних обмежень інколи все ж потрібне копіювання через
`model.CopyFrom` разом із копіюванням змінних.

Також можна використати функцію для автоматичного завершення hints для
допоміжних змінних, які часто складно задавати вручну. Запустіть функцію перед
розв’язанням. Встановіть ліміт часу залежно від складності. Якщо значення можна
вивести простою пропагацією, навіть великі моделі обробляються швидко.

```python
def complete_hint(
    model: cp_model.CpModel,
    time_limit: float = 0.5,
):
    """
    Completes the hint via a limited solve. Since CP-SAT only accepts complete hints,
    performing this step can improve solver performance.

    Args:
        model: The CpModel object to update.
        time_limit: Time limit for the solve (in seconds).

    Notes:
        This function performs a quick solve to deduce variable values.
        If successful, it replaces any existing hint with a complete one.
        If not successful, the model remains unchanged and a warning is issued.
    """
    logging.info("Completing hint with a time limit of %d seconds", time_limit)
    solver = cp_model.CpSolver()
    solver.parameters.max_time_in_seconds = time_limit
    solver.parameters.fix_variables_to_their_hinted_value = True
    status = solver.solve(model)
    logging.info(
        "Automatically completing hint with status: %s", solver.status_name(status)
    )
    if status in [cp_model.OPTIMAL, cp_model.FEASIBLE]:
        # Clear the existing hint to avoid model invalidation.
        model.clear_hints()
        # Set a new complete hint using the solver result.
        for i, _ in enumerate(model.proto.variables):
            v_ = model.get_int_var_from_proto_index(i)
            model.add_hint(v_, solver.value(v_))
        logging.info(
            "Hint successfully completed within time limit. Status: %s",
            solver.status_name(status),
        )
    else:
        logging.warning(
            "Unable to complete hint within time limit. Status: %s",
            solver.status_name(status),
        )

```

> [!WARNING]
>
> Під час presolve модель змінюється. Наприклад, симетрії можуть бути зламані
> шляхом заборони еквівалентних варіантів одного розв’язку. Хоча це може
> суттєво покращити продуктивність, це ускладнює збереження допустимості hints,
> наприклад, якщо підказка відповідає «обрізаній» варіації.
>
> На жаль, CP-SAT історично мав труднощі зі збереженням допустимості hints під
> час presolve. Хоча деякі проблеми вже виправлені, я досі бачу цю поведінку у
> свіжих релізах.
>
> Як обхідний шлях, можна змусити CP-SAT зберігати всі допустимі розв’язки під
> час presolve:
>
> ```python
> solver.parameters.keep_all_feasible_solutions_in_presolve = True
> ```
>
> Але цей параметр може погіршити продуктивність. Якщо помічаєте, що hints
> стають недопустимими після presolve, експериментально визначте, що краще:
> зберігати hints чи повноцінний presolve.

## Посилення моделі

Для просунутих користувачів, які працюють із CP-SAT інкрементально — тобто
модифікують і розв’язують модель багато разів — може бути цікавим параметр:

```python
solver.parameters.fill_tightened_domains_in_response = True
```

Коли ви прибираєте цільову функцію і розв’язуєте задачу на здійсненність,
solver повертає звужені домени змінних. Це може суттєво зменшити простір пошуку,
покращивши продуктивність, особливо якщо ви розв’язуєте модель багато разів із
різними цілями чи додатковими обмеженнями.

Однак, якщо цільова функція залишається, деякі допустимі розв’язки можуть бути
виключені. Вони можуть стати релевантними, якщо цілі чи обмеження зміняться
пізніше.

Увімкнення цього параметра не змінює модель; він лише повертає список звужених
доменів у response об’єкті, які ви можете використати в моделі.

```python
# Приклад після розв’язання
for i, v in enumerate(self.model.proto.variables):
    print(f"Tightened domain for variable {i} '{v.name}' is {solver.response_proto.tightened_variables[i].domain}")
```

### Припущення

Ще один спосіб дослідити вплив фіксації змінних — це припущення, що є типовою
функцією в SAT-розв’язувачах. На відміну від фіксації hints, припущення
обмежені булевими літералами в CP-SAT.

```python
b1 = model.new_bool_var("b1")
b2 = model.new_bool_var("b2")
b3 = model.new_bool_var("b3")

model.add_assumptions([b1, ~b2])  # припускаємо b1=True, b2=False
model.add_assumption(b3)  # припускаємо b3=True (один літерал)
# ... solve again and analyze ...
model.clear_assumptions()  # очищаємо припущення
```

> [!NOTE]
>
> Інкрементальні SAT-розв’язувачі можуть повторно використовувати вивчені
> клаузи між запуском за різних припущень. CP-SAT цього не підтримує. Його
> solver — безстанний і завжди починає з нуля.

Хоча припущення дозволяють досліджувати різні присвоєння булевих змінних без
перебудови моделі, CP-SAT має потужнішу можливість: витягнення unsat core з
недопустимих моделей. Це особливо корисно для налагодження. Умикаючи
обмеження умовно через `only_enforce_if(b)` і додаючи `b` як припущення, можна
ізолювати джерела недопустимості. Якщо модель недопустима, CP-SAT може
повернути мінімальний набір припущень (і відповідних обмежень), що спричиняють
конфлікт.

Розгляньмо приклад. Маємо три цілочисельні змінні $x$, $y$, $z$ і обмеження:

1. $x + y \leq 4$
2. $x + z \leq 2$
3. $z \geq 4$

За умови невід’ємності змінних модель явно недопустима через конфлікт між (2)
і (3). У великих моделях знайти джерело недопустимості складно. Але з
припущеннями і `sufficient_assumptions_for_infeasibility` CP-SAT може
автоматично показати, які обмеження винні.

```python
from ortools.sat.python import cp_model

model = cp_model.CpModel()

# Цілочисельні змінні
x = model.new_int_var(0, 100, 'x')
y = model.new_int_var(0, 100, 'y')
z = model.new_int_var(0, 100, 'z')

# Обмеження
indicator_1 = model.new_bool_var('Indicator 1: x + y <= 4')
model.add(x + y <= 4).only_enforce_if(indicator_1)
indicator_2 = model.new_bool_var('Indicator 2: x + z <= 2')
model.add(x + z <= 2).only_enforce_if(indicator_2)
indicator_3 = model.new_bool_var('Indicator 3: z >= 4')
model.add(z >= 4).only_enforce_if(indicator_3)

# Припущення
model.add_assumptions([indicator_1, indicator_2, indicator_3])

# Розв’язання
solver = cp_model.CpSolver()
status = solver.solve(model)

assert status == cp_model.INFEASIBLE

print("Minimal unsat core:")
for var_index in solver.sufficient_assumptions_for_infeasibility():
    print(f"{var_index}: '{model.proto.variables[var_index].name}'")
```

Результат:

```
Minimal unsat core:
4: 'Indicator 2: x + z <= 2'
5: 'Indicator 3: z >= 4'
```

На жаль, не всі обмеження в CP-SAT підтримують реїфікацію. Проте нижчорівневі
обмеження, де недопустимість найімовірніша, зазвичай підтримують. Для
високорівневих обмежень можуть існувати обхідні перетворення.

> [!NOTE]
>
> Більше інформації у
> [документації CPMpy](https://cpmpy.readthedocs.io/en/latest/unsat_core_extraction.html),
> бібліотеки моделювання з підтримкою CP-SAT як бекенду.

### Presolve

CP-SAT має етап presolve, який спрощує модель перед розв’язанням. Це може
суттєво зменшити простір пошуку і покращити продуктивність. Однак presolve може
бути дорогим, особливо для великих моделей. Якщо ваша модель відносно проста
(тобто є небагато складних рішень), і ви бачите, що presolve займає багато
часу, а сам пошук швидкий — можна зменшити presolve.

Наприклад, presolve можна повністю вимкнути:

```python
solver.parameters.cp_model_presolve = False
```

Але це надто радикально, тож можна лише обмежити presolve, а не вимикати.

Щоб зменшити кількість ітерацій presolve, використовуйте:

```python
solver.parameters.max_presolve_iterations = 3
```

Також можна обмежити конкретні техніки presolve, наприклад probing, який
фіксує змінні та дивиться результат. Probing потужний, але затратний.

```python
solver.parameters.cp_model_probing_level = 1
solver.parameters.presolve_probing_deterministic_time_limit = 5
```

Є додаткові параметри для керування presolve. Перед змінами рекомендую
переглянути лог, щоб зрозуміти, що саме забирає час.

Пам’ятайте: зменшення presolve може погіршити здатність розв’язувати складні
моделі. Не жертвуйте продуктивністю на складних інстансах лише заради швидких
простих випадків.

### Додавання власного сабсолвера до портфеля

Як ми бачили, CP-SAT використовує портфель сабсолверів із різними налаштуваннями
(наприклад, різним рівнем лінеаризації). Ви можете задати свій сабсолвер із
певною конфігурацією. Важливо не змінювати параметри на верхньому рівні, бо це
вплине на всі сабсолвери, включно з LNS. Це може зруйнувати баланс портфеля,
увімкнувши дорогі техніки для LNS, що сповільнить їх до непридатності. Також
ви ризикуєте створити сабсолвер за замовчуванням, несумісний з моделлю
(наприклад, якщо він вимагає ціль), і тоді CP-SAT може виключити більшість або
усі сабсолвери, зробивши solver неефективним або неспроможним.

Наприклад, у задачах пакування деякі дорогі техніки пропагації можуть сильно
прискорити пошук, але при неправильному використанні — сильно сповільнити.
Тому можна додати один сабсолвер із цими техніками. Якщо вони не допоможуть,
сповільниться лише один воркер, а решта портфеля працюватиме нормально. Якщо ж
допоможуть — цей воркер зможе ділитися розв’язками та межами з іншими,
покращуючи загальну продуктивність.

Ось як додати власний сабсолвер:

```python
from ortools.sat import sat_parameters_pb2

packing_subsolver = sat_parameters_pb2.SatParameters()
packing_subsolver.name = "MyPackingSubsolver"
packing_subsolver.use_area_energetic_reasoning_in_no_overlap_2d = True
packing_subsolver.use_energetic_reasoning_in_no_overlap_2d = True
packing_subsolver.use_timetabling_in_no_overlap_2d = True
packing_subsolver.max_pairs_pairwise_reasoning_in_no_overlap_2d = 5_000

# Додаємо сабсолвер до портфеля
solver.parameters.subsolver_params.append(packing_subsolver)  # Визначення
solver.parameters.extra_subsolvers.append(
    packing_subsolver.name
)  # Активація
```

Після додавання перевірте в логах, чи сабсолвер активний. Якщо його немає,
ймовірно, параметри несумісні з моделлю, і його виключили.

```
8 full problem subsolvers: [MyPackingSubsolver, default_lp, max_lp, no_lp, probing, probing_max_lp, quick_restart, quick_restart_no_lp]
```

Якщо хочете дізнатися, як налаштовані існуючі сабсолвери, див. файл
[cp_model_search.cc](https://github.com/google/or-tools/blob/stable/ortools/sat/cp_model_search.cc)
в репозиторії OR-Tools.

> [!TIP]
>
> Ви також можете перевизначити параметри існуючого сабсолвера, використавши
> те саме ім’я. Зміняться лише параметри, які ви явно задаєте. Також можна
> додати кілька сабсолверів у портфель, але майте на увазі, що це може
> «виштовхнути» деякі попередньо визначені сабсолвери, якщо воркерів
> недостатньо.

### Стратегія рішень

Наприкінці цього розділу — параметр, який може бути цікавим для просунутих
користувачів, бо дає уявлення про алгоритм пошуку. Його можна використовувати
разом із `solver.parameters.enumerate_all_solutions = True` щоб задати порядок
перебору рішень. Це може впливати на продуктивність, але передбачити це складно,
тому не змінюйте параметри без вагомої причини.

Ми можемо вказати CP-SAT, як розгалужуватися, коли пропагація більше нічого не
дедукує. Для цього потрібен список змінних (порядок може бути важливим),
стратегія вибору змінної (зафіксовані змінні автоматично пропускаються) і
стратегія вибору значення.

Варіанти вибору змінної:

- `CHOOSE_FIRST`: перша незакріплена змінна у списку.
- `CHOOSE_LOWEST_MIN`: змінна, що потенційно може мати найменше значення.
- `CHOOSE_HIGHEST_MAX`: змінна, що потенційно може мати найбільше значення.
- `CHOOSE_MIN_DOMAIN_SIZE`: змінна з найменшим доменом.
- `CHOOSE_MAX_DOMAIN_SIZE`: змінна з найбільшим доменом.

Варіанти вибору значення/діапазону:

- `SELECT_MIN_VALUE`: пробуємо найменше значення.
- `SELECT_MAX_VALUE`: пробуємо найбільше значення.
- `SELECT_LOWER_HALF`: беремо нижню половину.
- `SELECT_UPPER_HALF`: беремо верхню половину.
- `SELECT_MEDIAN_VALUE`: пробуємо медіану.

```python
model.add_decision_strategy([x], cp_model.CHOOSE_FIRST, cp_model.SELECT_MIN_VALUE)

# можна змусити CP-SAT слідувати цій стратегії точно
solver.parameters.search_branching = cp_model.FIXED_SEARCH
```

Наприклад, для [розфарбування графа](https://en.wikipedia.org/wiki/Graph_coloring)
(з цілими кольорами) ми можемо впорядкувати змінні за спаданням степеня
(через `CHOOSE_FIRST`) і завжди пробувати найменший колір (`SELECT_MIN_VALUE`).
Це дає неявну kernelization: якщо потрібно щонайменше $k$ кольорів, вершини з
менш ніж $k$ сусідами тривіальні. Розміщуючи їх наприкінці списку, CP-SAT
розглядатиме їх лише після розфарбування вершин з більшим степенем. Інша
стратегія — `CHOOSE_LOWEST_MIN`, щоб завжди брати вершину з найменшим доступним
кольором. Чи допоможе це — треба перевіряти: CP-SAT часто сам знаходить критичні
вершини через конфлікти.

> [!WARNING]
>
> Я трохи експериментував із ручними стратегіями. Навіть для розфарбування,
> де це здається логічним, це дало перевагу лише для поганої моделі. Після
> покращення моделі через розбиття симетрії результат став гіршим. Я також
> припускаю, що CP-SAT сам динамічно навчається найкращій стратегії (як це
> робить Gurobi) краще, ніж статичні ручні налаштування.

---

<!-- This file was generated by the `build.py` script. Do not edit it manually. -->
<!-- understanding_the_log.md -->
<a name="understanding-the-log"></a>

## Understanding the CP-SAT Log


If you want to master CP-SAT, understanding the log is crucial. The log is the
output of the solver that shows you what the solver is doing and how it is
progressing.

The log consists of different parts. Let us go through them step by step.

> [!TIP]
>
> Use the [Log Analyzer](https://cpsat-log-analyzer.streamlit.app/) to get your
> own logs explained to you.
>
> [![Streamlit App](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://cpsat-log-analyzer.streamlit.app/)
>
> [![d-krupke - CP-SAT Log Analyzer](https://img.shields.io/badge/d--krupke-CP--SAT%20Log%20Analyzer-blue?style=for-the-badge&logo=github)](https://github.com/d-krupke/CP-SAT-Log-Analyzer)

As a reminder, you activate logging with

```python
solver.parameters.log_search_progress = True  # Enable logging
```

### Initialization

The log starts with the version of CP-SAT, the parameters you set, and how many
workers it has been using. For example, we have set a time limit via
`max_time_in_seconds` to 30 seconds. If you are given a log, you can directly
see under which conditions the solver was running.

```
Starting CP-SAT solver v9.10.4067
Parameters: max_time_in_seconds: 30 log_search_progress: true relative_gap_limit: 0.01
Setting number of workers to 16
```

### Initial Model Description

The next block provides an overview of the model before presolve, detailing the
number of variables and constraints, as well as their coefficients and domains.

```
Initial optimization model '': (model_fingerprint: 0x1d316fc2ae4c02b1)
#Variables: 450 (#bools: 276 #ints: 6 in objective)
  - 342 Booleans in [0,1]
  - 12 in [0][10][20][30][40][50][60][70][80][90][100]
  - 6 in [0][10][20][30][40][100]
  - 6 in [0][80][100]
  - 6 in [0][100]
  - 6 in [0,1][34][67][100]
  - 12 in [0,6]
  - 18 in [0,7]
  - 6 in [0,35]
  - 6 in [0,36]
  - 6 in [0,100]
  - 12 in [21,57]
  - 12 in [22,57]
#kBoolOr: 30 (#literals: 72)
#kLinear1: 33 (#enforced: 12)
#kLinear2: 1'811
#kLinear3: 36
#kLinearN: 94 (#terms: 1'392)
```

For example, `- 12 in [22,57]` indicates that there are 12 variables with a
domain of `[22,57]`, meaning their values can range between 22 and 57.

Similarly, `#kLinearN: 94 (#terms: 1'392)` indicates the presence of 94 linear
constraints with 1,392 coefficients.

Comparing this data to the model after presolve (coming up soon) is useful to
ensure it aligns with your expectations. The presolve phase often reformulates
your model extensively to enhance efficiency.

Since most optimization models are created dynamically in code, reviewing this
section can help identify bugs or inefficiencies. Take the time to verify that
the numbers match your expectations and ensure you do not have too many or too
few variables or constraints of a certain type. This step is crucial as it also
provides insight into the number of auxiliary variables in your model, helping
you better understand its structure and complexity.

### Presolve Log

The next block represents the presolve phase, an essential component of CP-SAT.
During this phase, the solver reformulates your model for greater efficiency.
For instance, it may detect an affine relationship between variables, such as
`x=2y-1`, and replace `x` with `2y-1` in all constraints. It can also identify
and remove redundant constraints or unnecessary variables. For example, the log
entry `rule 'presolve: 33 unused variables removed.' was applied 1 time` may
indicate that some variables created by your code were unnecessary or became
redundant due to the reformulation. Multiple rounds of applying various rules
for domain reduction, expansion, equivalence checking, substitution, and probing
are performed during presolve. These rules can significantly enhance the
efficiency of your model, though they may take some time to run. However, this
time investment usually pays off during the search phase.

```
Starting presolve at 0.00s
  3.26e-04s  0.00e+00d  [DetectDominanceRelations]
  6.60e-03s  0.00e+00d  [PresolveToFixPoint] #num_loops=4 #num_dual_strengthening=3
  2.69e-05s  0.00e+00d  [ExtractEncodingFromLinear] #potential_supersets=44 #potential_subsets=12
[Symmetry] Graph for symmetry has 2'224 nodes and 5'046 arcs.
[Symmetry] Symmetry computation done. time: 0.000374304 dtime: 0.00068988
[Symmetry] #generators: 2, average support size: 12
[Symmetry] 12 orbits with sizes: 2,2,2,2,2,2,2,2,2,2,...
[Symmetry] Found orbitope of size 6 x 2
[SAT presolve] num removable Booleans: 0 / 309
[SAT presolve] num trivial clauses: 0
[SAT presolve] [0s] clauses:570 literals:1152 vars:303 one_side_vars:268 simple_definition:35 singleton_clauses:0
[SAT presolve] [3.0778e-05s] clauses:570 literals:1152 vars:303 one_side_vars:268 simple_definition:35 singleton_clauses:0
[SAT presolve] [4.6758e-05s] clauses:570 literals:1152 vars:303 one_side_vars:268 simple_definition:35 singleton_clauses:0
  1.10e-02s  9.68e-03d  [Probe] #probed=1'738 #new_bounds=12 #new_binary_clauses=1'111
  2.34e-03s  0.00e+00d  [MaxClique] Merged 602(1374 literals) into 506(1960 literals) at_most_ones.
  3.31e-04s  0.00e+00d  [DetectDominanceRelations]
  1.89e-03s  0.00e+00d  [PresolveToFixPoint] #num_loops=2 #num_dual_strengthening=1
  5.45e-04s  0.00e+00d  [ProcessAtMostOneAndLinear]
  8.19e-04s  0.00e+00d  [DetectDuplicateConstraints] #without_enforcements=306
  8.62e-05s  7.21e-06d  [DetectDominatedLinearConstraints] #relevant_constraints=114 #num_inclusions=42
...

Presolve summary:
  - 54 affine relations were detected.
  - rule 'TODO dual: make linear1 equiv' was applied 6 times.
  - rule 'TODO dual: only one blocking constraint?' was applied 1'074 times.
  - rule 'TODO dual: only one unspecified blocking constraint?' was applied 48 times.
  - rule 'TODO duplicate: identical constraint with different enforcements' was applied 612 times.
  - rule 'TODO linear2: contains a Boolean.' was applied 1'626 times.
  - rule 'TODO symmetry: add symmetry breaking inequalities?' was applied 2 times.
...
  - rule 'objective: variable not used elsewhere' was applied 15 times.
  - rule 'presolve: 33 unused variables removed.' was applied 1 time.
  - rule 'presolve: iteration' was applied 2 times.
  - rule 'variables with 2 values: create encoding literal' was applied 12 times.
  - rule 'variables with 2 values: new affine relation' was applied 12 times.
  - rule 'variables: canonicalize affine domain' was applied 30 times.
  - rule 'variables: detect half reified value encoding' was applied 54 times.
```

The presolve log can be challenging to read, but it provides vital information
on the simplifications and optimizations made by CP-SAT. Reviewing this log can
help you understand the transformations applied to your model, allowing you to
identify and address any unnecessary variables or constraints in your code.

### Presolved Model

This is the most important block of the presolve phase and gives an overview of
the model after presolve. It contains the number of variables and constraints,
as well as coefficients and domains.

`- 200 in [0,199]` will indicate that there are 200 variables with domain
`[0,199]`, i.e., values between 0 and 199. `- 6 in [0,1][34][67][100]` will
indicate that there are 6 variables with domain `[0,1][34][67][100]`, i.e.,
values 0, 1, 34, 67, and 100. `#kLinearN: 3'000 (#terms: 980'948)` indicates
that there are 3000 linear constraints with 980'948 coefficients.

It is useful to compare this to the initial model, to see if your model was
simplified by presolve, which indicates that you can simplify your model
yourself, saving presolve time. If you notice that a lot of time is spent in
presolve but it does not simplify your model, you can try to disable/reduce
presolve.

It is also interesting to see if the presolve replaced some of your constraints
with more efficient ones.

```
Presolved optimization model '': (model_fingerprint: 0xb4e599720afb8c14)
#Variables: 405 (#bools: 261 #ints: 6 in objective)
  - 309 Booleans in [0,1]
  - 12 in [0][2,6]
  - 6 in [0][4,5]
  - 6 in [0,3]
  - 6 in [0,4]
  - 6 in [0,6]
  - 6 in [0,7]
  - 12 in [0,10]
  - 12 in [0,13]
  - 6 in [0,100]
  - 12 in [21,57]
  - 12 in [22,57]
#kAtMostOne: 452 (#literals: 1'750)
#kBoolAnd: 36 (#enforced: 36) (#literals: 90)
#kBoolOr: 12 (#literals: 36)
#kLinear1: 854 (#enforced: 854)
#kLinear2: 42
#kLinear3: 24
#kLinearN: 48 (#enforced: 18) (#terms: 1'046)
```

> [!NOTE]
>
> This is the same model as in the initial model description. Take some time to
> compare the two and see how much the presolve-phase has reformulated the
> model.

### Preloading Model

This block serves as a prelude to the search phase and provides an overview of
the model at the beginning of the search. Typically, this information is not
very interesting unless the presolve phase was highly effective, essentially
solving the model before the search phase begins. This can lead to entries that
look very similar to that of the actual search phase, which comes next.

```
Preloading model.
#Bound   0.05s best:-inf  next:[-0.7125]  initial_domain
[Symmetry] Graph for symmetry has 2,111 nodes and 5,096 arcs.
[Symmetry] Symmetry computation done. time: 0.000365377 dtime: 0.00068122
[Symmetry] #generators: 2, average support size: 12
[Symmetry] Found orbitope of size 6 x 2
#Model   0.05s var:405/405 constraints:1468/1468
```

### Search Phase

The search progress log is an essential element of the overall log, crucial for
identifying performance bottlenecks. It clearly demonstrates the solver's
progression over time and pinpoints where it faces significant challenges. It is
important to discern whether the upper or lower bounds are causing issues, or if
the solver initially finds a near-optimal solution but struggles to minimize a
small remaining gap.

> [!WARNING]
>
> For models without an objective, especially the log of the search phase will
> look very different. This chapter focuses on models with an objective.

The structure of the log entries is standardized as follows:

```
EVENT NAME | TIME  | BEST SOLUTION | RANGE OF THE SEARCH | COMMENT
```

For instance, an event marked `#2` indicates the discovery of the second
solution. Here, you will observe an improvement in the `BEST SOLUTION` metric. A
notation like `best:16` confirms that the solver has found a solution with a
value of 16.

An event with `#Bound` denotes an enhancement in the bound, as seen by a
reduction in the `RANGE OF THE SEARCH`. A detail such as `next:[7,14]` signifies
that the solver is now focused on finding a solution valued between 7 and 14.

The `COMMENT` section provides essential information about the strategies that
led to these improvements.

Events labeled `#Model` signal modifications to the model, such as fixing
certain variables.

```
Starting search at 0.05s with 16 workers.
11 full problem subsolvers: [core, default_lp, lb_tree_search, max_lp, no_lp, objective_lb_search, probing, pseudo_costs, quick_restart, quick_restart_no_lp, reduced_costs]
4 first solution subsolvers: [fj_long_default, fj_short_default, fs_random, fs_random_quick_restart]
9 incomplete subsolvers: [feasibility_pump, graph_arc_lns, graph_cst_lns, graph_dec_lns, graph_var_lns, rins/rens, rnd_cst_lns, rnd_var_lns, violation_ls]
3 helper subsolvers: [neighborhood_helper, synchronization_agent, update_gap_integral]
#1       0.06s best:-0    next:[1,7125]   fj_short_default(batch:1 #lin_moves:0 #lin_evals:0 #weight_updates:0)
#2       0.07s best:1050  next:[1051,7125] fj_long_default(batch:1 #lin_moves:1'471 #lin_evals:2'102 #weight_updates:123)
#3       0.08s best:1051  next:[1052,7125] quick_restart_no_lp (fixed_bools=0/884)
#Bound   0.09s best:1051  next:[1052,1650] default_lp
#4       0.10s best:1052  next:[1053,1650] quick_restart_no_lp (fixed_bools=22/898)
#5       0.10s best:1053  next:[1054,1650] quick_restart_no_lp (fixed_bools=22/901)
#6       0.11s best:1055  next:[1056,1650] quick_restart_no_lp (fixed_bools=22/906)
#7       0.11s best:1056  next:[1057,1650] quick_restart_no_lp (fixed_bools=22/909)
#8       0.11s best:1057  next:[1058,1650] quick_restart_no_lp (fixed_bools=22/913)
#9       0.11s best:1058  next:[1059,1650] quick_restart_no_lp (fixed_bools=22/914)
#10      0.12s best:1059  next:[1060,1650] quick_restart_no_lp (fixed_bools=26/916)
#11      0.12s best:1060  next:[1061,1650] quick_restart_no_lp (fixed_bools=26/917)
#12      0.12s best:1061  next:[1062,1650] quick_restart_no_lp (fixed_bools=26/918)
#13      0.13s best:1062  next:[1063,1650] quick_restart_no_lp (fixed_bools=28/918)
#14      0.13s best:1063  next:[1064,1650] quick_restart_no_lp (fixed_bools=28/921)
#Bound   0.13s best:1063  next:[1064,1579] lb_tree_search
#15      0.13s best:1064  next:[1065,1579] quick_restart_no_lp (fixed_bools=28/924)
#Model   0.13s var:404/405 constraints:1435/1468
#16      0.13s best:1065  next:[1066,1579] quick_restart_no_lp (fixed_bools=28/930)
#17      0.13s best:1066  next:[1067,1579] quick_restart_no_lp (fixed_bools=28/932)
#18      0.14s best:1067  next:[1068,1579] quick_restart_no_lp (fixed_bools=28/935)
#19      0.14s best:1071  next:[1072,1579] quick_restart_no_lp (fixed_bools=28/946)
#20      0.15s best:1072  next:[1073,1579] quick_restart_no_lp (fixed_bools=28/950)
#21      0.15s best:1089  next:[1090,1579] quick_restart_no_lp (fixed_bools=28/966)
#22      0.15s best:1090  next:[1091,1579] quick_restart_no_lp (fixed_bools=28/966)
...
#Bound   8.73s best:1449  next:[1450,1528] lb_tree_search (nodes=13/18 rc=0 decisions=133 @root=28 restarts=0)
#Model   8.99s var:390/405 constraints:1292/1468
#Bound   9.37s best:1449  next:[1450,1527] lb_tree_search (nodes=15/20 rc=0 decisions=152 @root=28 restarts=0)
#Bound  11.79s best:1449  next:[1450,1526] lb_tree_search (nodes=78/83 rc=0 decisions=327 @root=28 restarts=0)
#Bound  12.40s best:1449  next:[1450,1525] lb_tree_search (nodes=96/104 rc=0 decisions=445 @root=28 restarts=0)
#Bound  13.50s best:1449  next:[1450,1524] lb_tree_search (nodes=123/138 rc=0 decisions=624 @root=28 restarts=0)
#Bound  15.71s best:1449  next:[1450,1523] lb_tree_search (nodes=164/180 rc=0 decisions=847 @root=29 restarts=0)
#132    16.69s best:1450  next:[1451,1523] rnd_var_lns (d=0.88 s=657 t=0.10 p=0.54 stall=53 h=folio_rnd)
#Bound  17.13s best:1450  next:[1451,1522] lb_tree_search (nodes=176/192 rc=0 decisions=1001 @root=30 restarts=0)
#Model  17.85s var:389/405 constraints:1289/1468
#Bound  19.35s best:1450  next:[1451,1521] lb_tree_search (nodes=44/44 rc=0 decisions=1112 @root=33 restarts=1)
#Bound  20.12s best:1450  next:[1451,1520] lb_tree_search (nodes=53/53 rc=0 decisions=1176 @root=34 restarts=1)
#Bound  22.08s best:1450  next:[1451,1519] lb_tree_search (nodes=114/114 rc=0 decisions=1369 @root=35 restarts=1)
#Bound  23.92s best:1450  next:[1451,1518] lb_tree_search (nodes=131/131 rc=0 decisions=1517 @root=36 restarts=1)
#Bound  25.84s best:1450  next:[1451,1517] lb_tree_search (nodes=174/174 rc=0 decisions=1754 @root=36 restarts=1)
#Bound  29.35s best:1450  next:[1451,1515] objective_lb_search
```

As this log is event-driven, it can be challenging to interpret. The
[Log Analyzer](https://cpsat-log-analyzer.streamlit.app/) helps by automatically
plotting these values in a more understandable way. Since the values at the
beginning of the search are often out of scale, use the zoom function to focus
on the relevant parts of the search.

| ![Search Progress](https://raw.githubusercontent.com/d-krupke/cpsat-primer/main/images/search_progress_plot_1.png) | ![Optimality Gap](https://raw.githubusercontent.com/d-krupke/cpsat-primer/main/images/search_progress_plot_2.png) | ![Model Changes](https://raw.githubusercontent.com/d-krupke/cpsat-primer/main/images/search_progress_plot_3.png) |
| :----------------------------------------------------------------------------------------------------------------: | :---------------------------------------------------------------------------------------------------------------: | :--------------------------------------------------------------------------------------------------------------: |
|                               Shows how the lower and upper bounds change over time.                               |                                  Shows how quickly the optimality gap converges.                                  |     Shows how the model changes over time as new insights from the search allow the solver to fix variables.     |

### Subsolver Details

Now there comes a lot of information about the different subsolvers that are
used. This is a very detailed part of the log and can be overwhelming. You
already need to be rather deep into the details of CP-SAT to actually make any
use of this information. It is primarily intended for the developers of CP-SAT.
It gives you insights into how the various subsolvers have been contributing to
the solution, how the otherwise hidden LP-techniques, including cutting planes,
have been used, and how the different heuristics have been applied. Based on
this data, you could try to tune the various parameters of CP-SAT for your
problem. However, note that you will probably need a lot of experience and
experiments to gain an advantage compared to the default settings.

```
Task timing                          n [     min,      max]      avg      dev     time         n [     min,      max]      avg      dev    dtime
                     'core':         1 [  29.95s,   29.95s]   29.95s   0.00ns   29.95s         1 [  27.99s,   27.99s]   27.99s   0.00ns   27.99s
               'default_lp':         1 [  29.94s,   29.94s]   29.94s   0.00ns   29.94s         1 [  21.11s,   21.11s]   21.11s   0.00ns   21.11s
         'feasibility_pump':       123 [  4.51ms,  70.61ms]  38.93ms   9.87ms    4.79s       122 [  6.31ms,  41.77ms]  17.96ms   6.53ms    2.19s
          'fj_long_default':         1 [ 10.28ms,  10.28ms]  10.28ms   0.00ns  10.28ms         1 [  2.08ms,   2.08ms]   2.08ms   0.00ns   2.08ms
         'fj_short_default':         1 [579.83us, 579.83us] 579.83us   0.00ns 579.83us         0 [  0.00ns,   0.00ns]   0.00ns   0.00ns   0.00ns
                'fs_random':         1 [  6.57ms,   6.57ms]   6.57ms   0.00ns   6.57ms         1 [ 20.00ns,  20.00ns]  20.00ns   0.00ns  20.00ns
  'fs_random_quick_restart':         1 [  6.82ms,   6.82ms]   6.82ms   0.00ns   6.82ms         1 [ 20.00ns,  20.00ns]  20.00ns   0.00ns  20.00ns
            'graph_arc_lns':       123 [  3.65ms, 430.55ms] 169.44ms 106.16ms   20.84s       123 [ 10.00ns, 119.31ms]  61.95ms  43.70ms    7.62s

...

Clauses shared            Num
                 'core':  137
           'default_lp':    1
       'lb_tree_search':    4
               'max_lp':    1
                'no_lp':   10
  'objective_lb_search':    3
         'pseudo_costs':    4
        'quick_restart':    4
  'quick_restart_no_lp':   74
        'reduced_costs':    2
```

### Summary

This final block of the log contains a summary by the solver. Here you find the
most important information, such as how successful the search was.

You can find the original documentation
[here](https://github.com/google/or-tools/blob/8768ed7a43f8899848effb71295a790f3ecbe2f2/ortools/sat/cp_model.proto#L720).

```
CpSolverResponse summary:
status: FEASIBLE  # The status of the search. Can be FEASIBLE, OPTIMAL, INFEASIBLE, UNKNOWN, or MODEL_INVALID.
objective: 1450  # The value of the objective function for the best solution found.
best_bound: 1515  # The proven bound on the objective function, i.e., the best possible value.
integers: 416
booleans: 857
conflicts: 0
branches: 370
propagations: 13193
integer_propagations: 6897
restarts: 370
lp_iterations: 0
walltime: 30.4515  # The time in seconds since solver creation.
usertime: 30.4515
deterministic_time: 306.548
gap_integral: 1292.47  # The integral of the gap over time. A lower value will indicate that the solver is converging faster.
solution_fingerprint: 0xf10c47f1901c2c16  # Useful to check if two runs result in the same solution.
```

<!-- This file was generated by the `build.py` script. Do not edit it manually. -->
<!-- ./chapters/07_under_the_hood.md -->
<!-- EDIT THIS PART VIA 07_under_the_hood.md -->

<a name="07-under-the-hood"></a>

## Як це працює?


CP-SAT — це універсальний _портфельний_ розв’язувач, у центрі якого —
Constraint Programming Solver на базі _Lazy Clause Generation (LCG)_, хоча він
включає значно ширший набір технологій.

Як портфельний розв’язувач, CP-SAT одночасно запускає багато різних алгоритмів і
стратегій, кожна зі своїми сильними й слабкими сторонами. Ці компоненти працюють
здебільшого незалежно, але обмінюються інформацією, коли з’являються кращі
розв’язки або більш тісні межі.

На перший погляд це може здатися неефективним через дублювання, але на практиці
підхід дуже ефективний. Причина — складність передбачення, який алгоритм найкраще
підійде для конкретної задачі (теорема «No Free Lunch»). Тому практична стратегія
— запускати різні підходи паралельно, сподіваючись, що один із них спрацює. Ви
також можете вказати, які алгоритми використовувати, якщо вже знаєте, які
перспективні або марні.

На відміну від цього, MIP-розв’язувачі на базі Branch and Cut, як-от Gurobi,
ефективніше ділять простір пошуку, зменшуючи дублювання. Але вони спеціалізуються
на конкретній стратегії, яка не завжди найкраща, хоча часто і є такою.

CP-SAT використовує Branch and Cut техніки, включно з лінійними релаксаціями та
площинами відсікання, як частину свого арсеналу. Моделі, які добре розв’язуються
MIP-розв’язувачами, зазвичай добре підходять і для CP-SAT. Проте основний фокус
CP-SAT — Lazy Clause Generation, яка спирається на SAT-розв’язувачі, а не на
лінійні релаксації. Через це CP-SAT може бути дещо повільнішим на класичних MIP
задачах, ніж спеціалізовані MIP-розв’язувачі. Зате він має суттєву перевагу в
задачах із великою кількістю складних логічних обмежень.

Ідея Lazy Clause Generation — (інкрементально) перетворювати задачу у SAT-формулу
і використовувати SAT-розв’язувач для пошуку розв’язку (або доведення меж через
недопустимість). Щоб уникнути непродуктивної «прямої» конверсії, LCG
використовує багато лінивих змінних і клауз.

Зокрема, теорема
[Cook-Levin](https://en.wikipedia.org/wiki/Cook%E2%80%93Levin_theorem)
показує, що будь-яку NP-задачу можна звести до SAT. Теоретично оптимізацію можна
реалізувати через двійковий пошук. Але цей підхід хоч і коректний, та
неефективний. CP-SAT використовує більш витончене кодування для оптимізації.

Якщо хочете зрозуміти внутрішню кухню CP-SAT, можна пройти такий шлях навчання:

1. Навчитися знаходити допустимий розв’язок на базі булевої логіки з
   SAT-розв’язувачами: Backtracking, DPLL, CDCL, VSIDS, ...
   - [Історичний огляд від Armin Biere](https://youtu.be/DU44Y9Pt504) (відео)
   - [Donald Knuth - The Art of Computer Programming, Volume 4, Fascicle 6: Satisfiability](https://www-cs-faculty.stanford.edu/~knuth/taocp.html)
     (книга)
   - [Carsten Sinz and Tomas Baylo - Practical SAT Solving](https://baldur.iti.kit.edu/sat/#about)
     (слайди)
2. Навчитися знаходити доведено оптимальні розв’язки через класичне
   змішане цілочисельне програмування:
   - Лінійне програмування: Simplex, Duality, Dual Simplex, ...
     - [Understanding and Using Linear Programming](https://link.springer.com/book/10.1007/978-3-540-30717-4)
       (книга)
     - [Optimization in Operations Research by Ronald Rardin](https://www.pearson.com/en-us/subject-catalog/p/optimization-in-operations-research/P200000003508/9780137982066)
       (дуже велика книга, також про MIP, евристики й просунуті теми)
     - [Відеосерія від Gurobi](https://www.youtube.com/playlist?list=PLHiHZENG6W8BeAfJfZ3myo5dsSQjEV5pJ)
   - Змішане цілочисельне програмування: Branch and Bound, Cutting Planes,
     Branch and Cut, ...
     - [Discrete Optimization на Coursera з Pascal Van Hentenryck і Carleton Coffrin](https://www.coursera.org/learn/discrete-optimization)
       (відеокурс, також про CP і евристики)
     - [Ресурси Gurobi](https://www.gurobi.com/resource/mip-basics/) (сайт)
3. Вивчити додаткові концепції LCG Constraint Programming: propagation,
   Lazy Clause Generation, ...
   - [Combinatorial Optimisation and Constraint Programming від Prof. Pierre Flener (Uppsala University)](https://user.it.uu.se/~pierref/courses/COCP/slides/)
     (слайди)
   - [Доповідь Peter Stuckey](https://www.youtube.com/watch?v=lxiCHRFNgno)
     (відео)
   - [Стаття про Lazy Clause Generation](https://people.eng.unimelb.edu.au/pstuckey/papers/cp09-lc.pdf)
     (paper)
4. Вивчити деталі CP-SAT:
   - [Proto-файл параметрів](https://github.com/google/or-tools/blob/stable/ortools/sat/sat_parameters.proto)
     (source)
   - [Повний вихідний код](https://github.com/google/or-tools/tree/stable/ortools/sat)
     (source)
   - [Свіжа доповідь розробників CP-SAT](https://www.youtube.com/live/vvUxusrUcpU?si=qVsXMq0xSOsfghTM)
     (відео)
   - [Інша доповідь розробників CP-SAT](http://egon.cheme.cmu.edu/ewo/video/CP_SAT_LP_google.mp4)
     (відео)
   - [Доповідь розробників CP-SAT](https://youtu.be/lmy1ddn4cyw) (відео)

Якщо у вас вже є досвід MIP, можна відразу перейти до слайдів
[Combinatorial Optimisation and Constraint Programming](https://user.it.uu.se/~pierref/courses/COCP/slides/).
Це повний і детальний курс з constraint programming, і на його проходження
потрібен час. Але він дає знання, необхідні для розуміння CP-SAT.

> Спочатку я написав короткі вступи до кожної теми, але прибрав їх, бо
> матеріали за посиланнями значно кращі. Стару версію можна знайти
> [тут](https://github.com/d-krupke/cpsat-primer/blob/main/old_how_does_it_work.md).

### Що відбувається в CP-SAT під час solve?

Що саме відбувається при `solver.solve(model)`?

1. **Завантаження і перевірка моделі:**

   - Модель читається з protobuf-представлення.
   - Модель перевіряється на коректність.

2. **Попередня обробка (кілька ітерацій, контролюється
   `max_presolve_iterations`):**

   1. **Presolve (зменшення доменів):**
      - Це зменшує розмір задачі, спрощуючи домени змінних. Див.:
        - [Відео про SAT preprocessing](https://www.youtube.com/watch?v=ez9ArInp8w4)
        - [Відео про MaxSAT preprocessing](https://www.youtube.com/watch?v=xLg4hbM8ooM)
        - [Стаття про MIP presolving](https://opus4.kobv.de/opus4-zib/frontdoor/index/index/docId/6037)
   2. **Розгортання високорівневих обмежень:**
      - Високорівневі обмеження перетворюються на нижчорівневі, які CP-SAT може
        ефективно пропагувати, але які менш зручні для запису. Аналогічний
        процес — [FlatZinc і Flattening](https://www.minizinc.org/doc-2.5.5/en/flattening.html).
   3. **Виявлення еквівалентних змінних і афінних зв’язків:**
      - Ідентифікуються афінні зв’язки на кшталт `a * x + b = y`. Детальніше:
        [affine relations](https://personal.math.ubc.ca/~cass/courses/m309-03a/a1/olafson/affine_fuctions.htm).
   4. **Заміна на канонічні представлення:**
      - Виявлені афінні зв’язки замінюються канонічними представленнями.
   5. **Пробінг змінних:**
      - Деякі змінні тестуються, щоб визначити, чи можна їх зафіксувати або
        виявити інші еквівалентності.

3. **Завантаження і релаксація:**

   - Попередньо оброблена модель завантажується у внутрішній solver, і
     створюються лінійні релаксації.

4. **Пошук розв’язку:**

   - Solver шукає розв’язки і межі, доки нижня і верхня межі не збіглися або
     не спрацював інший критерій зупинки (наприклад, ліміт часу).
   - Запускаються кілька повних сабсолверів у різних потоках з різними
     стратегіями:
     - більш лінеаризовані моделі
     - агресивні рестарти
     - фокус на нижній або верхній межі
   - Теоретично кожен сабсолвер може знайти оптимум, але деякі швидші.

5. **Пошук першого розв’язку і локальний пошук:**

   - Додаткові «first solution searchers» запускаються на вільних потоках.
     Вони зупиняються після знаходження допустимого розв’язку.
   - Після цього активуються неповні сабсолвери, що застосовують локальний
     пошук, наприклад Large Neighborhood Search (LNS).
   - Під час кожної ітерації LNS:
     1. Робиться копія моделі, і обирається розв’язок з пулу.
     2. Частина змінних «виймається» (спосіб вибору відрізняється за
        стратегіями). Для цих змінних досліджується околиця.
     3. Решта змінних фіксується у копії моделі.
     4. Спрощена модель проходить presolve, що робить її легшою.
     5. Спрощена модель розв’язується повною стратегією з коротким лімітом
        часу і одним потоком.
     6. Якщо знайдено новий розв’язок, він додається у пул.

6. **Трансформація розв’язку:**
   - Фінальний розв’язок трансформується назад у формат початкової моделі,
     щоб ви могли читати значення змінних у вихідному вигляді.

Це взято з [цієї доповіді](https://youtu.be/lmy1ddn4cyw?t=434) і трохи розширено.

### Використання лінійного програмування

Як уже згадувалося, CP-SAT також використовує (dual) simplex і лінійні
релаксації. Лінійна релаксація реалізована як пропагатор і може виконуватися
на кожному вузлі дерева пошуку, але з найнижчим пріоритетом. Важлива різниця
порівняно з Branch and Bound: виконується лише частина pivot-ітерацій (для
швидкості). Оскільки дерева пошуку можуть бути глибшими і використовується
warm-start, оптимальна лінійна релаксація все одно може бути обчислена, але
глибше у дереві (у SAT-розв’язуванні дерево часто обходиться DFS). На корені
використовуються навіть відсікання на кшталт Gomory-cuts, щоб покращити
лінійну релаксацію.

Лінійна релаксація використовується для виявлення недопустимості (IP можуть
бути потужніші за SAT, принаймні теоретично), для покращення меж цілі і змінних,
а також для прийняття рішень щодо розгалуження (на основі цілі релаксації та
reduced costs).

Використаний Relaxation Induced Neighborhood Search RINS (LNS worker), дуже
успішна евристика, теж використовує лінійне програмування.

### Обмеження CP-SAT

Хоч CP-SAT є дуже потужним solver-ом, він має певні обмеження у порівнянні з
альтернативами:

1. Хоч він ефективний, він може бути повільнішим за спеціалізований SAT-solver
   при розв’язанні SAT-формул, хоча якість все одно дуже висока.
2. Для класичних MIP-задач CP-SAT може не перевершити спеціалізовані
   MIP-розв’язувачі, хоча результати часто все одно хороші.
3. На відміну від MIP/LP-розв’язувачів, CP-SAT не має неперервних змінних, а
   обхідні шляхи не завжди ефективні. Якщо задача здебільшого має неперервні
   змінні та лінійні обмеження, LP-розв’язувач, швидше за все, буде значно
   швидшим.
4. CP-SAT не підтримує lazy constraints або інкрементальне побудування моделі,
   що доступно в MIP/LP-розв’язувачах і деяких SAT-розв’язувачах. Тому
   застосування моделей експоненційного розміру (типових у MIP) може бути
   обмеженим.
5. CP-SAT обмежується Simplex і не має interior point методів. Це означає, що
   він не може використовувати поліноміальні алгоритми для певних класів
   квадратичних обмежень, як-от Second Order Cone. На відміну від нього,
   Gurobi застосовує Barrier алгоритм і розв’язує такі обмеження поліноміально.

CP-SAT також може бути неефективним для деяких обмежень, наприклад modulo.
Втім, мені не відомо жодного альтернативного solver-а, який ефективно працює
з такими обмеженнями. Іноді NP-складні задачі об’єктивно дуже складні, і
доводиться шукати більш зручні моделювальні підходи, а не кращі solver-и.

<!-- This file was generated by the `build.py` script. Do not edit it manually. -->
<!-- ./chapters/03_big_picture.md -->
<!-- EDIT THIS PART VIA 03_big_picture.md -->

<a name="section-alternatives"></a> <a name="03-big-picture"></a>

## Альтернативи: місце CP-SAT у світі оптимізації


Коли ви починаєте досліджувати оптимізацію, то зустрінете безліч інструментів,
технік і спільнот. Це може збивати з пантелику, адже ці групи, маючи багато
спільного, водночас суттєво відрізняються. Вони можуть використовувати ту саму
термінологію для різних понять або різні терміни для однакових понять, що ще
більше плутає. Небагато експертів уміють ефективно орієнтуватися в цих різних
спільнотах і техніках. Часто навіть вузькі спеціалісти, включно з професорами,
зосереджуються на одній техніці чи спільноті й не знають про потенційно
ефективніші методи, розроблені в інших колах.

Якщо вам цікаві зв’язки між різними концепціями оптимізації, перегляньте
доповідь
[Logic, Optimization, and Constraint Programming: A Fruitful Collaboration](https://simons.berkeley.edu/talks/john-hooker-carnegie-mellon-university-2023-04-19)
від John Hooker. Зауважте, що це академічна презентація і вона передбачає певну
обізнаність із теоретичною інформатикою.

Тепер розгляньмо доступні інструменти й техніки та порівняймо їх із CP-SAT.
Будь ласка, пам’ятайте, що це огляд високого рівня і він не є вичерпним. Якщо у
вас є суттєві доповнення — відкрийте issue, і я розгляну можливість їхнього
включення.

- **Змішане цілочисельне (лінійне) програмування (MIP):** MIP — надзвичайно
  ефективний метод для розв’язання різноманітних оптимізаційних задач,
  особливо тих, що стосуються мереж, наприклад задач потоків чи турів. Хоча
  MIP підтримує лише лінійні обмеження, що робить його менш виразним, ніж CP-SAT,
  він часто є найкращим вибором, якщо ваша модель сумісна з такими обмеженнями.
  CP-SAT включає техніки з MIP, але з обмеженнями, зокрема відсутністю
  неперервних змінних і інкрементального моделювання. Тому «чисті» MIP-розв’язувачі,
  як більш спеціалізовані, зазвичай ефективніші для певних застосувань.
  Помітні MIP-розв’язувачі:
  - [Gurobi](https://www.gurobi.com/): комерційний розв’язувач, відомий своїми
    передовими можливостями в MIP. Пропонує безкоштовні академічні ліцензії,
    відмінну продуктивність, зручність використання та сильну підтримку через
    документацію й вебінари з експертами. Особливо вражає здатністю працювати зі
    складними великомасштабними задачами.
  - [SCIP](https://www.scipopt.org/): розв’язувач з відкритим кодом із Python-інтерфейсом.
    Хоча він не такий ефективний і дружній, як Gurobi, SCIP дозволяє глибоку
    кастомізацію і є ідеальним для досліджень та розробки, особливо для експертів,
    яким потрібно реалізовувати складні техніки декомпозиції. Якщо ви вмієте ним
    користуватися, для деяких задач (особливо з Branch and Price) можна досягти
    кращої продуктивності, ніж будь-яким іншим розв’язувачем.
  - [FICO Xpress Optimization](https://www.fico.com/en/products/fico-xpress-optimization):
    ще один популярний комерційний розв’язувач. Багато розробників SCIP зрештою
    переходять працювати або в Gurobi, або в Xpress.
  - [COPT Cardinal Solver](https://www.copt.de/): відносно новий комерційний
    розв’язувач, який, здається, дуже сильний для деяких класів задач.
  - [HiGHS](https://highs.dev/): новіший розв’язувач під ліцензією MIT, що є
    цікавою альтернативою SCIP. Він, імовірно, швидший і має більш дружній
    інтерфейс, але менш універсальний. Для бенчмарків продуктивності див.
    [тут](https://plato.asu.edu/ftp/milp.html).
- **Програмування з обмеженнями (CP):** CP — більш загальний підхід до задач
  оптимізації, ніж MIP. Як випливає з назви, він зосереджується на обмеженнях,
  і розв’язувачі зазвичай мають багато просунутих обмежень, які дозволяють
  природніше описувати задачу. Класичний приклад — обмеження `AllDifferent`,
  яке дуже складно змоделювати в MIP, але воно дозволяє, наприклад, тривіально
  змоделювати судоку. CP був дуже успішним, наприклад, у розв’язанні задач
  планування, де є багато обмежень, які складно описати лінійно. Внутрішні
  техніки CP-розв’язувачів часто більше опираються на логіку й менше — на
  лінійну алгебру, порівняно з MIP-розв’язувачами. Популярні CP-розв’язувачі:
  - [CP-SAT від OR-Tools](https://github.com/google/or-tools/): розглядається в
    цьому праймері; CP-SAT поєднує різні оптимізаційні техніки, зокрема з MIP,
    але його ключова техніка — Lazy Clause Generation. Цей підхід переводить
    задачі у (Max-)SAT формули для розв’язання.
  - [Choco](https://choco-solver.org/): традиційний CP-розв’язувач, написаний на
    Java і ліцензований за BSD 4-Clause. Хоча він може поступатися CP-SAT у
    ефективності чи сучасності, Choco пропонує значну гнучкість, зокрема можливість
    інтегрувати власні пропагатори.
- **SAT-розв’язувачі:** якщо ваша задача полягає лише в пошуку допустимого
  розв’язку для булевих змінних, варто подумати про SAT-розв’язувач. Вони
  напрочуд ефективні й часто здатні працювати з задачами з мільйонами змінних.
  Якщо підійти креативно, можна виконувати й деякі оптимізаційні задачі за
  допомогою SAT-розв’язувачів, як це робить CP-SAT. Більшість SAT-розв’язувачів
  підтримують інкрементальне моделювання, а деякі — обмеження кардинальності.
  Однак це досить низькорівневі інструменти, і CP-SAT може досягати подібної
  продуктивності для багатьох задач. Популярна бібліотека SAT-розв’язувачів:
  - [PySAT](https://pysathq.github.io/): Python-бібліотека під ліцензією MIT,
    що надає зручний інтерфейс до багатьох SAT-розв’язувачів. Її легко
    використовувати, і вона дозволяє перемикатися між розв’язувачами без змін
    коду. Гарний вибір для експериментів із SAT-розв’язувачами.
  - Щороку з’являється багато нових розв’язувачів, і чимало з них мають відкритий
    код. Перегляньте [SAT Competition](http://www.satcompetition.org/), щоб
    побачити актуальний стан мистецтва. Більшість розв’язувачів написані на C
    або C++ і мають небагато документації. Проте, оскільки SAT-формули дуже
    прості, а розв’язувачі зазвичай не мають складних залежностей, ними все ще
    можна користуватися доволі легко.
- **Задовільність з урахуванням теорій (SMT):** SMT-розв’язувачі — це наступний
  щабель після традиційних SAT-розв’язувачів. Вони перевіряють
  задовільність математичних формул, розширюючи пропозиційну логіку додатковими
  теоріями, як-от лінійна арифметика, бітові вектори, масиви й квантори.
  Наприклад, SMT-розв’язувач може визначити, чи є формула задовільною за умов,
  що всі змінні — цілі числа з певними лінійними обмеженнями. Подібно до Lazy
  Clause Generation у CP-SAT, SMT-розв’язувачі зазвичай використовують SAT
  у бекенді, доповнений складними кодуваннями й додатковими пропагаторами для
  підтримки великого набору виразів. Ці розв’язувачі широко застосовують у
  автоматизованому доведенні теорем і верифікації систем. Популярний SMT-розв’язувач:
  - [Z3](https://github.com/z3prover/z3): розроблений Microsoft і доступний за
    ліцензією MIT. Z3 має надійний Python-інтерфейс і ґрунтовну документацію,
    що робить його доступним для широкого спектра застосувань.
- **Нелінійне програмування (NLP):** багато MIP-розв’язувачів насправді можуть
  обробляти деякі нелінійні обмеження, адже з часом з’ясувалося, що певні
  техніки є більш загальними, ніж просто лінійні обмеження; наприклад, методи
  внутрішніх точок можуть також розв’язувати задачі з конічними обмеженнями
  другого порядку. Проте ви помітите значне падіння продуктивності, оскільки
  нелінійність набагато складніше обробляти. Якщо ваші обмеження та цілі стають
  надто складними, такі розв’язувачі можуть перестати бути життєздатним
  варіантом. На щастя, у цій області зараз багато руху, і можна очікувати, що
  великі розв’язувачі (Gurobi, COPT, Xpress тощо) ставатимуть дедалі кращими в
  роботі з такими задачами. Якщо у вас невеликі оптимізаційні задачі майже будь-якого
  типу, варто розглянути:
  - [SciPy](https://docs.scipy.org/doc/scipy/reference/optimize.html): Python-бібліотека,
    що пропонує широкий набір алгоритмів оптимізації. Не очікуйте, що вона
    наблизиться до продуктивності спеціалізованих розв’язувачів, але вона дає
    багато різних опцій для розв’язання широкого спектра задач.
- **Мови моделювання:** мови моделювання надають високорівневий, зручний інтерфейс
  для формулювання оптимізаційних задач, зосереджуючись на труднощах розробки й
  підтримки моделей, що точно відображають реальні сценарії. Ці мови є
  незалежними від конкретних розв’язувачів, дозволяючи легко перемикатися між
  різними розв’язувачами — наприклад, від безкоштовного SCIP до комерційного
  Gurobi — без зміни самої моделі. Вони також полегшують використання різних
  технік, як-от перехід між програмуванням з обмеженнями і змішаним цілочисельним
  програмуванням. Однак компроміс — потенційна втрата контролю й продуктивності
  заради універсальності та простоти. Найпопулярніші мови моделювання:
  - [MiniZinc](https://www.minizinc.org/): дуже добре задокументована і безкоштовна
    мова моделювання, що має високу репутацію в академічній спільноті. Вона
    використовується, зокрема, у
    [чудовому курсі з програмування з обмеженнями від Pierre Flener](https://user.it.uu.se/~pierref/courses/COCP/slides/).
    Підтримує багато бекендів, а також є
    [MiniZinc Challenges](https://www.minizinc.org/challenge/), де CP-SAT здобув
    чимало медалей.
  - [AMPL](https://ampl.com/): можливо, найпопулярніша мова моделювання. Має як
    безкоштовні, так і комерційні розв’язувачі. Є не лише ґрунтовна документація,
    а й навіть книга про те, як нею користуватися.
  - [GAMS](https://www.gams.com/): комерційна система, що підтримує багато
    розв’язувачів і отримала Python-інтерфейс. Я особисто знаю людей із GAMS,
    бо у них є офіс у Брауншвейгу. Вони мають великий досвід в оптимізації, але
    сам я їхнє ПЗ не використовував.
  - [pyomo](http://www.pyomo.org/): Python-бібліотека, що дозволяє моделювати
    оптимізаційну задачу в Python, а потім розв’язувати її різними розв’язувачами.
    Вона не така високорівнева, як AMPL чи GAMS, але є безкоштовною та з
    відкритим кодом. Дуже гнучка і дозволяє моделювати в Python, що є великою
    перевагою, якщо ви вже знайомі з Python. Вона має підтримку CP-SAT і може
    бути варіантом, якщо вам потрібне швидке рішення.
  - [MathOpt від OR-Tools](https://developers.google.com/optimization/math_opt):
    дуже новий конкурент і «родич» CP-SAT. Підтримує лише кілька розв’язувачів,
    але все одно може бути цікавим.
- **Спеціалізовані алгоритми:** для багатьох оптимізаційних задач існують
  спеціалізовані алгоритми, які можуть бути значно ефективнішими за
  універсальні розв’язувачі. Приклади:
  - [Concorde](http://www.math.uwaterloo.ca/tsp/concorde.html): розв’язувач для
    задачі комівояжера, який, попри свій вік, все ще дуже швидкий для багатьох
    екземплярів.
  - [Routing Solver від OR-Tools](https://developers.google.com/optimization/routing):
    OR-Tools також має окремий розв’язувач для маршрутних задач.
  - [Network Flows від OR-Tools](https://developers.google.com/optimization/flow):
    OR-Tools також має окремий розв’язувач для задач мережевих потоків.
  - ...
- **Алгоритми наближення:** для багатьох складних оптимізаційних задач можна
  знайти наукові статті, що описують алгоритми наближення. Ці алгоритми мають
  певні гарантії того, що результат не буде надто далеким від оптимального
  розв’язку. Деякі навіть доведено досягають найкращих можливих гарантій. Однак
  не варто намагатися безпосередньо реалізувати таку статтю, навіть якщо вона
  ідеально підходить до вашої задачі. Деякі алгоритми наближення справді
  практичні, але багато — ні. Гарантії зазвичай зосереджені на штучних
  найгірших сценаріях, і навіть якщо алгоритм можна реалізувати, його часто
  легко перевершують прості евристики. Алгоритми наближення і їхній аналіз
  можуть бути корисними для розуміння структури задачі, але пряме практичне
  використання обмежене.
- **Мета-евристики:** замість використання універсального розв’язувача, як CP-SAT,
  ви можете спробувати створити власний алгоритм для задачі на основі певного
  шаблону мета-евристики, наприклад імітації відпалу, генетичних алгоритмів
  чи табу-пошуку. Мета-евристики потребують певного програмування, але щойно
  ви зрозумієте шаблон, їх досить просто реалізувати. Хоча існують бібліотеки,
  що узагальнюють частини цих алгоритмів, ви також можете написати весь алгоритм
  самостійно. Це дає перевагу справді розуміти, що відбувається в алгоритмі,
  але ви втрачаєте багато просунутих технік, наявних у розв’язувачах на кшталт
  CP-SAT. Для багатьох оптимізаційних задач вам буде складно конкурувати з
  рішеннями, що використовують сучасні розв’язувачі, з погляду якості розв’язку.
  Якщо вам потрібне швидке рішення, мета-евристики можуть бути хорошим стартом.

Як видно, існує різноманітний набір інструментів і технік для розв’язання
оптимізаційних задач. CP-SAT вирізняється як універсальний підхід, особливо
добре пристосований до комбінаторної оптимізації. Якщо ви часто маєте справу з
такими задачами, вивчення CP-SAT дуже рекомендується. Його ефективність у
широкому спектрі сценаріїв — і особливо у багатьох з них — вражає для інструмента,
який є безкоштовним і відкритим.

---

<!-- This file was generated by the `build.py` script. Do not edit it manually. -->
<!-- ./chapters/06_coding_patterns.md -->
<!-- EDIT THIS PART VIA 06_coding_patterns.md -->

# Частина 2: Просунуті теми

<a name="06-coding-patterns"></a>

## Патерни кодування для задач оптимізації


У цьому розділі ми розглянемо різні патерни кодування, які допомагають
структурувати реалізації оптимізаційних задач із використанням CP-SAT. Ці
патерни особливо корисні, коли ви працюєте зі складними задачами, які потрібно
розв’язувати постійно й потенційно за змінних вимог. Хоча ми зосереджуємося на
Python API CP-SAT, багато патернів можна адаптувати до інших розв’язувачів і
мов.

У багатьох випадках достатньо просто описати модель і розв’язати її без
особливої структури. Але є ситуації, коли моделі складні й потребують частих
ітерацій — або через продуктивність, або через зміну вимог. Тоді критично мати
добру структуру, щоб легко змінювати й розширювати код, не ламаючи його, а також
щоб полегшити тестування й розуміння. Уявіть, що у вас складна модель і потрібно
адаптувати обмеження через нові вимоги. Якщо код не модульний, а тестова система
перевіряє лише всю модель, навіть невелика зміна змусить переписувати всі тести.
Після кількох ітерацій ви можете взагалі відмовитися від тестів — а це
небезпечний шлях.

Ще одна типова проблема в складних моделях — ризик забути додати тривіальні
обмеження, що з’єднують допоміжні змінні, через що частина моделі перестає
працювати. Якщо це стосується здійсненності, ви, можливо, помітите проблему
під час перевірки здійсненності розв’язку. Але якщо це впливає на цільову
функцію (наприклад, штрафи), ви можете не помітити, що розв’язок субоптимальний,
бо штрафи не застосовано. Крім того, реалізація складних обмежень часто важка,
і модульна структура дозволяє тестувати такі обмеження окремо. Розробка через
тести (TDD) — ефективний підхід для швидкої й надійної реалізації складних
обмежень.

Оптимізація як сфера дуже неоднорідна, і відсоток оптимізаторів із професійним
бекграундом у програмній інженерії, здається, напрочуд низький. Багато
оптимізаційної роботи роблять математики, фізики та інженери, які мають глибоку
експертизу у своїх галузях, але обмежений досвід у софт-інженерії. Вони
зазвичай дуже кваліфіковані й можуть створювати чудові моделі, але їхній код
часто непідтримуваний і не відповідає практикам ПЗ. Багато задач подібні між
собою, тож мінімальних пояснень чи структури часто вважають достатніми —
подібно до побудови графіків через копіювання шаблонів. Такий підхід може бути
не надто читабельним, але для багатьох у галузі це звично. Також для
математиків типово спочатку документувати модель, а потім реалізовувати її.
З погляду інженерії це нагадує водоспадну модель, яка не є гнучкою.

Схоже, що літератури про agile-розробку в оптимізації бракує, і цей розділ
покликаний заповнити прогалину, описуючи патерни, які я вважаю корисними у
своїй роботі. Я запитував старших колег, але вони не змогли запропонувати
ресурси або навіть не бачили потреби в них. Для багатьох кейсів простого
підходу справді достатньо. Але я виявив, що ці патерни роблять мій agile,
тест-орієнтований робочий процес значно легшим, швидшим і приємнішим. З огляду
на брак джерел, цей розділ значною мірою базується на моєму особистому досвіді.
Буду радий почути ваші історії та патерни, які ви вважаєте корисними.

Далі ми почнемо з базового патерну на основі функцій, а потім перейдемо до
інших концепцій і патернів, які я вважаю цінними. Ми працюватимемо на простих
прикладах, де переваги патернів можуть бути неочевидними, але сподіваюся, ви
побачите їхній потенціал у складніших задачах. Альтернатива — навести складні
приклади, що могло б відволікти від самих патернів.

> [!TIP]
>
> Наведені патерни зосереджуються на деталях, специфічних для обчислювальної
> оптимізації. Проте багато інженерів-оптимізаторів походять із математики чи
> фізики і можуть не мати професійного досвіду в Python чи софт-інженерії. Якщо
> це про вас, рекомендую ознайомитися особливо з
> [базовими структурами даних і їх _comprehensions_](https://docs.python.org/3/tutorial/datastructures.html)
> та елегантними циклами з
> [itertools](https://docs.python.org/3/library/itertools.html). Ці інструменти
> дозволяють елегантніше виражати математичні ідеї у Python і особливо корисні
> для задач оптимізації.
>
> Також є чудові інструменти для автоматичного форматування, перевірки та
> покращення коду, наприклад [ruff](https://docs.astral.sh/ruff/tutorial/).
> Регулярний запуск `ruff check --fix` та `ruff format` підвищує якість коду з
> мінімальними зусиллями. Оптимально інтегрувати це через
> [pre-commit hook](https://pre-commit.com/).
>
> Для старту з побудови оптимізаційних моделей загалом дуже рекомендую статтю
> [The Art Of Not Making It An Art](https://www.gurobi.com/resources/optimization-modeling-the-art-of-not-making-it-an-art/).
> Вона чудово підсумовує принципи успішного ведення оптимізаційного проєкту
> незалежно від конкретної мови чи розв’язувача.

### Проста функція

Для простих задач оптимізації практично обгорнути побудову та розв’язання
моделі в одну функцію. Цей метод підходить для простих випадків, але має меншу
гнучкість для складних сценаріїв. Параметри на кшталт ліміту часу або допуску
оптимальності можна задавати через keyword-аргументи з значеннями за
замовчуванням.

Нижче приклад функції на Python для задачі рюкзака. Нагадаємо, що в задачі
рюкзака ми вибираємо предмети (з вагою і цінністю), щоб максимізувати сумарну
цінність при обмеженні на вагу. Через простоту (лише одне обмеження) ця задача
ідеальна для вступних прикладів.

```python
from ortools.sat.python import cp_model
from typing import List


def solve_knapsack(
    weights: List[int],
    values: List[int],
    capacity: int,
    *,
    time_limit: int = 900,
    opt_tol: float = 0.01,
) -> List[int]:
    # ініціалізуємо модель
    model = cp_model.CpModel()
    n = len(weights)  # кількість предметів
    # Змінні рішень
    x = [model.new_bool_var(f"x_{i}") for i in range(n)]
    # Обмеження місткості
    model.add(sum(weights[i] * x[i] for i in range(n)) <= capacity)
    # Цільова функція
    model.maximize(sum(values[i] * x[i] for i in range(n)))
    # Розв’язання
    solver = cp_model.CpSolver()
    solver.parameters.max_time_in_seconds = time_limit
    solver.parameters.relative_gap_limit = opt_tol
    status = solver.solve(model)
    # Витягуємо розв’язок
    return (
        [i for i in range(n) if solver.value(x[i])]
        if status in [cp_model.OPTIMAL, cp_model.FEASIBLE]
        else []
    )
```

Можна додати гнучкість, дозволивши передавати будь-які параметри solver-а.

```python
def solve_knapsack(
    weights: List[int],
    values: List[int],
    capacity: int,
    *,
    time_limit: int = 900,
    opt_tol: float = 0.01,
    **kwargs,
) -> List[int]:
    # ініціалізуємо модель
    model = cp_model.CpModel()
    # ...
    # Розв’язання
    solver = cp_model.CpSolver()
    solver.parameters.max_time_in_seconds = time_limit
    solver.parameters.relative_gap_limit = opt_tol
    for key, value in kwargs.items():
        setattr(solver.parameters, key, value)
    # ...
```

Додайте модульні тести у окремому файлі (наприклад, `test_knapsack.py`), щоб
переконатися, що модель працює очікувано.

> [!TIP]
>
> Пишіть тести до написання коду. Це підхід TDD, який допомагає структурувати
> код і забезпечити його правильність. Він також змушує продумати API функції
> до реалізації.

```python
# Переконайтеся, що у вас правильна структура проєкту і ви можете імпортувати функцію
from myknapsacksolver import solve_knapsack

def test_knapsack_empty():
    # Тест для тривіального випадку завжди корисний
    assert solve_knapsack([], [], 0) == []

def test_knapsack_nothing_fits():
    # Якщо нічого не вміщується, розв’язок має бути порожнім
    assert solve_knapsack([10, 20, 30], [1, 2, 3], 5) == []

def test_knapsack_one_item():
    # Якщо вміщується лише один предмет
    assert solve_knapsack([10, 20, 30], [1, 2, 3], 10) == [0]

def test_knapsack_all_items():
    # Якщо вміщуються всі предмети
    assert solve_knapsack([10, 20, 30], [1, 2, 3], 100) == [0, 1, 2]
```

Запустити всі тести в проєкті можна через `pytest .`. Гарний туторіал —
[Real Python](https://realpython.com/pytest-python-testing/).

### Логування побудови моделі

У великих задачах логування процесу побудови моделі може бути критичним для
пошуку й виправлення проблем. Часто проблема не в solver-і, а саме в моделі.

У прикладі нижче додаємо базове логування у функцію solver-а, щоб отримати
інсайти про побудову моделі. Логування легко вмикається/вимикається через
logging framework, що дозволяє використовувати його і в продакшені.

Якщо ви не знайомі з logging у Python — це чудова нагода. Я вважаю це
необхідною навичкою для продакшн-коду, і подібні фреймворки використовуються
майже всюди. Офіційна документація має
[гарний туторіал](https://docs.python.org/3/howto/logging.html). Дехто любить
інші фреймворки, але вбудований logging цілком достатній і кращий за `print`.

```python
import logging
from ortools.sat.python import cp_model
from typing import List

# Налаштовуємо logging, якщо ще не налаштовано
logging.basicConfig(format="%(asctime)s - %(message)s", level=logging.DEBUG)

_logger = logging.getLogger(__name__)


def solve_knapsack(
    weights: List[int],
    values: List[int],
    capacity: int,
    *,
    time_limit: int = 900,
    opt_tol: float = 0.01,
) -> List[int]:
    _logger.debug("Building the knapsack model")
    model = cp_model.CpModel()
    n = len(weights)
    _logger.debug("Number of items: %d", n)
    if n > 0:
        if _logger.isEnabledFor(logging.DEBUG):
            _logger.debug(
                "Min/Mean/Max weight: %d/%.2f/%d",
                min(weights),
                sum(weights) / n,
                max(weights),
            )
            _logger.debug(
                "Min/Mean/Max value: %d/%.2f/%d", min(values), sum(values) / n, max(values)
            )
    x = [model.new_bool_var(f"x_{i}") for i in range(n)]
    model.add(sum(weights[i] * x[i] for i in range(n)) <= capacity)
    model.maximize(sum(values[i] * x[i] for i in range(n)))
    _logger.debug("Model created with %d items", n)
    solver = cp_model.CpSolver()
    solver.parameters.max_time_in_seconds = time_limit
    solver.parameters.relative_gap_limit = opt_tol
    _logger.debug(
        "Starting the solution process with time limit %d seconds", time_limit
    )
    status = solver.solve(model)
    selected_items = (
        [i for i in range(n) if solver.value(x[i])]
        if status in [cp_model.OPTIMAL, cp_model.FEASIBLE]
        else []
    )
    _logger.debug("Selected items: %s", selected_items)
    return selected_items
```

У наступних прикладах ми не використовуватимемо логування, щоб зекономити місце,
але варто подумати про його додавання до коду.

> [!TIP]
>
> Класний хак із logging — можна легко під’єднатися до коду і робити аналіз
> не лише через тексти логів. Ви можете написати handler, який, наприклад,
> ловить тег "Selected items: %s" і отримує сам об’єкт (а не лише рядок). Це
> дуже корисно для збору статистики чи візуалізації процесу пошуку без зміни
> (продакшн) коду.

### Власні data-класи для інстансів, конфігурацій і розв’язків

Використання серіалізованих data-класів зі строгими схемами для інстансів,
конфігурацій і розв’язків значно підвищує читабельність і підтримуваність
коду. Це також полегшує документацію, тестування і забезпечує узгодженість
даних у великих проєктах.

Одна з популярних бібліотек для цього —
[Pydantic](https://docs.pydantic.dev/latest/). Вона проста і дає багато
функціональності «з коробки». Нижче — класи для інстансу, конфігурації і
розв’язку задачі рюкзака. Хоча duck typing у Python зручний для швидкої
внутрішньої розробки, він може створювати проблеми для API. Користувачі часто
неправильно використовують інтерфейс і звинувачують вас. Pydantic допомагає
зменшити ці проблеми, даючи чіткий інтерфейс і валідацію. До того ж можна
легко створити API через FastAPI, який побудований на Pydantic.

```python
# pip install pydantic
from pydantic import (
    BaseModel,
    PositiveInt,
    NonNegativeFloat,
    PositiveFloat,
    Field,
    model_validator,
)


class KnapsackInstance(BaseModel):
    # Інстанс задачі
    weights: list[PositiveInt] = Field(..., description="The weight of each item.")
    values: list[PositiveInt] = Field(..., description="The value of each item.")
    capacity: PositiveInt = Field(..., description="The capacity of the knapsack.")

    @model_validator(mode="after")
    def check_lengths(cls, v):
        if len(v.weights) != len(v.values):
            raise ValueError("Mismatch in number of weights and values.")
        return v


class KnapsackSolverConfig(BaseModel):
    # Конфігурація solver-а
    time_limit: PositiveFloat = Field(
        default=900.0, description="Time limit in seconds."
    )
    opt_tol: NonNegativeFloat = Field(
        default=0.01, description="Optimality tolerance (1% gap allowed)."
    )
    log_search_progress: bool = Field(
        default=False, description="Whether to log the search progress."
    )


class KnapsackSolution(BaseModel):
    # Розв’язок задачі
    selected_items: list[int] = Field(..., description="Indices of selected items.")
    objective: float = Field(..., description="Objective value of the solution.")
    upper_bound: float = Field(
        ..., description="Upper bound of the solution, i.e., a proven limit on how good a solution could be."
    )
```

> [!WARNING]
>
> Схема даних має бути повністю підготовлена для оптимізації без додаткової
> передобробки. Підготовка даних і оптимізація — обидві складні задачі, і їхнє
> змішування значно ускладнює код. Ідеально, щоб оптимізаційний код просто
> проходив по даних і додавав відповідні обмеження та цілі до моделі.

Початковий код потрібно адаптувати під ці data-класи.

```python
from ortools.sat.python import cp_model


def solve_knapsack(
    instance: KnapsackInstance, config: KnapsackSolverConfig
) -> KnapsackSolution:
    model = cp_model.CpModel()
    n = len(instance.weights)
    x = [model.new_bool_var(f"x_{i}") for i in range(n)]
    model.add(sum(instance.weights[i] * x[i] for i in range(n)) <= instance.capacity)
    model.maximize(sum(instance.values[i] * x[i] for i in range(n)))
    solver = cp_model.CpSolver()
    solver.parameters.max_time_in_seconds = config.time_limit
    solver.parameters.relative_gap_limit = config.opt_tol
    solver.parameters.log_search_progress = config.log_search_progress
    status = solver.solve(model)
    if status in [cp_model.OPTIMAL, cp_model.FEASIBLE]:
        return KnapsackSolution(
            selected_items=[i for i in range(n) if solver.value(x[i])],
            objective=solver.objective_value,
            upper_bound=solver.best_objective_bound,
        )
    return KnapsackSolution(selected_items=[], objective=0, upper_bound=0)
```

Можна використовувати можливості серіалізації Pydantic для швидкого створення
тест-кейсів на основі реальних даних. Хоча такі тести не гарантують коректність,
вони принаймні сигналізують про неочікувані зміни логіки після рефакторингу.

```python
from datetime import datetime
from hashlib import md5
from pathlib import Path


def add_test_case(instance: KnapsackInstance, config: KnapsackSolverConfig):
    """
    Швидко генеруємо тест-кейс на основі інстансу і конфігурації.
    """
    test_folder = Path(__file__).parent / "test_data"
    unique_id = (
        datetime.now().strftime("%Y-%m-%d-%H-%M-%S")
        + "_"
        + md5(
            (instance.model_dump_json() + config.model_dump_json()).encode()
        ).hexdigest()
    )
    subfolder = test_folder / "knapsack" / unique_id
    subfolder.mkdir(parents=True, exist_ok=True)
    with open(subfolder / "instance.json", "w") as f:
        f.write(instance.model_dump_json())
    with open(subfolder / "config.json", "w") as f:
        f.write(config.model_dump_json())
    solution = solve_knapsack(instance, config)
    with open(subfolder / "solution.json", "w") as f:
        f.write(solution.model_dump_json())


def test_saved_test_cases():
    test_folder = Path(__file__).parent / "test_data"
    for subfolder in test_folder.glob("knapsack/*"):
        with open(subfolder / "instance.json") as f:
            instance = KnapsackInstance.model_validate_json(f.read())
        with open(subfolder / "config.json") as f:
            config = KnapsackSolverConfig.model_validate_json(f.read())
        with open(subfolder / "solution.json") as f:
            solution = KnapsackSolution.model_validate_json(f.read())
        new_solution = solve_knapsack(instance, config)
        assert (
            new_solution.objective <= solution.upper_bound
        ), "New solution is better than the previous upper bound: One has to be wrong."
        assert (
            solution.objective <= new_solution.upper_bound
        ), "Old solution is better than the new upper bound: One has to be wrong."
        # Не тестуємо selected_items, бо solver може знайти інший розв’язок тієї ж якості
```

Тепер можна легко генерувати тест-кейси і перевіряти їх таким кодом. Ідеально,
якщо ви використовуєте реальні інстанси, наприклад автоматично зберігаючи 1%
інстансів з продакшену.

```python
# Інстанс задачі рюкзака
instance = KnapsackInstance(
    weights=[23, 31, 29, 44, 53, 38, 63, 85, 89, 82],
    values=[92, 57, 49, 68, 60, 43, 67, 84, 87, 72],
    capacity=165,
)
# Конфігурація solver-а
config = KnapsackSolverConfig(
    time_limit=10.0, opt_tol=0.01, log_search_progress=False
)
# Розв’язання
solution = solve_knapsack(instance, config)
# Додаємо тест-кейс у папку
add_test_case(instance, config)
```

Також легко підтримувати зворотну сумісність, якщо додавати значення за
замовчуванням для нових полів.

> [!TIP]
>
> Часто доводиться проектувати data-класи максимально загальними, щоб вони
> підходили для кількох solver-ів і залишалися сумісними на різних етапах
> оптимізації. Наприклад, граф можна подати як список ребер, матрицю
> суміжності або список суміжності — і вибір формату залежить від задачі. Але
> конвертація між форматами зазвичай проста, потребує лише кількох рядків і має
> незначний вплив порівняно з оптимізацією. Тому я рекомендую фокусуватися на
> функціональності для вашого поточного solver-а і не ускладнювати цю частину.

### Клас розв’язувача

У багатьох реальних сценаріях оптимізації потрібно ітеративно уточнювати модель
і розв’язок. Наприклад, нові обмеження можуть з’явитися після показу первинного
розв’язку користувачу або іншому алгоритму (наприклад, фізичній симуляції, яку
занадто складно оптимізувати напряму). У таких випадках важлива гнучкість, тому
корисно інкапсулювати модель і solver в одному класі. Це дозволяє динамічно
додавати обмеження і повторно розв’язувати задачу без повної перебудови моделі,
а також потенційно використовувати warm-start.

Нижче — `KnapsackSolver`, який інкапсулює побудову та розв’язання задачі. Ми
також розбиваємо побудову моделі на менші методи, що корисно для складних
моделей.

```python
class KnapsackSolver:
    def __init__(self, instance: KnapsackInstance, config: KnapsackSolverConfig):
        self.instance = instance
        self.config = config
        self.model = cp_model.CpModel()
        self.n = len(instance.weights)
        self.x = [self.model.new_bool_var(f"x_{i}") for i in range(self.n)]
        self._build_model()
        self.solver = cp_model.CpSolver()

    def _add_constraints(self):
        used_weight = sum(
            weight * x_i for weight, x_i in zip(self.instance.weights, self.x)
        )
        self.model.add(used_weight <= self.instance.capacity)

    def _add_objective(self):
        self.model.maximize(
            sum(value * x_i for value, x_i in zip(self.instance.values, self.x))
        )

    def _build_model(self):
        self._add_constraints()
        self._add_objective()

    def solve(self, time_limit: float | None = None) -> KnapsackSolution:
        self.solver.parameters.max_time_in_seconds = time_limit if time_limit else self.config.time_limit
        self.solver.parameters.relative_gap_limit = self.config.opt_tol
        self.solver.parameters.log_search_progress = self.config.log_search_progress
        status = self.solver.solve(self.model)
        if status in [cp_model.OPTIMAL, cp_model.FEASIBLE]:
            return KnapsackSolution(
                selected_items=[
                    i for i in range(self.n) if self.solver.value(self.x[i])
                ],
                objective=self.solver.objective_value,
                upper_bound=self.solver.best_objective_bound,
            )
        return KnapsackSolution(
            selected_items=[], objective=0, upper_bound=float("inf")
        )

    def prohibit_combination(self, item_a: int, item_b: int):
        """
        Забороняє комбінацію двох предметів у розв’язку.
        Це корисно, якщо після показу розв’язку з’ясувалося, що ці предмети
        не можна пакувати разом. Після цього просто викликаємо `solve` знову.
        """
        self.model.add(self.x[item_a] + self.x[item_b] <= 1)
```

На перший погляд це може здаватися громіздким — треба створити solver-об’єкт, а
потім викликати `solve`. Але така структура підходить для багатьох кейсів, і я
використовую її варіанти у більшості проєктів. Для простих випадків можна додати
обгортку-функцію.

```python
instance = KnapsackInstance(weights=[1, 2, 3], values=[4, 5, 6], capacity=3)
config = KnapsackSolverConfig(time_limit=10, opt_tol=0.01, log_search_progress=True)
solver = KnapsackSolver(instance, config)
solution = solver.solve()

print(solution)
# Припустимо, симуляція показала, що перші два предмети не можна пакувати разом.
solver.prohibit_combination(0, 1)

# Розв’язуємо знову, але лише 5 секунд.
solution = solver.solve(time_limit=5)
print(solution)
```

Хоча повторне використання класу здебільшого економить на повторній побудові
моделі, кожен `solve` все одно стартує новий пошук. Проте інкрементальне
уточнення моделі в межах одного екземпляра solver-а більш інтуїтивне для коду,
ніж повністю нова постановка на кожній ітерації. Ба більше, як ми побачимо
далі, це дозволяє покращити продуктивність через warm-start.

### Покращення продуктивності через warm-start

Оскільки solver-клас зберігає стан і пам’ятає попередні ітерації, можна легко
додавати оптимізації, які було б складно реалізувати у статичній функції. Одна
з них — warm-start, коли solver використовує попередній розв’язок як підказку
для наступного запуску. Це може суттєво пришвидшити розв’язання, бо solver може
використати попередній розв’язок як хороший старт для «ремонту», навіть якщо
він став недопустимим через нові обмеження. Це працює лише тоді, коли нові
обмеження не змінюють задачу кардинально.

Оскільки ремонт недопустимої підказки може бути дорогим, CP-SAT обережно до
цього ставиться. Ви можете наказати CP-SAT ремонтувати підказку через
`solver.parameters.repair_hint = True`, а також керувати лімітом конфліктів через
`solver.parameters.hint_conflict_limit`.

Приклад:

```python
class KnapsackSolver:
    # ...

    def _set_solution_as_hint(self):
        """Використати поточний розв’язок як підказку для наступного solve."""
        for i, v in enumerate(self.model.proto.variables):
            v_ = self.model.get_int_var_from_proto_index(i)
            assert v.name == v_.name, "Variable names should match"
            self.model.add_hint(v_, self.solver.value(v_))
        # Сказати CP-SAT ремонтувати підказку
        self.solver.parameters.repair_hint = True
        self.solver.parameters.hint_conflict_limit = 20

    def solve(self, time_limit: float | None = None) -> KnapsackSolution:
        self.solver.parameters.max_time_in_seconds = time_limit if time_limit else self.config.time_limit
        self.solver.parameters.relative_gap_limit = self.config.opt_tol
        self.solver.parameters.log_search_progress = self.config.log_search_progress
        status = self.solver.solve(self.model)
        if status in [cp_model.OPTIMAL, cp_model.FEASIBLE]:
            # Є розв’язок — використовуємо його як підказку
            self._set_solution_as_hint()
            return KnapsackSolution(
                selected_items=[
                    i for i in range(self.n) if self.solver.value(self.x[i])
                ],
                objective=self.solver.objective_value,
                upper_bound=self.solver.best_objective_bound,
            )
        return KnapsackSolution(
            selected_items=[], objective=0, upper_bound=float("inf")
        )

    # ...
```

Щоб ще покращити підхід, можна додати евристику для ремонту підказки. Допустима
підказка набагато корисніша, ніж та, яку треба сильно ремонтувати. Наприклад,
якщо підказка недопустима через заборонену комбінацію предметів, можна просто
викинути найменш цінний предмет.

> [!WARNING]
>
> Часта помилка при ітеративній оптимізації — додавати попередню межу як
> обмеження. Це може дозволити CP-SAT «продовжити» з попередньої межі, але часто
> обмежує його здатність знаходити кращі розв’язки, бо додає сильне обмеження,
> не пов’язане зі здійсненністю. Це може заважати внутрішнім алгоритмам,
> наприклад зменшувати ефективність лінійної релаксації.
>
> Якщо межі сильно впливають на продуктивність, краще використовувати callback,
> який перевіряє, чи поточна ціль достатньо близька до попередньої межі, і
> зупиняє пошук. Це менш агресивно, хоча callbacks додають накладні витрати.

|                                                                                                                                                                                                                                                                                                                                                                         ![Impact of Lower Bound Constraint on Relaxation](https://raw.githubusercontent.com/d-krupke/cpsat-primer/main/images/impact_lb_constraint_tsp.png)                                                                                                                                                                                                                                                                                                                                                                          |
| :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: |
| Це зображення показує негативний вплив додавання обмеження нижньої межі в моделі TSP. Лінійна релаксація явно погіршується: якщо початкова релаксація збігалася з оптимальним розв’язком на 44 з 50 ребер, то релаксація з обмеженням нижньої межі (рівною оптимуму) збігається лише на 38 ребрах і має більше дробових значень. Розгалуження на певних ребрах може перестати бути корисним; якщо не розгалужуватися по «правильному» ребру, значення цілі часто не змінюється через домінування нижньої межі. Крім втрати інформативності релаксації, такі обмеження відомі як джерело числових нестабільностей (хоча CP-SAT, ймовірно, не страждає від цього через цілочисельну арифметику). |

### Змінна ціль / багатокритеріальна оптимізація

У реальних задачах цілі часто нечіткі. Зазвичай є кілька цілей із різним
пріоритетом, і їх складно об’єднати. Розгляньмо задачу рюкзака як логістичну
ситуацію: ми хочемо перевезти максимальну цінність за одну поїздку. Основна
ціль — максимізувати цінність. Але після того, як показали розв’язок, нас
можуть попросити знайти альтернативу, що заповнює машину меншою мірою, навіть
якщо це означає падіння цінності до 5%.

|                              [![xkcd grapfruit](https://imgs.xkcd.com/comics/fuck_grapefruit.png)](https://xkcd.com/388/)                              |
| :----------------------------------------------------------------------------------------------------------------------------------------------------: |
| Який фрукт найкращий? Багато задач багатокритеріальні й не мають однозначної мети. Автор [xkcd](https://xkcd.com/388/) (CC BY-NC 2.5) |

Щоб впоратися, можна оптимізувати у два етапи. Спочатку максимізуємо цінність
за обмеженням ваги. Потім додаємо обмеження, що цінність має бути не менше 95%
від початкового розв’язку, і змінюємо ціль на мінімізацію ваги. Цей процес можна
повторювати, досліджуючи фронт Парето. Більш складні задачі можна розв’язувати
схожими підходами.

Проблема такого методу — уникнути створення кількох моделей і старту з нуля
кожного разу. Оскільки у нас уже є розв’язок близький до нового, а зміна цілі
не впливає на здійсненність, це чудова можливість використовувати поточний
розв’язок як підказку.

Нижче — приклад розширення solver-класу для змінної цілі. Ми зберігаємо поточну
ціль у `_objective` і додаємо методи для максимізації цінності або мінімізації
ваги. Також додаємо метод для фіксації поточної цілі, щоб уникнути деградації,
і автоматично ставимо підказку при успішному розв’язанні.

```python
class MultiObjectiveKnapsackSolver:
    def __init__(self, instance: KnapsackInstance, config: KnapsackSolverConfig):
        self.instance = instance
        self.config = config
        self.model = cp_model.CpModel()
        self.n = len(instance.weights)
        self.x = [self.model.new_bool_var(f"x_{i}") for i in range(self.n)]
        self._objective = 0
        self._build_model()
        self.solver = cp_model.CpSolver()

    def set_maximize_value_objective(self):
        """Максимізувати цінність."""
        self._objective = sum(
            value * x_i for value, x_i in zip(self.instance.values, self.x)
        )
        self.model.maximize(self._objective)

    def set_minimize_weight_objective(self):
        """Мінімізувати вагу."""
        self._objective = sum(
            weight * x_i for weight, x_i in zip(self.instance.weights, self.x)
        )
        self.model.minimize(self._objective)

    def _set_solution_as_hint(self):
        """Використати поточний розв’язок як підказку для наступного solve."""
        for i, v in enumerate(self.model.proto.variables):
            v_ = self.model.get_int_var_from_proto_index(i)
            assert v.name == v_.name, "Variable names should match"
            self.model.add_hint(v_, self.solver.value(v_))

    def fix_current_objective(self, ratio: float = 1.0):
        """Зафіксувати поточну ціль, щоб уникнути деградації."""
        if ratio == 1.0:
            self.model.add(self._objective == self.solver.objective_value)
        elif ratio > 1.0:
            self.model.add(self._objective <= ceil(self.solver.objective_value * ratio))
        else:
            self.model.add(
                self._objective >= floor(self.solver.objective_value * ratio)
            )

    def _add_constraints(self):
        """Додаємо обмеження ваги."""
        used_weight = sum(
            weight * x_i for weight, x_i in zip(self.instance.weights, self.x)
        )
        self.model.add(used_weight <= self.instance.capacity)

    def _build_model(self):
        """Будуємо модель з обмеженнями та ціллю."""
        self._add_constraints()
        self.set_maximize_value_objective()

    def solve(self, time_limit: float | None = None) -> KnapsackSolution:
        """Розв’язуємо задачу рюкзака та повертаємо розв’язок."""
        self.solver.parameters.max_time_in_seconds = time_limit if time_limit else self.config.time_limit
        self.solver.parameters.relative_gap_limit = self.config.opt_tol
        self.solver.parameters.log_search_progress = self.config.log_search_progress
        status = self.solver.solve(self.model)
        if status in [cp_model.OPTIMAL, cp_model.FEASIBLE]:
            self._set_solution_as_hint()
            return KnapsackSolution(
                selected_items=[
                    i for i in range(self.n) if self.solver.value(self.x[i])
                ],
                objective=self.solver.objective_value,
                upper_bound=self.solver.best_objective_bound,
            )
            )
        return KnapsackSolution(
            selected_items=[], objective=0, upper_bound=float("inf")
        )
```

Можна використовувати `MultiObjectiveKnapsackSolver` так:

```python
config = KnapsackSolverConfig(time_limit=15, opt_tol=0.01, log_search_progress=True)
solver = MultiObjectiveKnapsackSolver(instance, config)
solution_1 = solver.solve()

# зберігаємо щонайменше 95% поточного значення цілі
solver.fix_current_objective(0.95)
# змінюємо ціль на мінімізацію ваги
solver.set_minimize_weight_objective()
solution_2 = solver.solve(time_limit=10)
```

Існують більш просунуті й точні методи обчислення
[фронту Парето](https://en.wikipedia.org/wiki/Pareto_front), але
[багатокритеріальна оптимізація](https://en.wikipedia.org/wiki/Multi-objective_optimization)
— окрема складна сфера досліджень. Якщо ваша задача вже складна з однією
ціллю, додаткові цілі лише підвищать складність.

Підхід лексикографічної оптимізації (з послабленням) або об’єднання кількох
цілей в одну, наприклад через ваги, часто є розумним компромісом. Також можна
використовувати евристики, щоб досліджувати простір розв’язків навколо
початкового розв’язку з CP-SAT.

Втім, багатокритеріальна оптимізація залишається складною темою, і навіть
експерти покладаються на суттєвий trial-and-error, бо компроміси часто
неминучі.

### Контейнери змінних

У складних моделях змінні відіграють ключову роль і можуть охоплювати всю
модель. Для простих моделей достатньо списку або словника, але у складних це
стає громіздким і схильним до помилок. Один неправильний індекс може
спричинити тонкі помилки, які складно відстежити.

Оскільки змінні — основа моделі, їх рефакторинг стає складнішим із ростом
моделі. Тому важливо рано налагодити надійну систему керування. Інкапсуляція
змінних у класі забезпечує правильний доступ до них. Це також дозволяє легко
додавати нові змінні або змінювати логіку без переписування всієї моделі.

Крім того, зрозумілі методи-запити допомагають підтримувати читабельність
обмежень. Читабельні обмеження без складних схем доступу гарантують, що вони
відповідають задуму.

Нижче ми вводимо `_ItemSelectionVars` як контейнер для змінних вибору. Цей
клас створює змінні і має допоміжні методи для взаємодії з ними, що підвищує
читабельність і підтримуваність.

```python
from typing import Generator, Tuple, List


class _ItemSelectionVars:
    def __init__(self, instance: KnapsackInstance, model: cp_model.CpModel, var_name: str = "x"):
        self.instance = instance
        self.x = [model.new_bool_var(f"{var_name}_{i}") for i in range(len(instance.weights))]

    def __getitem__(self, i: int) -> cp_model.IntVar:
        return self.x[i]

    def packs_item(self, i: int) -> cp_model.IntVar:
        return self.x[i]

    def extract_packed_items(self, solver: cp_model.CpSolver) -> List[int]:
        return [i for i, x_i in enumerate(self.x) if solver.value(x_i)]

    def used_weight(self) -> cp_model.LinearExprT:
        return sum(weight * x_i for weight, x_i in zip(self.instance.weights, self.x))

    def packed_value(self) -> cp_model.LinearExprT:
        return sum(value * x_i for value, x_i in zip(self.instance.values, self.x))

    def iter_items(
        self,
        weight_lb: float = 0.0,
        weight_ub: float = float("inf"),
        value_lb: float = 0.0,
        value_ub: float = float("inf"),
    ) -> Generator[Tuple[int, cp_model.IntVar], None, None]:
        """
        Приклад складнішого методу-запиту для фільтрації предметів.
        """
        for i, (weight, x_i) in enumerate(zip(self.instance.weights, self.x)):
            if (
                weight_lb <= weight <= weight_ub
                and value_lb <= self.instance.values[i] <= value_ub
            ):
                yield i, x_i

```

Цей клас можна використовувати в `KnapsackSolver`, який відповідає за високий
рівень логіки (що має робити модель), а деталі сховати в контейнері.

```python
class KnapsackSolver:
    def __init__(self, instance: KnapsackInstance, config: KnapsackSolverConfig):
        self.instance = instance
        self.config = config
        self.model = cp_model.CpModel()
        self._item_vars = _ItemSelectionVars(instance, self.model)
        self._build_model()
        self.solver = cp_model.CpSolver()

    def _add_constraints(self):
        self.model.add(self._item_vars.used_weight() <= self.instance.capacity)

    def _add_objective(self):
        self.model.maximize(self._item_vars.packed_value())

    def _build_model(self):
        self._add_constraints()
        self._add_objective()

    def solve(self) -> KnapsackSolution:
        self.solver.parameters.max_time_in_seconds = self.config.time_limit
        self.solver.parameters.relative_gap_limit = self.config.opt_tol
        self.solver.parameters.log_search_progress = self.config.log_search_progress
        status = self.solver.solve(self.model)
        if status in [cp_model.OPTIMAL, cp_model.FEASIBLE]:
            return KnapsackSolution(
                selected_items=self._item_vars.extract_packed_items(self.solver),
                objective=self.solver.objective_value,
                upper_bound=self.solver.best_objective_bound,
            )
        return KnapsackSolution(
            selected_items=[], objective=0, upper_bound=float("inf")
        )

    def prohibit_combination(self, item_a: int, item_b: int):
        self.model.add_at_most_one(self._item_vars.packs_item(item_a),
        self._item_vars.packs_item(item_b))
```

Наприклад, `self.model.add(self._item_vars.used_weight() <= self.instance.capacity)`
тепер прямо виражає зміст обмеження, що підвищує читабельність і зменшує
ймовірність помилок. У контейнері можна також приховати оптимізації, не змінюючи
високорівневий код solver-а. Наприклад, контейнер може автоматично замінювати
змінні предметів, які не можуть вміститися в рюкзак, на константи.

Можна повторно використовувати тип контейнера, якщо з’явиться два рюкзаки. Код
нижче показує, як розширити solver на два рюкзаки без втрати читабельності.

```python
class KnapsackSolver:
    def __init__(self, # ...
    ):
        #...
        self._knapsack_a = _ItemSelectionVars(instance, self.model, var_name="x1")
        self._knapsack_b = _ItemSelectionVars(instance, self.model, var_name="x2")
        #...

    def _add_constraints(self):
        self.model.add(self._knapsack_a.used_weight() <= self.instance.capacity_1)
        self.model.add(self._knapsack_b.used_weight() <= self.instance.capacity_2)
        self.model.add(self._knapsack_a.used_weight() + self._knapsack_b.used_weight() <= self.instance.capacity_total)
        # Забороняємо пакувати предмет у два рюкзаки
        for i in range(len(instance.weights)):
            self.model.add_at_most_one(self._knapsack_a.packs_item(i), self._knapsack_b.packs_item(i))

    def _add_objective(self):
        self.model.maximize(self._knapsack_a.packed_value() + self._knapsack_b.packed_value())
```

> [!WARNING]
>
> Не створюйте контейнерний клас для простих моделей, якщо він лише обгортає
> список або словник без додаткової логіки. У таких випадках простий список або
> словник читається легше й коротше. Те саме стосується окремих змінних, яким
> не потрібен контейнер.

### Ліниве створення змінних

У моделях з великою кількістю допоміжних змінних часто реально використовується
лише невелика підмножина. Спроба створювати лише потрібні змінні заздалегідь
може ускладнити код і при подальших розширеннях ще більше ускладнюється. Тут
допомагає ліниве створення змінних: вони створюються лише при доступі до них.
Це гарантує, що створюються лише потрібні змінні, економлячи пам’ять та час.
Якщо зрештою використовується більшість змінних, це може бути дорожчим, але коли
потрібні лише кілька — економія суттєва.

Для ілюстрації введемо `_CombiVariables`. Він управляє допоміжними змінними для
пар предметів, щоб задавати бонус за пакування разом. Теоретично кількість пар
квадратична, але на практиці релевантні лише деякі. Ліниве створення економить
ресурси.

```python
class _CombiVariables:
    def __init__(
        self,
        instance: KnapsackInstance,
        model: cp_model.CpModel,
        item_vars: _ItemSelectionVars,
    ):
        self.instance = instance
        self.model = model
        self.item_vars = item_vars
        self.bonus_vars = {}

    def __getitem__(self, item_pair: Tuple[int, int]) -> cp_model.IntVar:
        i, j = sorted(item_pair)
        if (i, j) not in self.bonus_vars:
            var = self.model.NewBoolVar(f"bonus_{i}_{j}")
            self.model.add(
                self.item_vars.packs_item(i) + self.item_vars.packs_item(j) >= 2 * var
            )
            self.bonus_vars[(i, j)] = var
        return self.bonus_vars[(i, j)]
```

У `KnapsackSolver` можна поводитися так, ніби всі змінні існують, не турбуючись
про оптимізацію. Зверніть увагу: ціль ми будуємо у `solve`, бо бонуси змінюють
ціль. Також, інкапсулювавши змінні у `_ItemSelectionVars`, ми можемо легко
передавати їх іншим компонентам.

```python
class KnapsackSolver:
    def __init__(self, instance: KnapsackInstance, config: KnapsackSolverConfig):
        self.instance = instance
        self.config = config
        self.model = cp_model.CpModel()
        self._item_vars = _ItemSelectionVars(instance, self.model)
        self._bonus_vars = _CombiVariables(instance, self.model, self._item_vars)
        self._objective_terms = [self._item_vars.packed_value()]
        self.solver = cp_model.CpSolver()

    def solve(self) -> KnapsackSolution:
        self.model.maximize(sum(self._objective_terms))
        self.solver.parameters.max_time_in_seconds = self.config.time_limit
        self.solver.parameters.relative_gap_limit = self.config.opt_tol
        self.solver.parameters.log_search_progress = self.config.log_search_progress
        status = self.solver.solve(self.model)
        if status in [cp_model.OPTIMAL, cp_model.FEASIBLE]:
            return KnapsackSolution(
                selected_items=self._item_vars.extract_packed_items(self.solver),
                objective=self.solver.objective_value,
                upper_bound=self.solver.best_objective_bound,
            )
        return KnapsackSolution(
            selected_items=[], objective=0, upper_bound=float("inf")
        )

    def add_bonus(self, item_a: int, item_b: int, bonus: int):
        bonus_var = self._bonus_vars[(item_a, item_b)]
        self._objective_terms.append(bonus * bonus_var)
```

> [!TIP]
>
> Якщо ми точно знаємо, що `add_bonus` викликається для пари лише один раз,
> можна не зберігати bonus_vars, а створювати змінну і додавати в ціль одразу.
> Немає потреби зберігати handle, якщо він не потрібен пізніше.

### Підмоделі

Ми можемо покращити підхід, інкапсулюючи цілі секції моделі в окремі підмоделі.
Це корисно для складних моделей, де компоненти слабо пов’язані. Розбиття на
підмоделі підвищує модульність і підтримуваність. Підмоделі комунікують із
головною моделлю через спільні змінні, приховуючи деталі, як-от допоміжні
змінні. Якщо вимоги зміняться, можна переписати одну підмодель без впливу на
інші. Також часто логіка повторюється у різних оптимізаційних задачах, тому
бібліотека підмоделей дозволяє швидко збирати нові моделі з компонентів.

Наприклад, кусково-лінійні функції можна оформити як підмодель, як у класі
`PiecewiseLinearConstraint` у
[piecewise_linear_function.py](https://github.com/d-krupke/cpsat-primer/blob/main/utils/piecewise_functions/piecewise_linear_function.py).
Кожна підмодель керує однією функцією, взаємодіючи з моделлю через `x` та `y`.
Інкапсуляція робить логіку повторно використовуваною і тестованою окремо.

```python
from ortools.sat.python import cp_model

requirements_1 = (3, 5, 2)
requirements_2 = (2, 1, 3)

model = cp_model.CpModel()
buy_1 = model.new_int_var(0, 1_500, "buy_1")
buy_2 = model.new_int_var(0, 1_500, "buy_2")
buy_3 = model.new_int_var(0, 1_500, "buy_3")

produce_1 = model.new_int_var(0, 300, "produce_1")
produce_2 = model.new_int_var(0, 300, "produce_2")

model.add(produce_1 * requirements_1[0] + produce_2 * requirements_2[0] <= buy_1)
model.add(produce_1 * requirements_1[1] + produce_2 * requirements_2[1] <= buy_2)
model.add(produce_1 * requirements_1[2] + produce_2 * requirements_2[2] <= buy_3)

# PiecewiseLinearFunction і PiecewiseLinearConstraint — у utils
from piecewise_functions import PiecewiseLinearFunction, PiecewiseLinearConstraint

# Функції витрат
costs_1 = [(0, 0), (1000, 400), (1500, 1300)]
costs_2 = [(0, 0), (300, 300), (700, 500), (1200, 600), (1500, 1100)]
costs_3 = [(0, 0), (200, 400), (500, 700), (1000, 900), (1500, 1500)]

f_costs_1 = PiecewiseLinearFunction(
    xs=[x for x, y in costs_1], ys=[y for x, y in costs_1]
)
f_costs_2 = PiecewiseLinearFunction(
    xs=[x for x, y in costs_2], ys=[y for x, y in costs_2]
)
f_costs_3 = PiecewiseLinearFunction(
    xs=[x for x, y in costs_3], ys=[y for x, y in costs_3]
)

# Функції доходу
gain_1 = [(0, 0), (100, 800), (200, 1600), (300, 2000)]
gain_2 = [(0, 0), (80, 1000), (150, 1300), (200, 1400), (300, 1500)]

f_gain_1 = PiecewiseLinearFunction(
    xs=[x for x, y in gain_1], ys=[y for x, y in gain_1]
)
f_gain_2 = PiecewiseLinearFunction(
    xs=[x for x, y in gain_2], ys=[y for x, y in gain_2]
)

# y >= f(x) для витрат
x_costs_1 = PiecewiseLinearConstraint(model, buy_1, f_costs_1, upper_bound=False)
x_costs_2 = PiecewiseLinearConstraint(model, buy_2, f_costs_2, upper_bound=False)
x_costs_3 = PiecewiseLinearConstraint(model, buy_3, f_costs_3, upper_bound=False)

# y <= f(x) для доходу
x_gain_1 = PiecewiseLinearConstraint(model, produce_1, f_gain_1, upper_bound=True)
x_gain_2 = PiecewiseLinearConstraint(model, produce_2, f_gain_2, upper_bound=True)

# Максимізуємо дохід мінус витрати
model.maximize(x_gain_1.y + x_gain_2.y - (x_costs_1.y + x_costs_2.y + x_costs_3.y))
```

Тестування складних оптимізаційних моделей часто складне, бо результати можуть
змінюватися навіть через дрібні зміни. Навіть якщо тест знаходить помилку,
виявити джерело складно. Винесення елементів у підмоделі дозволяє тестувати їх
окремо, забезпечуючи коректність перед інтеграцією.

Підмоделі зазвичай значно простіші за основну задачу, тож оптимізуються швидко,
а отже тести працюють швидко.

```python
from ortools.sat.python import cp_model

def test_piecewise_linear_upper_bound_constraint():
    model = cp_model.CpModel()
    x = model.new_int_var(0, 20, "x")
    f = PiecewiseLinearFunction(xs=[0, 10, 20], ys=[0, 10, 5])

    # Використовуємо підмодель
    c = PiecewiseLinearConstraint(model, x, f, upper_bound=True)
    model.maximize(c.y)

    # Перевіряємо поведінку
    solver = cp_model.CpSolver()
    status = solver.solve(model)
    assert status == cp_model.OPTIMAL
    assert solver.value(c.y) == 10
    assert solver.value(x) == 10
```

Альтернативно можна тестувати здійсненність/недопустимість, особливо якщо
підмодель не є оптимізаційною задачею сама по собі.

```python
from ortools.sat.python import cp_model

def test_piecewise_linear_upper_bound_constraint_via_fixation():
    model = cp_model.CpModel()
    x = model.new_int_var(0, 20, "x")
    f = PiecewiseLinearFunction(xs=[0, 10, 20], ys=[0, 10, 5])
    c = PiecewiseLinearConstraint(model, x, f, upper_bound=True)

    # Фіксуємо змінні на конкретних значеннях
    model.add(x == 10)
    model.add(c.y == 10)

    solver = cp_model.CpSolver()
    status = solver.solve(model)
    assert status == cp_model.OPTIMAL, "Модель має бути допустимою"

def test_piecewise_linear_upper_bound_constraint_via_fixation_infeasible():
    model = cp_model.CpModel()
    x = model.new_int_var(0, 20, "x")
    f = PiecewiseLinearFunction(xs=[0, 10, 20], ys=[0, 10, 5])
    c = PiecewiseLinearConstraint(model, x, f, upper_bound=True)

    # Фіксуємо значення, що порушують обмеження
    model.add(x == 10)
    model.add(c.y == 11)

    solver = cp_model.CpSolver()
    status = solver.solve(model)
    assert status == cp_model.INFEASIBLE, "Модель має бути недопустимою"
```

### Вбудовування CP-SAT у застосунок через multiprocessing

Якщо ви хочете вбудувати CP-SAT у застосунок для потенційно довгих
оптимізаційних задач, можна використати callbacks, щоб показувати прогрес і
дозволяти раннє припинення. Проте застосунок може реагувати лише в момент
callback, а вони не завжди викликаються часто. Це може спричинити затримки і
погано підходить для GUI чи API.

Альтернатива — запускати solver в окремому процесі й спілкуватися з ним через
pipe. Це дозволяє перервати solver у будь-який момент і дає миттєву реакцію.
Python multiprocessing пропонує досить прості інструменти для цього.
[Цей приклад](https://github.com/d-krupke/cpsat-primer/blob/main/examples/embedding_cpsat/)
показує такий підхід. Щоб масштабувати його, зазвичай потрібна черга задач, де
solver запускається воркерами. Multiprocessing все одно корисний, бо дозволяє
воркеру залишатися чутливим до сигналів зупинки, поки solver працює.

| ![Interactive Solver with Streamlit using multiprocessing](https://github.com/d-krupke/cpsat-primer/blob/main/images/streamlit_solver.gif) |
| :----------------------------------------------------------------------------------------------------------------------------------------: |
|                                _Використовуючи multiprocessing, можна створити чутливий інтерфейс для solver-а._                                 |

[@oulianov](https://github.com/oulianov) розгорнув це
[тут](https://cpsat-embeddings-demo.streamlit.app/), щоб можна було спробувати
у браузері.

---

<!-- This file was generated by the `build.py` script. Do not edit it manually. -->
<!-- ./chapters/test_driven_optimization.md -->
# Test-Driven Development with CP-SAT


<a name="test-driven-optimization"></a>

In this chapter, we demonstrate how to apply test-driven development (TDD)
principles to the nurse rostering problem using the CP-SAT solver. Our objective
is to build a model that is modular, thoroughly tested, extensible, and
straightforward to maintain.

I consider TDD a valuable approach for optimization problems, even though I do
not follow the formal TDD cycle strictly. Writing tests early helps clarify
requirements, refine problem specifications, and expose ambiguities in the
initial formulation. In many real-world scenarios, the problem statement is
incomplete or evolving. By expressing expectations as executable tests, we can
communicate requirements more effectively and adjust them as new insights
emerge.

The nurse rostering problem is particularly suitable for illustrating this
approach. It represents a class of scheduling problems where constraints and
objectives change frequently in response to stakeholder feedback. In such
settings, modular design and systematic testing substantially reduce the cost of
adapting and validating the model as requirements evolve.

For small or well-defined problems, a simple implementation with a few manual
checks may suffice. However, as complexity grows and outcomes become harder to
verify informally, a structured, test-driven approach proves highly beneficial.
It allows the problem to be decomposed into smaller, testable components that
can be incrementally implemented, validated, and refined.

This chapter does not advocate for perfection at the outset. In practice,
building a working prototype often comes first, and design improvements are
introduced once they offer clear benefits. The key is to maintain a balance
between rapid prototyping and introducing structure and tests at the right stage
of development.

We will incrementally construct a nurse rostering model using CP-SAT, guided by
test-driven principles. The workflow includes defining formal **data schemas**
for inputs and outputs, implementing **solver-independent validation functions**
that encode constraints and objectives, and creating **modular components** for
decision variables, constraints, and soft objectives. We conclude by combining
these modules into a complete solver and verifying its solutions on test
instances. However, before doing so, we will briefly review a classical approach
and what can go wrong when the problem complexity increases.

> :warning:
>
> This chapter is not intended as a strict guideline but as one possible
> approach. I do not follow every step outlined here in every project. Instead,
> I aim to share principles that I have found useful in practice. Operations
> researchers may gain insights into software engineering practices, while
> software engineers may learn how to apply their skills to optimization models.
> Experienced optimizers may find value in comparing their own approach with the
> one presented here.

---

> [!TIP]
>
> There appears to be limited material addressing software engineering practices
> specifically in operations research. However, the talk
> [_Optimization Modeling: The Art of Not Making It an Art_](https://www.gurobi.com/events/optimization-modeling-the-art-of-not-making-it-an-art/)
> by Ronald van der Velden (Gurobi) is an excellent resource that partially
> overlaps with the themes discussed in this chapter. (Note: Registration with a
> company name and email address is required to access the content.)

You can find the complete code for this chapter
[here](https://github.com/d-krupke/cpsat-primer/tree/main/examples/tdd).

## Classical Steps for Textbook Problems

<!-- From classroom to complex reality -->

Before introducing the more advanced TDD-inspired workflow, let us briefly
review a classical approach to implementing optimization models, as commonly
encountered in textbook exercises or university homework. This traditional
approach can also be effective for many real-world problems, provided their
complexity remains moderate. However, real-world problems often introduce
additional challenges that are absent from well-structured academic exercises.
As the problem complexity increases, this classical approach becomes difficult
to manage. We will therefore explore how software engineering practices can help
address these challenges.

Let us consider a concrete example: the **Facility Location Problem (FLP)**. To
set the right context, we will present it as if it were stated directly on a
homework sheet:

<!-- Textbook Exercise FLP -->

> A delivery company is planning to open new warehouses to serve its customers.
> There is a set $F$ of potential warehouse locations, and a set $C$ of
> customers who need to receive their orders.
>
> Opening a warehouse at location $i \in F$ comes with a fixed cost $f_i$.
> Shipping goods from warehouse $i \in F$ to customer $j \in C$ costs $c_{i,j}$.
>
> Every customer $j \in C$ must be served by exactly one warehouse, and a
> warehouse can only ship goods if it is actually opened.
>
> The company needs to decide which warehouse locations $i \in F$ to open and
> which warehouse will serve each customer $j \in C$ so that the total
> cost—consisting of the opening costs $f_i$ and the shipping costs $c_{i,j}$—is
> as small as possible.

<!-- Approach to convert it into a mathematical model -->

Now, a good idea would be to highlight parameters, decisions, constraints, and
objectives in the text (using different colors), and then write down the
mathematical formulation of the problem in the following steps:

1. **Parameters:** Define the problem parameters, specifying the input data for
   the model.
2. **Decision Variables:** Define the variables representing the decisions or
   assignments to be made.
3. **Constraints and Objectives:** Specify the constraints that must be
   satisfied and the objectives to be optimized.

<!-- The mathematical model -->

For this problem, this would look like this:

> **Parameters:**
>
> - $F$: Set of potential facility locations.
> - $C$: Set of customers.
> - $f_i \in \mathbb{N}_0$ for $i \in F$: Fixed cost of opening facility $i$.
> - $c_{i,j} \in \mathbb{N}_0$ for $i \in F, j \in C$: Cost of serving customer
>   $j$ from facility $i$.
>
> **Decision Variables:**
>
> - $y_i \in \mathbb{B} \ \forall i \in F$: $y_i = 1$ if facility $i$ is opened,
>   and 0 otherwise.
> - $x_{i,j} \in \mathbb{B} \ \forall i \in F, j \in C$: $x_{i,j} = 1$ if
>   customer $j$ is served by facility $i$, and 0 otherwise.
>
> **Objective Function:**
>
> Minimize the total cost of opening facilities and serving customers:
> $\min \sum_{i \in F} f_i \cdot y_i + \sum_{i \in F} \sum_{j \in C} c_{i,j} \cdot x_{i,j}.$
>
> **Constraints:**
>
> 1. **Customer Assignment:** Each customer must be served by exactly one open
>    facility: $\sum_{i \in F} x_{i,j} = 1 \quad \forall j \in C.$
> 2. **Facility Activation:** A customer can only be served by a facility if
>    that facility is open: $x_{i,j} \leq y_i \quad \forall i \in F, j \in C.$

<!-- The mathematical model is concise and precise -->

The mathematical notation is so compact that one can easily work through it on a
whiteboard or a sheet of paper, which makes it ideal for group discussions. Such
concise, precise notation also makes it easier to identify inconsistencies or
errors directly at least for smaller problems.

<!-- implementation -->

Finally, you implement it either with your favorite optimization framework or
modelling language. In case of an exercise, it is also very likely that your
instructor has already provided some test instances, which you can use to verify
your implementation.

```python
from ortools.sat.python import cp_model

# 1. Parameters
F = [1, 2, 3]  # Set of potential facility locations.
C = [1, 2, 3]  # Set of customers.
f = {1: 100, 2: 200, 3: 150}  # Fixed cost f[i] of opening facility i.
c = {1: {1: 10, 2: 20, 3: 30},
     2: {1: 15, 2: 25, 3: 35},
     3: {1: 20, 2: 30, 3: 40}}  # Cost c[i][j] of serving customer j from facility i.

model = cp_model.CpModel()

# 2. Decision variables
y = {i: model.new_bool_var(f'y_{i}') for i in F}  # y[i] = 1 if facility i is opened.
x = {(i, j): model.new_bool_var(f'x_{i}_{j}') for i in F for j in C}  # x[i,j] = 1 if customer j is served by facility i.

# 3. Objective function
model.minimize(
    sum(f[i] * y[i] for i in F) + sum(c[i][j] * x[i, j] for i in F for j in C)
)
# 4. Constraints
for j in C:
    model.add(sum(x[i, j] for i in F) == 1)  # Each customer must be served by exactly one open facility.
for i in F:
    for j in C:
        model.add(x[i, j] <= y[i])  # A customer can only be served by a facility if that facility is open.

# Solve the model
solver = cp_model.CpSolver()
status = solver.solve(model)
# ...
```

<!-- classes instead of functions -->

Usually you would implement this in a function; however, I often need to make
models incremental, which is not compatible with stateless functions. Moreover,
using classes in Python is almost as straightforward as using pure functions.
Being able to manipulate the model after construction, like fixing certain
variables, also makes it easier to test and debug.

<!-- Example of wrapping it into a class. -->

I would encapsulate this code in a class to enhance reusability, resulting in an
implementation similar to the following:

```python
class FacilityLocationModel:
    def __init__(self, F, C, f, c):
        self.F, self.C, self.f, self.c = F, C, f, c
        self.model = cp_model.CpModel()

        # 2. Decision variables
        self.y = {i: self.model.new_bool_var(f'y_{i}') for i in self.F}  # y[i] = 1 if facility i is opened.
        # ...

    def solve(self, **parameters):
        # Solve the model
        solver = cp_model.CpSolver()
        # ...
```

<!-- you could also just directly model it in code -->

As you can see, the implementation is actually nearly identical to the
mathematical formulation and many experts may opt to directly implement it,
especially when using modeling languages like Pyomo, GAMS, or AMPL.

<!-- also works for many practical cases as many practical problems are basic -->

In practice, many cases are still simple enough to follow this workflow.
Although the data may not be readily available or may require extensive
preprocessing, and the problem statement may not yet be fully defined, it is
often possible to sketch the mathematical formulation and then implement it in a
single step. This is particularly feasible because many problems are essentially
well-known combinatorial optimization problems, merely obscured by
domain-specific terminology. With experience, you can often identify the
underlying structure of the problem quickly and adapt them to custom constraints
with ease.

<!-- perfect for simple problems -->

As long as the model remains this simple, you may only need to add a few basic
tests to verify that the solutions behave as expected; there is no need for
modularization or extensive validation functions. Such a model is easy to
understand and can be implemented within minutes. It can be presented on a
single slide, and any additional structure would likely introduce unnecessary
complexity rather than improving clarity.

<!-- from simplifying abstraction to incomprehensible, similar to tech debt -->

Mathematical abstraction can simplify a problem; however, it can also become so
abstract that the original problem is no longer recognizable. While the
threshold varies depending on one's background, there comes a point at which
monolithic mathematical formulations become incomprehensible, and even minor
modifications require significant effort. It will also be extremely difficult to
debug such a model if you cannot look at components in isolation. This situation
parallels a software architecture that, while initially straightforward, has
accumulated complexity through incremental growth, to the point where any
modification is fraught with risk and development velocity suffers.

<!-- Examples of things that can go wrong -->

Here are a few things that can go wrong when the model grows too complex:

- You are the only one who understands the model, making it unmaintainable by
  others.
- Even you no longer fully understand the model, causing simple changes to take
  forever or to break things—often only discovered when it fails in production.
- The model's complexity makes it impossible to verify individual components in
  isolation, making root-cause analysis extremely difficult.
- Testing becomes impractical, leaving you with constant doubts about whether
  the model is correct.
- A subtle bug silently excludes high-quality solutions, leading to significant
  opportunity loss without any explicit error.
- Bad or inconsistent data goes undetected due to missing validation checks,
  producing incorrect results and eroding trust in your code.
- Communication with stakeholders breaks down because you lack a clear, shared
  language to formally specify requirements.
- The model becomes so convoluted that implementing all requirements—or even
  building a first useful prototype—feels impossible.
- No clear input/output data interfaces, making collaboration and integration
  difficult.
- ...

<!-- These are failures on the "easy" parts -->

All of these issues may fail the project, before even reaching the real
challenges of optimizing scalability and ensuring real-world accuracy.

<!-- Overview -->

In the remainder of this chapter, we will explore how to avoid this situation by
applying software engineering practices to optimization models on the example of
the nurse rostering problem. We will do the following steps:

1. **Data Schema:** Define structured schemas for the problem instance and
   solution, covering parameters and parts of the decision space.
2. **Validation Functions:** Implement functions to verify feasibility and
   compute objective values, serving as the formal specification.
3. **Decision Variables:** Introduce decision variables encapsulated in
   containers to simplify constraint and objective construction.
4. **Modular Constraints and Objectives:** Build constraints and soft objectives
   as independent, testable modules.
5. **Solver Integration:** Combine these components into a complete CP-SAT model
   and test it in completion to check that the components work together as
   expected.

<!-- not all-or-nothing -->

> [!TIP]
>
> You can transition fluently between the two approaches; it is not an
> all-or-nothing choice. It is entirely feasible to adopt only parts of the
> approach described here and apply them to selected aspects of the problem.

## The Nurse Rostering Problem

Before implementing a solution, we first outline the nurse rostering problem and
its initial requirements. The
[nurse rostering problem](https://en.wikipedia.org/wiki/Nurse_scheduling_problem)
involves assigning a set of nurses to shifts over a defined planning horizon.
Each shift has a specified demand indicating the minimum number of nurses
required. The goal is to produce an assignment that satisfies all operational
constraints while optimizing soft preferences and priorities. In this example,
the requirements are as follows:

**Constraints (Hard Requirements):**

1. **Unavailability Constraint:** A nurse must not be assigned to any shift for
   which they are unavailable or explicitly blocked.
2. **Shift Coverage Requirement:** Each shift must be staffed with a sufficient
   number of nurses to meet its demand.
3. **Rest Period Constraint:** A nurse must have an adequate rest period between
   consecutive shifts. If the interval between the end of one shift and the
   start of the next is too short, the nurse cannot be assigned to both.

**Objectives (Soft Goals):**

1. **Preference Satisfaction:** Nurses may indicate preferences for particular
   shifts. The model should honor these preferences wherever possible.
2. **Staffing Preference:** Internal staff members should be preferred over
   external or contract nurses when all other constraints are satisfied.

To keep the initial formulation manageable, we start with this limited set of
constraints and objectives. The implementation is designed to be **modular and
extensible**, allowing additional requirements—such as fairness, seniority,
on-call shifts, and others—to be introduced later with minimal refactoring.
While the initial requirements may still be easily implemented in a monolithic
model, it should already be complex enough to illustrate the benefits of a more
structured, test-driven approach.

> [!WARNING]
>
> This chapter focuses on correctness, not performance. First, ensure the
> solution is correct; only then focus on making it efficient. Correspondingly,
> the implementation here may not be the most efficient.

## Instance and Solution Schema

<!-- Textbook examples assume perfect data; real-world data rarely is -->

In academic or textbook settings, one often starts with clean, well-structured
data that is perfectly tailored to the problem at hand. In real-world projects,
however, this is rarely the case. You are often lucky to receive any data at
all—let alone data that is complete, consistent, and ready for use.

<!-- Data might not even exist yet, or only on paper, or be incomplete -->

Data may not yet exist in digital form, or it may still be collected
manually—perhaps even on paper. Even if a digital system is under development,
it may not yet be deployed, and any available data might be outdated or
incomplete. Privacy concerns or legal constraints may further restrict access to
critical information, especially when working with personnel data, such as nurse
schedules.

> [!TIP]
>
> Obtain a data sample as early as possible, even if it is only an "educated
> guess" or a small subset of the actual dataset. Such samples simplify the
> extraction of test cases and support iterative discussions with stakeholders,
> who often overlook trivial but important details. For instance, the model
> developed here does not enforce a single shift per day, focusing instead on
> rest periods and total working hours over a given period (e.g., a week).
> Stakeholders are likely to recognize such omissions as soon as they review a
> solution for a realistic instance. Addressing these issues typically requires
> an agile, iterative process, which we omit here for simplicity but which can
> be applied throughout all phases of this example.

<!-- Even available data is often inconsistent or unreliable -->

And when the data does arrive, it often brings problems of its own. It may be
incomplete, contain contradictory entries, or be structured inconsistently.
Excel remains a de facto standard in many organizations, which introduces risks
such as data type mismatches, inconsistent formatting, or broken formulas. Even
worse are schemaless databases like Firestore, which offer no guarantees about
the structure or consistency of stored documents. It is not uncommon to find
fields that sometimes contain integers, sometimes strings, and occasionally just
vanish altogether—along with keys that are misspelled, duplicated, or silently
dropped.

<!-- Bad input leads to failure in your code, not just theirs -->

In such environments, any error in the data will propagate directly to your
application. Your logic fails not because your model is incorrect, but because
upstream inputs violate assumptions you did not realize you were making.

<!-- Introduce schema validation and Pydantic as solution -->

After enough frustrating encounters with malformed data, I became a strong
proponent of defining formal data schemas as a first step in any serious
optimization project. For Python, I have found
[Pydantic](https://docs.pydantic.dev/latest/) to be an excellent tool: it allows
you to define input and output schemas declaratively, enforces type checks and
invariants automatically, and raises clear validation errors when assumptions
are violated. With these schemas in place, problems can be caught early and
diagnosed easily—long before they produce incorrect results or puzzling
failures.

<!-- Schemas are not just for machines; they clarify team communication -->

Defining a schema is also crucial for ensuring that all collaborators (including
clients) are aligned in their understanding of the problem. You may all be using
the same terms—like "shift", "start time", or "duration"—but interpret them
differently. Is that duration in seconds, minutes, or hours? Is the "shift ID"
an index or a foreign key to a separate table? Without a precise schema, it is
easy to make dangerous assumptions.

<!-- Example from history: Mars Climate Orbiter -->

A vivid historical example is the loss of the
[Mars Climate Orbiter](https://en.wikipedia.org/wiki/Mars_Climate_Orbiter)
in 1999. The spacecraft was destroyed because one team used imperial units while
another expected metric, and there was no enforced contract between the systems.
The entire $327 million mission failed because of a silent mismatch in a shared
data interface. While most optimization projects are not launching spacecraft,
the takeaway is just as relevant: never assume shared understanding—make your
assumptions explicit.

<!-- Start with schemas before writing any logic -->

That is why I prefer to define and document both the input and output schemas at
the beginning of a project, even before writing the first line of algorithmic
code. It helps formalize the problem, clarifies the roles of different fields,
and allows everyone to work toward the same structure. Even if the schema
evolves over time (and it almost certainly will), the evolution is transparent,
versioned, and easy to manage.

<!-- Summary: schemas are foundational -->

Below is the data schema we will be using for the nurse rostering problem. We
made two non-trivial additions: `preferred_shift_weight` and `staff_weight`.
These will unlikely be part of the initial problem formulation, but as we have
two objectives, this would allow us to easily weight the two objectives against
each other. It could be that later on, we decide that the optimization should be
lexicographic, making these weights irrelevant, but it is a good starting point
to have at least some way of balancing the two objectives. If there are more
parameters to specify the problem, e.g., switching constraints on and off, I
would create a separate `NurseRosteringParameters` class that contains these
parameters, instead of integrating them into the instance schema, but let us
skip that for simplicity.

```python
"""
This module defines the data schema for the nurse rostering problem.
Note that this is just a random variant of the nurse rostering problem.

We define the instance and solution data structures using Pydantic.
"""

from datetime import datetime, timedelta
from pydantic import BaseModel, Field, NonNegativeInt, model_validator, PositiveInt
import uuid

# Semantic type aliases for clarity
NurseUid = int
ShiftUid = int


def generate_random_uid() -> int:
    # Use uuid4 and convert to an integer (truncated to 64 bits for practical use)
    return uuid.uuid4().int >> 64


class Nurse(BaseModel):
    """
    Represents a nurse whose shifts we want to plan. Will be part of `NurseRosteringInstance`.
    """
    uid: NurseUid = Field(
        default_factory=generate_random_uid,
        description="Unique identifier for the nurse",
    )
    name: str = Field(..., description="Name of the nurse")
    preferred_shifts: set[ShiftUid] = Field(
        ..., description="List of preferred shift UIDs for the nurse"
    )
    blocked_shifts: set[ShiftUid] = Field(
        ..., description="List of blocked shift UIDs for the nurse"
    )
    staff: bool = Field(
        ...,
        description="Indicates if the nurse is a staff member (True) or a contractor (False)",
    )
    min_time_between_shifts: timedelta = Field(
        ..., description="Minimum off duty time between two shifts for the same nurse"
    )
    preferred_shift_weight: NonNegativeInt = Field(
        default=1,
        description="The weight in the objective function for every assigned preference.",
    )


class Shift(BaseModel):
    """
    Represents a shift that needs to be covered by nurses. Will be part of `NurseRosteringInstance`.
    """
    uid: ShiftUid = Field(
        default_factory=generate_random_uid,
        description="Unique identifier for the shift",
    )
    name: str = Field(..., description="Name of the shift (e.g., '2025-01-01 Morning')")
    start_time: datetime = Field(
        ..., description="Start time of the shift as a full datetime (YYYY-MM-DD HH:MM)"
    )
    end_time: datetime = Field(..., description="End time of the shift as a full datetime (YYYY-MM-DD HH:MM)")
    demand: NonNegativeInt = Field(
        ..., description="Number of nurses required for this shift"
    )

class NurseRosteringInstance(BaseModel):
    """
    This schema defines the INPUT for the nurse rostering problem.
    """
    nurses: list[Nurse] = Field(
        ..., description="List of nurses in the rostering instance"
    )
    shifts: list[Shift] = Field(
        ...,
        description="List of shifts that need to be covered. Shifts must be sorted in time.",
    )
    staff_weight: int = Field(
        default=1,
        description="The weight in the objective function for each assigned staff nurse.",
    )

    @model_validator(mode="after")
    def validate_shifts_unique_uids(self):
        """
        Ensure that all shifts have unique UIDs to avoid conflicts.
        """
        shift_uids = {shift.uid for shift in self.shifts}
        if len(shift_uids) != len(self.shifts):
            raise ValueError("Shift UIDs must be unique.")
        return self

    @model_validator(mode="after")
    def validate_nurses_unique_uids(self):
        """
        Ensure that all nurses have unique UIDs to avoid conflicts.
        """
        nurse_uids = {nurse.uid for nurse in self.nurses}
        if len(nurse_uids) != len(self.nurses):
            raise ValueError("Nurse UIDs must be unique.")
        return self

    @model_validator(mode="after")
    def validate_shifts_sorted_by_time(self):
        """
        Ensure that shifts are sorted by start time.
        """
        for shift_a, shift_b in zip(self.shifts, self.shifts[1:]):
            if shift_a.start_time > shift_b.start_time:
                raise ValueError("Shifts must be sorted by start time.")
        return self
```

<!-- Solution schema and pydantic vs native lists -->

For the solution, each shift is mapped to a list of assigned nurses. In
addition, the objective value and the timestamp at which the solution was
computed are recorded. As a potential improvement, the `list[NurseUid]`
structure could be replaced with a dedicated Pydantic model. This approach would
allow for the inclusion of additional shift-specific data in the future, which
cannot be directly attached to a plain `list`. Such a design would be
particularly advantageous when the solution must be presented in a user
interface. Nevertheless, as long as the base object is defined as a Pydantic
model, it is generally possible to maintain backward compatibility when
extending the schema, even when certain native Python elements are involved.

```python
class NurseRosteringSolution(BaseModel):
    """
    This schema defines the OUTPUT for the nurse rostering problem.
    """
    nurses_at_shifts: dict[ShiftUid, list[NurseUid]] = Field(
        ..., description="Maps shift UIDs to lists of assigned nurse UIDs."
    )
    objective_value: int = Field(
        description="Objective value of the computed solution."
    )
    timestamp: datetime = Field(
        default_factory=datetime.now,
        description="Time when the solution was generated. Takes little space and can be extremely useful when investigating issues with the solution. Optimally, also add the revision of the algorithm that generated the solution, e.g., by using a git commit hash.",
    )
    # Validation of the solution will be handled in a separate module.
```

With these schemas in place, it becomes immediately clear what structure the
input and output must follow. The `model_validator` methods let you encode
important assumptions—such as uniqueness or sorting—and they raise explicit
errors if those assumptions are violated. While this does not guarantee that all
data is actually correct, it prevents many accidental errors and makes debugging
significantly easier. By catching issues at the boundary, you gain confidence
that the optimization logic operates on well-formed inputs.

> [!TIP]
>
> You do not need to use the same schema for the endpoint contract and the
> internal representation of the optimization model. Converting between
> different schemas is inexpensive compared to the computational cost of solving
> the model. If a different representation enables more efficient model
> construction, introduce an additional layer. Remember that the internal schema
> can be modified easily, but changes to the outward-facing schema must be
> handled carefully to avoid breaking existing interfaces.

### Tabular Data

<!-- Tabular data is common and very nice to work with, if it is clean -->

Many people, including myself, appreciate working with tables. In the chapter’s
example project, we use a nested data structure. However, in many projects
tabular data is entirely sufficient, and in such cases you should prefer this
representation. In principle, any data structure can be expressed in tabular
form, and most common databases, in particular relational databases accessed via
SQL, are built around tables. Nevertheless, when extracting information requires
complex joins or aggregations, you may need to either restructure your tables or
adopt a more object-oriented format, for example by using Pydantic models as
shown above. Since input data should not be modified during model construction,
it is perfectly acceptable to employ both representations in parallel.

If your data can be naturally and intuitively expressed in tabular form, then
you should retain this representation. Python provides excellent libraries for
working with tabular data, most notably [Pandas](https://pandas.pydata.org/) and
[Polars](https://www.pola.rs/). Pandas is the most widely used library for data
analysis in Python, and it benefits from a rich ecosystem of extensions and
integrations. However, it can exhibit performance limitations, particularly with
large datasets. Polars is a newer library that is more performance-oriented.
Since optimization problems typically involve much smaller datasets than those
encountered in data analysis or machine learning, the widespread use and
ecosystem of Pandas usually make it the more suitable choice.

The major advantage of storing data in a Pandas DataFrame is the ability to
perform aggregations, filtering, and transformations with a concise and
expressive syntax. In addition, Pandas integrates well with visualization
libraries such as [Matplotlib](https://matplotlib.org/) and
[Seaborn](https://seaborn.pydata.org/), which allow you to easily create
informative visual representations of your data.

Do you want to scale a column to the range [0, 1]? This requires only a single
line of code:

```python
df['scaled_column'] = (df['column'] - df['column'].min()) / (df['column'].max() - df['column'].min())
```

Do you want to filter rows based on a condition? Again, this can be achieved in
one line:

```python
filtered_df = df[df['column'] > threshold]
```

CP-SAT also provides integration with Pandas, as demonstrated in the following
knapsack example, where the values and weights of items are stored in a
`DataFrame`:

```python
from ortools.sat.python import cp_model
import pandas as pd

# Example data: each row is an item with a weight and a value
# In production, you would likely load this from a file or database,
# which pandas has simple loaders for.
df = pd.DataFrame(
    data={
        "weight": [2, 4, 3, 5, 1, 6, 2, 7, 3, 4],
        "value": [10, 8, 7, 6, 5, 9, 4, 3, 2, 1],
    },
    index=["A", "B", "C", "D", "E", "F", "G", "H", "I", "J"],
)

model = cp_model.CpModel()

# Create a Boolean variable for each item (indexed by DataFrame index)
x = model.new_bool_var_series("x", df.index)

# Use Pandas vectorized operations to build constraints and objectives
model.add((x @ df["weight"]) <= 15)  # total weight limit
model.maximize(x @ df["value"])      # maximize total value
```

Some constraints can also be conveniently added row by row. For example, suppose
we have a set of prohibited pairs of items that cannot be selected together.
Such restrictions can be represented naturally as a two-column table:

```python
prohibited_pairs_df = pd.DataFrame(
    data={
        "item1": ["A", "B", "C"],
        "item2": ["D", "E", "F"],
    }
)

# For each row, apply the corresponding constraint
for _, row in prohibited_pairs_df.iterrows():
    model.add(x[row["item1"]] + x[row["item2"]] <= 1)
```

Suppose we have not only prohibited pairs of items but arbitrary sets of items
that cannot be selected together. To express this structure in a classical
tabular format, we would introduce a unique identifier for each set and a
relation table that maps item identifiers to set identifiers. To build the
constraints, we would first group the rows by set identifier, aggregate the
corresponding item identifiers, and then add the constraint for each set. If
this requirement constitutes only a small portion of the model, the tabular
approach is acceptable. However, if the model relies on many such sets or lists,
I recommend switching to a more object-oriented representation, as used in the
nurse rostering problem in this chapter.

When working with tabular data, it is still important to enforce a strict
schema, as we did with the Pydantic models above. This can be achieved with
libraries such as [pandera](https://pandera.readthedocs.io/en/stable/). For
instance, we can require that the weights and values of the items are
non-negative integers. Although this may appear trivial, errors can easily
arise, for example when data is extracted from widely used Excel files somewhere
in the processing pipeline.

```python
import pandas as pd
import pandera.pandas as pa

schema = pa.DataFrameSchema({
    "weight": pa.Column(int, pa.Check.ge(0)),
    "value": pa.Column(int, pa.Check.ge(0)),
})

validated_df = schema.validate(df)
```

> [!NOTE]
>
> Princeton Consultants provide an excellent post on
> [Rapid Optimization Model Development with Python and pandas in 7 Steps](https://princetonoptimization.com/blog/rapid-optimization-model-development-python-and-pandas-7-steps/),
> which offers a more detailed discussion of the model-building process with
> Pandas. In my own work, I am often involved in projects where the data is more
> graph-like or hierarchical, in which case Pydantic tends to be a more natural
> representation for building optimization models. I explicitly added this
> subsection to emphasize that using nested data with Pydantic is not the only
> approach, and it is not always the best one. Ultimately, you should choose the
> representation that best matches your data and your team. If necessary, use
> multiple representations in parallel, as the additional memory overhead is
> usually negligible.

## Solver-Agnostic Validation

<!-- Writing validation functions early clarifies the constraints and enables TDD -->

With the data schemas defined, we can now implement validation functions that
check whether a proposed solution satisfies all constraints. This is the first
concrete step toward a test-driven workflow.

<!-- Emphasizes the value of validation for synchronization with stakeholders -->

These validation functions are solver-independent, meaning they do not rely on
any specific algorithm or library like CP-SAT. This makes them ideal for
communicating and verifying the specification with domain experts or clients. In
fact, someone with only basic programming skills could review or even contribute
to these checks, reducing misunderstandings about the problem's requirements.

<!-- Clarifies that defining the objective function explicitly is a big step forward -->

In addition to feasibility, we also define the objective function here. That
might seem unusual for validation logic, but it provides a clear and unambiguous
specification of what we are trying to optimize. In practice, the objective
function is often the most volatile part of the specification—frequently revised
as new goals, costs, or incentives are introduced. By expressing it in code, we
make it easier to reason about and iterate on collaboratively.

> :warning:
>
> Crafting an effective objective function requires experience. I have often
> observed less experienced practitioners reaching incorrect conclusions about
> its proper formulation. Common errors include unintentionally encoding parts
> of the objective as constraints or defining the objective in a way that allows
> undesirable trade-offs between its components. If a client provides an
> objective function, do not implement it blindly; instead, analyze it carefully
> before proceeding.

<!-- Summarizes the benefits -->

By writing these checks up front, we make the problem precise and executable.
Even without an optimization engine, we already know how to distinguish valid
from invalid solutions and how to compare two feasible solutions in terms of
quality. This gives us a solid foundation for developing and testing
optimization algorithms in the next steps. If we are lucky, we could even use it
as a feedback loop for an AI assistant to code the solution for us, although my
experiences with that have been mixed so far.

The following Python module provides these validation checks and a function to
compute the objective value:

```python
"""
This module contains validation functions for nurse rostering solutions.
It is solver and algorithm agnostic, meaning it can be used to validate solutions
from any solver that produces a `NurseRosteringSolution` object. Just by providing
such functions, you have taken a huge step toward computing a solution, as you now
have a clean specification of what a valid and good solution looks like.
"""

from collections import defaultdict
from .data_schema import NurseRosteringInstance, NurseRosteringSolution


def assert_consistent_uids(
    instance: NurseRosteringInstance, solution: NurseRosteringSolution
):
    """
    Assert that all UIDs in the solution are part of the instance.
    """
    nurse_uids = {n.uid for n in instance.nurses}
    shift_uids = {s.uid for s in instance.shifts}
    for shift_uid, nurse_list in solution.nurses_at_shifts.items():
        if shift_uid not in shift_uids:
            raise AssertionError(f"Shift {shift_uid} is not present in the instance.")
        for nurse_uid in nurse_list:
            if nurse_uid not in nurse_uids:
                raise AssertionError(
                    f"Nurse {nurse_uid} is not present in the instance."
                )


def assert_no_blocked_shifts(
    instance: NurseRosteringInstance, solution: NurseRosteringSolution
):
    """
    Assert that no nurse is assigned to a blocked shift in the solution.
    """
    for nurse in instance.nurses:
        for shift_uid in nurse.blocked_shifts:
            if (
                shift_uid in solution.nurses_at_shifts
                and nurse.uid in solution.nurses_at_shifts[shift_uid]
            ):
                raise AssertionError(
                    f"Nurse {nurse.uid} is assigned to blocked shift {shift_uid}."
                )


def assert_demand_satisfaction(
    instance: NurseRosteringInstance, solution: NurseRosteringSolution
):
    """
    Assert that each shift meets its nurse demand.
    """
    for shift in instance.shifts:
        assigned = solution.nurses_at_shifts.get(shift.uid, [])
        if len(assigned) < shift.demand:
            raise AssertionError(
                f"Shift {shift.uid} demand not met: {len(assigned)}/{shift.demand} assigned."
            )


def assert_min_time_between_shifts(
    instance: NurseRosteringInstance, solution: NurseRosteringSolution
):
    """
    Assert that nurses are not assigned to shifts too close together.
    """
    shifts_by_uid = {s.uid: s for s in instance.shifts}
    nurse_to_shifts = defaultdict(list)
    for shift_uid, nurse_uids in solution.nurses_at_shifts.items():
        for nurse_uid in nurse_uids:
            nurse_to_shifts[nurse_uid].append(shifts_by_uid[shift_uid])
    for nurse in instance.nurses:
        assigned = sorted(nurse_to_shifts[nurse.uid], key=lambda s: s.start_time)
        for a, b in zip(assigned, assigned[1:]):
            if b.start_time < a.end_time + nurse.min_time_between_shifts:
                raise AssertionError(
                    f"Nurse {nurse.uid} assigned to shifts {a.uid} and {b.uid} with insufficient rest."
                )


def objective_value(
    instance: NurseRosteringInstance, solution: NurseRosteringSolution
) -> int:
    """
    Calculate the objective value of the solution based on the instance's preferences and staff assignments.
    """
    nurses_by_uid = {n.uid: n for n in instance.nurses}
    obj_val = 0
    for shift_uid, nurse_uids in solution.nurses_at_shifts.items():
        for nurse_uid in nurse_uids:
            nurse = nurses_by_uid[nurse_uid]
            if shift_uid in nurse.preferred_shifts:
                # Preferred shifts decrease the objective (we minimize).
                obj_val -= nurse.preferred_shift_weight
            if not nurse.staff:
                # Non-staff nurses incur a penalty (they are more expensive).
                obj_val += instance.staff_weight
    return obj_val


def assert_solution_is_feasible(
    instance: NurseRosteringInstance,
    solution: NurseRosteringSolution,
    check_objective: bool = True,
):
    """
    Run all standard feasibility checks.
    """
    assert_consistent_uids(instance, solution)
    assert_no_blocked_shifts(instance, solution)
    assert_demand_satisfaction(instance, solution)
    assert_min_time_between_shifts(instance, solution)
    if check_objective:
        obj_val = objective_value(instance, solution)
        if obj_val != solution.objective_value:
            raise AssertionError(
                f"Objective value mismatch: expected {obj_val}, got {solution.objective_value}."
            )
```

<!-- validation functions are solver-independent and prioritize clarity -->

The main advantage of these validation functions is that they are completely
independent of any solver or optimization model. This means we do not need to
optimize their performance—they are meant to be correct, clear, and easy to
understand. Precise and informative error messages are essential, as these will
guide you when tests fail.

<!-- validation is especially valuable for complex problems -->

For simple problems, this level of validation may appear excessive, especially
since CP-SAT already uses a declarative modeling style. However, these functions
provide an independent specification of the problem, which is valuable for
catching misunderstandings and hidden assumptions early.

<!-- validation and CP-SAT complement each other -->

For more complex problems, these validation functions are often simpler and more
intuitive than the corresponding CP-SAT constraints. For example, when enforcing
minimum rest times between shifts, the validation logic directly checks for
violations, whereas CP-SAT encodes permissible patterns of assignments. In that
sense, validation and CP-SAT complement each other: one detects what is wrong,
the other defines what is allowed.

<!-- allows you to completely change the optimization algorithm -->

Lastly, it is quite possible that a pure CP-SAT model will not scale
sufficiently, despite all optimizations and you will have to decompose the
problem. These validation functions would remain useful and safeguard you while,
e.g., replacing the vanilla CP-SAT model with a large neighborhood search or a
metaheuristic approach.

> [!TIP]
>
> You could also add unit tests for these validation functions to ensure that
> they raise the expected errors for invalid inputs. However, I would consider
> this unnecessary in most cases, as the complementary nature of validation
> functions and CP-SAT constraints will likely catch most inconsistencies. If a
> test fails, always verify whether the test itself might be incorrect.

## Decision Variables

<!-- Transition from specification to modeling -->

Up to this point, we have defined the **parameters** of the problem (through our
Pydantic schemas) and created **validation functions** that serve as a
solver-independent specification of the constraints and objectives. These
validation functions essentially describe what a valid solution must look like
and how we measure its quality.

<!-- Motivation for CP-SAT model -->

The next step is to turn this high-level specification into a formal
optimization model using CP-SAT. To do so, we start by defining **decision
variables**, which represent the core choices of our problem. For the nurse
rostering problem, a natural decision variable is:

> **Is nurse $i$ assigned to shift $j$?**

This can be represented by a Boolean variable $x_{i,j}$ that is true if nurse
$i$ works shift $j$, and false otherwise.

<!-- Variable container as a design pattern -->

Instead of managing these variables as a raw two-dimensional array, we structure
them using **variable containers**. For each nurse, we create a container that
holds their assignment variables and provides useful methods for counting
shifts, iterating over assignments, and extracting the solution. This approach
keeps the model modular, makes constraints easier to implement, and supports
reusability when we later add new constraints or objectives.

```python
"""
This module provides a basic container to manage the variables for a single nurse in the nurse rostering problem.
"""

from collections.abc import Iterable
from ortools.sat.python import cp_model
from .data_schema import Nurse, Shift, ShiftUid


class NurseDecisionVars:
    """
    A container to create and manage the decision variables for a single nurse.

    Each nurse has one Boolean variable for each shift, indicating whether the nurse is assigned to that shift.
    This class also provides helper methods to iterate over assignments and extract results.
    """

    def __init__(self, nurse: Nurse, shifts: list[Shift], model: cp_model.CpModel):
        self.nurse = nurse
        self.shifts = shifts
        self.model = model
        # Create one Boolean decision variable per shift for this nurse
        self._x = {
            shift.uid: model.new_bool_var(f"assign_{nurse.uid}_{shift.uid}")
            for shift in shifts
        }

    def fix(self, shift_uid: ShiftUid, value: bool):
        """
        Fix the assignment variable for the given shift UID to a specific value (True or False).
        Useful for setting hard constraints or testing the model.
        """
        if shift_uid not in self._x:
            raise ValueError(
                f"Shift UID {shift_uid} not found in nurse {self.nurse.uid} assignments."
            )
        self.model.add(self._x[shift_uid] == value)

    def is_assigned_to(self, shift_uid: ShiftUid) -> cp_model.BoolVarT:
        """
        Return the decision variable for the given shift UID.
        This variable is True if the nurse is assigned to that shift, and False otherwise.
        """
        return self._x[shift_uid]

    def iter_shifts(self) -> Iterable[tuple[Shift, cp_model.BoolVarT]]:
        """
        Iterate over all (shift, variable) pairs for this nurse.
        """
        for shift in self.shifts:
            yield shift, self.is_assigned_to(shift_uid=shift.uid)

    def extract(self, solver: cp_model.CpSolver) -> list[ShiftUid]:
        """
        Extract a list of shift UIDs that this nurse is assigned to in the solution.
        """
        return [shift_uid for shift_uid in self._x if solver.value(self._x[shift_uid])]
```

<!-- Allows refactoring and performance hacks -->

By encapsulating the decision variables in this manner, the process of
constructing constraints and objectives is simplified. Each constraint module
can focus on a single nurse or a subset of shifts without dealing with the
low-level details of variable creation or indexing. The behavior of the
`NurseDecisionVars` class can later be modified, for example, to avoid creating
variables for shifts irrelevant to a given nurse and instead return a constant
`0` when such shifts are queried. These shifts can also be skipped in
`iter_shifts` to improve loop efficiency. Such refactoring is straightforward
with this container-based design but would be considerably more complex when
using, for instance, a raw two-dimensional array.

## Modules

<!-- Introduce modular design -->

Now that we have defined the decision variables, the next step is to translate
the problem constraints and objectives into an optimization model. For the nurse
rostering problem, we have multiple constraints that are logically independent.
Instead of writing them directly into a monolithic solver script, we will
implement each constraint or objective as a separate **module**.

<!-- Why modularity is valuable -->

This modular approach offers several benefits:

- It keeps the model organized and readable.
- Each module can be tested individually (aligned with our TDD approach).
- Adding, removing, or modifying a constraint or objective later becomes
  trivial—simply add or replace a module.

<!-- Abstract base class introduction -->

To ensure all modules follow the same structure, we define an **abstract base
class** that specifies the interface for implementing constraints and
objectives. This base class defines a single method, `build`, which applies the
module’s constraints and optionally returns a sub-objective expression. These
sub-objectives will later be combined to form the global objective function.

<!-- Linking to decision variables -->

The `build` method takes three arguments:

1. The **instance**, which contains the problem parameters.
2. The **CP-SAT model**, which we modify by adding constraints.
3. A list of **decision variable containers** (one per nurse), which gives easy
   access to all variables related to that nurse.

<!-- Code explanation -->

Here is the abstract base class for all modules:

```python
import abc
from ortools.sat.python import cp_model
from .data_schema import NurseRosteringInstance
from .nurse_vars import NurseDecisionVars


class ShiftAssignmentModule(abc.ABC):
    @abc.abstractmethod
    def build(
        self,
        instance: NurseRosteringInstance,
        model: cp_model.CpModel,
        nurse_shift_vars: list[NurseDecisionVars],
    ) -> cp_model.LinearExprT:
        """
        Apply the constraints and return an optional sub-objective expression.
        Subclasses must implement this method to define their specific constraints and objectives.
        """
        return 0
```

For testing, we will use a few auxiliary helper classes that significantly
reduce boilerplate code when validating CP-SAT models. These helpers provide an
intuitive way to assert whether a model is feasible or infeasible after
constraints have been added.

You can install these helpers via `pip install cpsat-utils`

```python
from cpsat_utils.testing import (
    AssertModelFeasible,
    AssertModelInfeasible,
    assert_objective,
)

with AssertModelFeasible() as model:
    # build a model that is supposed to be feasible
    # if the model is infeasible, the context manager will raise an error

with AssertModelInfeasible() as model:
    # build a model that is supposed to be infeasible
    # if the model is feasible, the context manager will raise an error

# assert that the model is feasible and has the expected objective value
assert_objective(model=model, expected=-1.0)
```

These helpers are particularly useful for **test-driven development (TDD)**
because they keep the tests concise and focused on **what should happen**,
rather than on the mechanics of solving and checking the model. By wrapping the
solver logic inside a context manager, you avoid repetitive setup code and make
tests easier to read and maintain.

We will write tests using [**pytest**](https://docs.pytest.org/en/stable/), a
widely used testing framework for Python. With pytest, you simply write
functions that start with `test_`, and the framework will automatically discover
and execute them. To run all tests, just type `pytest` in your terminal, and it
will find all test files (named either `test_*.py` or `*_test.py`) and run the
contained tests.

Here is a minimal example:

```python
# ./tests/test_example.py

def test_example():
    """
    This is a simple example test that always fails.
    Use it to verify that your testing framework is set up correctly.
    """
    assert False  # Make sure you get an error here to confirm the test framework is working.
```

In order to get some simple test data, we will also write some simple data
generation functions.

1. **create_shifts**: Generates a list of shifts with consecutive start times.
2. **create_nurse**: Creates a nurse with a specified name and blocked shifts.

The code is quite simple and you can find it below:

<details><summary>Click to expand the code for data generation</summary>

```python
# ./tests/generate.py
"""
A simple utility to create shifts and nurses for testing purposes.
"""

from datetime import datetime, timedelta
from nurserostering.data_schema import Shift, Nurse


def create_shifts(k: int, week: int = 0, shift_length: int = 8) -> list[Shift]:
    """
    Create a list of shifts for testing.
    Each shift is named "Shift {i}" and has a start time and end time.
    """
    shifts = []
    for i in range(k):
        start_time = (
            datetime(2025, 1, 1, 0, 0)
            + timedelta(hours=i * shift_length)
            + timedelta(days=week * 7)
        )
        end_time = (
            datetime(2025, 1, 1, 0, 0)
            + timedelta(hours=(i + 1) * shift_length)
            + timedelta(days=week * 7)
        )
        shifts.append(
            Shift(
                name=f"Shift {i + 1}",
                start_time=start_time,
                end_time=end_time,
                demand=2,
            )
        )
    return shifts


def create_nurse(
    nurse_name: str = "Test Nurse",
    preferred_shifts: set[int] | None = None,
    blocked_shifts: set[int] | None = None,
    staff: bool = True,
    min_time_between_shifts: timedelta = timedelta(hours=8),
) -> Nurse:
    """
    Create a nurse with customizable attributes.
    """
    if preferred_shifts is None:
        preferred_shifts = set()
    if blocked_shifts is None:
        blocked_shifts = set()
    return Nurse(
        name=nurse_name,
        preferred_shifts=preferred_shifts,
        blocked_shifts=blocked_shifts,
        staff=staff,
        min_time_between_shifts=min_time_between_shifts,
    )
```

</details>

### No Blocked Shifts

When we begin implementing constraints, it is wise to start with the simplest
rule possible. For our nurse rostering problem, one such rule is that **a nurse
cannot be assigned to a shift if they are explicitly blocked from working that
shift.** This models situations such as vacations, sick leave, or other forms of
unavailability. If this constraint is violated, the schedule is invalid, no
matter how good it is otherwise.

We will now apply a test-driven approach to implement this constraint.

#### Step 1: Writing the First Test (Trivial Feasibility)

Our first test checks the trivial case: a nurse with **no blocked shifts**
should not cause any infeasibility. We do not even need to fix any assignments
in this case. The purpose is to verify that the model remains valid when there
are no constraints to enforce.

```python
def test_no_blocked_shifts_trivial():
    """
    A nurse with no blocked shifts should always lead to a feasible model.
    """
    shifts = create_shifts(2)  # two consecutive shifts
    nurse = create_nurse("Nurse A", blocked_shifts=set())
    instance = NurseRosteringInstance(nurses=[nurse], shifts=shifts)

    with AssertModelFeasible() as model:
        nurse_vars = NurseDecisionVars(nurse, shifts, model)
        NoBlockedShiftsModule().build(instance, model, [nurse_vars])
```

This test will of course fail because we have not yet implemented the
`NoBlockedShiftsModule`. Let us do that next.

```python
class NoBlockedShiftsModule(ShiftAssignmentModule):
    """
    Prohibit assignment to blocked shifts.
    """

    def build(
        self,
        instance: NurseRosteringInstance,
        model: cp_model.CpModel,
        nurse_shift_vars: list[NurseDecisionVars],
    ) -> cp_model.LinearExprT:
        # TODO
        return 0
```

Now it should pass, as we actually do not enforce any constraints yet. Let us
create a second test that will check that we cannot assign a nurse to a shift
they are blocked from.

#### Step 2: Testing Infeasibility for Blocked Shifts

If a nurse is **blocked from working a shift** but we force them to be assigned
to it, the model should become infeasible. This confirms that our constraint
actually prevents invalid assignments.

```python
def test_no_blocked_shifts_infeasible():
    """
    The model should be infeasible if we assign a nurse to a blocked shift.
    """
    shifts = create_shifts(2)
    nurse = create_nurse("Nurse A", blocked_shifts={shifts[0].uid})
    instance = NurseRosteringInstance(nurses=[nurse], shifts=shifts)

    with AssertModelInfeasible() as model:
        nurse_vars = NurseDecisionVars(nurse, shifts, model)
        NoBlockedShiftsModule().build(instance, model, [nurse_vars])
        nurse_vars.fix(shifts[0].uid, True)  # Force assignment to a blocked shift
```

This test should now fail, as we have not yet implemented the logic to enforce
the blocked shifts constraint. Let us implement the logic in the
`NoBlockedShiftsModule`.

```python
class NoBlockedShiftsModule(ShiftAssignmentModule):
    """
    Prohibit assignment to blocked shifts.
    """

    def enforce_for_nurse(self, model: cp_model.CpModel, nurse_x: NurseDecisionVars):
        for shift_uid in nurse_x.nurse.blocked_shifts:
            # Prohibit assignment to blocked shifts
            model.add(nurse_x.is_assigned_to(shift_uid=shift_uid) == 0)

    def build(
        self,
        instance: NurseRosteringInstance,
        model: cp_model.CpModel,
        nurse_shift_vars: list[NurseDecisionVars],
    ) -> cp_model.LinearExprT:
        for nurse_x in nurse_shift_vars:
            self.enforce_for_nurse(model, nurse_x)
        return 0  # no objective contribution
```

#### Step 3: Testing Feasibility on Non-Blocked Shifts

Finally, we check that a nurse can still work on **other, non-blocked shifts**.
Here we assign the nurse to a shift that is allowed, and we expect the model to
remain feasible.

```python
def test_no_blocked_shifts_feasible():
    """
    A nurse assigned to a non-blocked shift should remain feasible.
    """
    shifts = create_shifts(2)
    nurse = create_nurse("Nurse A", blocked_shifts={shifts[0].uid})
    instance = NurseRosteringInstance(nurses=[nurse], shifts=shifts)

    with AssertModelFeasible() as model:
        nurse_vars = NurseDecisionVars(nurse, shifts, model)
        NoBlockedShiftsModule().build(instance, model, [nurse_vars])
        nurse_vars.fix(shifts[1].uid, True)  # Assign allowed shift
```

Our `NoBlockedShiftsModule` should cover that case as well. In the following
modules, we will not perform the TDD cycle in detail, but we will still describe
the key tests and the implementation of each module. This will keep the focus on
the constraints and objectives rather than the testing mechanics.

> [!TIP]
>
> How do you find good test cases? A good rule of thumb is to start with simple
> cases that cover the basic functionality. Then add edge cases from both sides:
> create one case that is right on the edge of feasibility, and another that is
> just outside it. Any scenario that could be off by one is an excellent
> candidate for an edge case.

### Minimum Off Time

The **minimum off time constraint** enforces that a nurse cannot work two shifts
that are too close together. Formally, for each nurse and for every pair of
shifts, if the time between the end of one shift and the start of the next is
less than the required rest period, both cannot be assigned to the nurse.

#### Key Tests

To verify this constraint, we first test with simple assignment patterns:

- `[None, True, True, None]`: infeasible (two consecutive shifts without rest).
- `[True, False, True]`: feasible if the gap is long enough.
- `[True, True]`: infeasible if two consecutive shifts overlap or violate the
  minimum rest.

Using a helper function, we can easily run these tests with different
parameters:

```python
def run_min_rest_test(
    assignments: list[bool|None],
    expected_feasible: bool,
    shift_length: int = 8,
    min_time_in_between: timedelta = timedelta(hours=16),
):
    shifts = create_shifts(len(assignments), shift_length=shift_length)
    nurse = create_nurse("Nurse A", min_time_between_shifts=min_time_in_between)
    instance = NurseRosteringInstance(nurses=[nurse], shifts=shifts)

    context = AssertModelFeasible() if expected_feasible else AssertModelInfeasible()
    with context as model:
        nurse_vars = NurseDecisionVars(nurse, shifts, model)
        MinTimeBetweenShifts().build(instance, model, [nurse_vars])
        for s, assign in zip(shifts, assignments):
            if assign is None:
                continue  # skip free assignments
            nurse_vars.fix(s.uid, assign)
```

The individual tests can then be defined as follows:

```python
def test_min_time_between_shifts_infeasible_pattern():
    run_min_rest_test(
        assignments=[None, True, True, None],
        expected_feasible=False,
        shift_length=8,
        min_time_in_between=timedelta(hours=8),
    )
```

```python
def test_min_time_between_shifts_feasible_pattern():
    run_min_rest_test(
        assignments=[True, False, True],
        expected_feasible=True,
        shift_length=8,
        min_time_in_between=timedelta(hours=8),
    )
```

Additional test cases (e.g., single-shift, all-false, and variable-length gaps)
are available in the full test file but omitted here for clarity.

> [!WARNING]
>
> For testing feasibility, you should fix as many assignments as possible, as
> each fixed assignment makes it harder for the solver to maneuver around the
> constraints. For testing infeasibility, you should fix as few assignments as
> necessary, allowing the solver enough freedom to explore potential ways of
> circumventing the constraints.

#### Implementation

For the implementation, we find for each shift of a nurse all subsequent shifts
that would violate the minimum rest time if both were assigned. If the first
shift is assigned, then none of these subsequent shifts can be assigned. Here we
can optimize the model building by leveraging the fact that the shifts are
sorted by start time.

A simpler, but less efficient, implementation would check all pairs of shifts
for each nurse, and enforce that only one of them can be assigned.

```python
class MinTimeBetweenShifts(ShiftAssignmentModule):
    def enforce_for_nurse(self, model: cp_model.CpModel, nurse_x: NurseDecisionVars):
        min_time_between_shifts = nurse_x.nurse.min_time_between_shifts
        for i in range(len(nurse_x.shifts) - 1):
            shift_i = nurse_x.shifts[i]
            colliding: list[Shift] = []  # shifts that are too close to shift_i
            for j in range(i + 1, len(nurse_x.shifts)):
                shift_j = nurse_x.shifts[j]
                if shift_i.end_time + min_time_between_shifts <= shift_j.start_time:
                    # Since shifts are sorted by start time, if the current shift_j starts
                    # after the required rest period, all subsequent shifts will also be valid.
                    # Therefore, we can safely break here to avoid unnecessary checks.
                    break
                colliding.append(shift_j)
            if colliding:
                # if there are shifts that are too close to shift_i,
                # prevent their assignment if shift_i is assigned
                shift_i_selected = nurse_x.is_assigned_to(shift_i.uid)
                no_colliding_selected = (
                    sum(nurse_x.is_assigned_to(s.uid) for s in colliding) == 0
                )
                model.add(no_colliding_selected).only_enforce_if(shift_i_selected)

    def build(self, instance, model, nurse_shift_vars):
        """
        Enforce minimum rest time between any two shifts for a nurse.
        """
        for nv in nurse_shift_vars:
            self.enforce_for_nurse(model, nv)
        return 0  # no objective contribution
```

### Demand Satisfaction

In the real world, every shift requires a minimum number of nurses to ensure
safe and efficient operations. This requirement is captured as the **demand** of
the shift. The demand satisfaction constraint enforces that each shift is
assigned at least as many nurses as its demand specifies.

To verify this behavior, we use simple tests. In the first test, we create one
shift with a demand of 2 and two available nurses, which is feasible. In the
second test, we block the assignment of one of the nurses, which violates the
demand requirement and should make the model infeasible.

```python
from nurserostering.modules import DemandSatisfactionModule
from nurserostering.nurse_vars import NurseDecisionVars
from cpsat_utils.testing import AssertModelFeasible, AssertModelInfeasible
from generate import create_shifts, create_nurse
from nurserostering.data_schema import NurseRosteringInstance

def test_demand_satisfaction_met():
    shifts = create_shifts(1)
    shifts[0].demand = 2
    nurse1 = create_nurse("N1")
    nurse2 = create_nurse("N2")
    instance = NurseRosteringInstance(nurses=[nurse1, nurse2], shifts=shifts)

    with AssertModelFeasible() as model:
        nurse_vars1 = NurseDecisionVars(nurse1, shifts, model)
        nurse_vars2 = NurseDecisionVars(nurse2, shifts, model)
        DemandSatisfactionModule().build(instance, model, [nurse_vars1, nurse_vars2])


def test_demand_satisfaction_understaffed():
    shifts = create_shifts(1)
    shifts[0].demand = 2
    nurse1 = create_nurse("N1")
    nurse2 = create_nurse("N2")
    instance = NurseRosteringInstance(nurses=[nurse1, nurse2], shifts=shifts)

    with AssertModelInfeasible() as model:
        nurse_vars1 = NurseDecisionVars(nurse1, shifts, model)
        nurse_vars2 = NurseDecisionVars(nurse2, shifts, model)
        DemandSatisfactionModule().build(instance, model, [nurse_vars1, nurse_vars2])
        nurse_vars2.fix(shifts[0].uid, False)
```

The corresponding implementation of the constraint is equally straightforward:
we simply add a constraint that the total number of assigned nurses for a shift
must be at least the shift’s demand.

```python
class DemandSatisfactionModule(ShiftAssignmentModule):
    """
    Ensure each shift meets its demand.
    """
    def build(
        self,
        instance: NurseRosteringInstance,
        model: cp_model.CpModel,
        nurse_shift_vars: list[NurseDecisionVars],
    ) -> cp_model.LinearExprT:
        for shift in instance.shifts:
            assigned_nurses = [
                nurse.is_assigned_to(shift_uid=shift.uid)
                for nurse in nurse_shift_vars
                if shift.uid in nurse._x
            ]
            model.add(sum(assigned_nurses) >= shift.demand)
        return 0
```

### Prefer Staff

While the previous modules defined hard constraints that must be satisfied, this
module introduces a **soft constraint**. We prefer to assign internal staff
nurses over contractors, as contractors may be more expensive or less desirable
for other reasons. Instead of enforcing this rule strictly, we **penalize** the
use of contractors in the objective function. This way, the solver will try to
minimize the number of contractor assignments while still satisfying all hard
constraints.

**Example Test:**

```python
from nurserostering.modules import PreferStaffModule, DemandSatisfactionModule
from cpsat_utils.testing import assert_objective
from generate import create_shifts, create_nurse

from nurserostering.nurse_vars import NurseDecisionVars
from nurserostering.data_schema import NurseRosteringInstance
from ortools.sat.python import cp_model


def test_prefer_staff_module():
    """
    Prefer assigning the staff nurse (objective = 0).
    """
    shifts = create_shifts(1)
    shifts[0].demand = 1

    staff = create_nurse("Staff", staff=True)
    contractor = create_nurse("Contractor", staff=False)
    instance = NurseRosteringInstance(nurses=[staff, contractor], shifts=shifts)

    model = cp_model.CpModel()
    vars_staff = NurseDecisionVars(staff, shifts, model)
    vars_contractor = NurseDecisionVars(contractor, shifts, model)
    solver = cp_model.CpSolver()
    staff_mod = PreferStaffModule()

    DemandSatisfactionModule().build(instance, model, [vars_staff, vars_contractor])
    model.minimize(staff_mod.build(instance, model, [vars_staff, vars_contractor]))

    assert_objective(model=model, solver=solver, expected=0.0)
    assert solver.value(vars_staff.is_assigned_to(shifts[0].uid)) == 1
    assert solver.value(vars_contractor.is_assigned_to(shifts[0].uid)) == 0
```

**Implementation:**

```python
class PreferStaffModule(ShiftAssignmentModule):
    def build(
        self,
        instance: NurseRosteringInstance,
        model: cp_model.CpModel,
        nurse_shift_vars: list[NurseDecisionVars],
    ) -> cp_model.LinearExprT:
        """
        Penalize use of non-staff (contract) nurses in the objective.
        """
        expr = 0
        for nv in nurse_shift_vars:
            if not nv.nurse.staff:
                for uid in nv._x:
                    expr += instance.staff_weight * nv.is_assigned_to(uid)
        return expr
```

### Preferences Objective

While many of the previous modules focused on enforcing constraints,
`MaximizePreferences` is different: it defines what we actually want to
optimize. Nurses often have preferences for specific shifts—perhaps due to
personal schedules, skill matching, or desired working hours. A good schedule
should take these preferences into account as much as possible.

The `MaximizePreferences` module encodes this by assigning a **negative
contribution** (a reward) to the objective function whenever a nurse is assigned
to one of their preferred shifts. As our interface will minimize by default, we
negate the weight so that preferred assignments reduce the total objective
value. Note that we could have easily specified that the expression returned by
`build` should be maximized.

This module is therefore not a soft constraint but a **true objective**: among
all feasible schedules, it guides the solver to find one that maximizes nurse
satisfaction.

**Example Test:**

```python
from nurserostering.modules import MaximizePreferences, DemandSatisfactionModule
from cpsat_utils.testing import assert_objective
from generate import create_shifts, create_nurse

from nurserostering.nurse_vars import NurseDecisionVars
from nurserostering.data_schema import NurseRosteringInstance

from ortools.sat.python import cp_model


def test_maximize_preferences_module():
    """
    Prefer assigning the nurse to their preferred shift (objective = -1).
    """
    shifts = create_shifts(1)
    shifts[0].demand = 1

    nurse = create_nurse("Preferred Nurse", preferred_shifts={shifts[0].uid})
    instance = NurseRosteringInstance(nurses=[nurse], shifts=shifts)

    model = cp_model.CpModel()
    nurse_vars = NurseDecisionVars(nurse, shifts, model)
    solver = cp_model.CpSolver()
    pref_mod = MaximizePreferences()

    DemandSatisfactionModule().build(instance, model, [nurse_vars])
    model.minimize(pref_mod.build(instance, model, [nurse_vars]))

    assert_objective(model=model, solver=solver, expected=-1.0)
    assert (
        solver.value(nurse_vars.is_assigned_to(shifts[0].uid)) == 1
    ), "Nurse should be assigned to their preferred shift"
```

**Implementation:**

```python
class MaximizePreferences(ShiftAssignmentModule):
    def build(
        self,
        instance: NurseRosteringInstance,
        model: cp_model.CpModel,
        nurse_shift_vars: list[NurseDecisionVars],
    ) -> cp_model.LinearExprT:
        """
        Reward assignments that match nurse preferences by reducing the objective value.
        """
        expr = 0
        for nv in nurse_shift_vars:
            for uid in nv.nurse.preferred_shifts:
                expr += -nv.nurse.preferred_shift_weight * nv.is_assigned_to(uid)
        return expr
```

## Full Solver

<!-- Introduces the solver class as the orchestration of all modules -->

At this point, we have implemented all the necessary modules: the constraints,
soft constraints, and objectives. The next step is to combine these components
into a complete optimization model. The `NurseRosteringModel` class is
responsible for orchestrating all modules, building the CP-SAT model, and
extracting the solution.

```python
from ortools.sat.python import cp_model
from .nurse_vars import NurseDecisionVars
from .data_schema import NurseRosteringInstance, NurseRosteringSolution
from .modules import (
    ShiftAssignmentModule,
    NoBlockedShiftsModule,
    DemandSatisfactionModule,
    MinTimeBetweenShifts,
    MaximizePreferences,
    PreferStaffModule,
)


class NurseRosteringModel:
    """
    A compact and extensible solver for the nurse rostering problem using CP-SAT.
    """

    def __init__(
        self, instance: NurseRosteringInstance, model: cp_model.CpModel | None = None
    ):
        self.instance = instance
        self.model = model or cp_model.CpModel()
        self.nurse_vars = [
            NurseDecisionVars(nurse, instance.shifts, self.model)
            for nurse in instance.nurses
        ]

        self.modules: list[ShiftAssignmentModule] = [
            NoBlockedShiftsModule(),
            DemandSatisfactionModule(),
            MinTimeBetweenShifts(),
            MaximizePreferences(),
            PreferStaffModule(),
        ]

        objective = sum(
            module.build(instance, self.model, self.nurse_vars)  # type: ignore
            for module in self.modules
        )
        self.model.minimize(objective)

    def solve(
        self,
        log_search_progress: bool = True,
        max_time_in_seconds: float = 60.0,
        **solver_params,
    ) -> NurseRosteringSolution:
        solver = cp_model.CpSolver()
        solver.parameters.log_search_progress = log_search_progress
        solver.parameters.max_time_in_seconds = max_time_in_seconds
        for key, value in solver_params.items():
            setattr(solver.parameters, key, value)

        status = solver.solve(self.model)
        if status == cp_model.INFEASIBLE:
            raise ValueError("The model is infeasible.")
        elif status not in (cp_model.OPTIMAL, cp_model.FEASIBLE):
            raise ValueError("Solver failed to find a feasible solution.")

        nurses_at_shifts = {}
        for nurse_model in self.nurse_vars:
            for shift_uid in nurse_model.extract(solver):
                nurses_at_shifts.setdefault(shift_uid, []).append(nurse_model.nurse.uid)

        return NurseRosteringSolution(
            nurses_at_shifts=nurses_at_shifts,
            objective_value=round(solver.objective_value),
        )
```

<!-- Introduces the example test instance -->

To demonstrate the full workflow, we can test the solver with a small but
non-trivial instance. The following test sets up 7 days with 3 shifts per day
(morning, day, and night), resulting in 21 shifts. The nurses have a mix of
preferences, blocked shifts, and max shift limits, creating an interesting
scheduling challenge.

```python
def test_fixed_instance():
    base_date = datetime(2025, 1, 1)
    shift_length = 8
    shifts = []

    # 7 days, 3 shifts/day = 21 shifts
    for day in range(7):
        for idx, hour in enumerate([0, 8, 16]):  # Morning, Day, Night
            start = base_date + timedelta(days=day, hours=hour)
            end = start + timedelta(hours=shift_length)
            shifts.append(
                Shift(
                    name=f"Day {day+1} Shift {idx+1}",
                    start_time=start,
                    end_time=end,
                    demand=2 if hour == 8 else 1,  # Higher demand for day shifts
                )
            )

    # Total demand: 7*2 (day) + 7*1 (morning) + 7*1 (night) = 28 + 7 + 7 = 42 shifts needed

    nurses = [
        Nurse(
            name="Alice (prefers mornings, no Sundays)",
            preferred_shifts={s.uid for s in shifts if s.start_time.hour == 0},
            blocked_shifts={s.uid for s in shifts if s.start_time.weekday() == 6},
            staff=True,
            min_time_between_shifts=timedelta(hours=10),
            preferred_shift_weight=3,
        ),
        Nurse(
            name="Bob (prefers nights)",
            preferred_shifts={s.uid for s in shifts if s.start_time.hour == 16},
            blocked_shifts=set(),
            staff=True,
            min_time_between_shifts=timedelta(hours=10),
            preferred_shift_weight=3,
        ),
        Nurse(
            name="Clara (prefers weekends, blocks weekdays)",
            preferred_shifts={
                s.uid for s in shifts if s.start_time.weekday() in {5, 6}
            },
            blocked_shifts={s.uid for s in shifts if s.start_time.weekday() < 5},
            staff=True,
            min_time_between_shifts=timedelta(hours=10),
            preferred_shift_weight=2,
        ),
        Nurse(
            name="Dan (no preferences)",
            preferred_shifts=set(),
            blocked_shifts=set(),
            staff=True,
            min_time_between_shifts=timedelta(hours=8),
            preferred_shift_weight=1,
        ),
        Nurse(
            name="Eve (contractor, prefers day shifts)",
            preferred_shifts={s.uid for s in shifts if s.start_time.hour == 8},
            blocked_shifts=set(),
            staff=False,
            min_time_between_shifts=timedelta(hours=10),
            preferred_shift_weight=2,
        ),
        Nurse(
            name="Frank (prefers day shifts)",
            preferred_shifts={s.uid for s in shifts if s.start_time.hour == 8},
            blocked_shifts=set(),
            staff=True,
            min_time_between_shifts=timedelta(hours=10),
            preferred_shift_weight=2,
        ),
        Nurse(
            name="Grace (prefers mornings)",
            preferred_shifts={s.uid for s in shifts if s.start_time.hour == 0},
            blocked_shifts=set(),
            staff=True,
            min_time_between_shifts=timedelta(hours=10),
            preferred_shift_weight=3,
        ),
        Nurse(
            name="Heidi (contractor, no preferences)",
            preferred_shifts=set(),
            blocked_shifts=set(),
            staff=False,
            min_time_between_shifts=timedelta(hours=8),
            preferred_shift_weight=1,
        ),
    ]

    instance = NurseRosteringInstance(
        nurses=nurses, shifts=sorted(shifts, key=lambda s: s.start_time), staff_weight=2
    )

    model = NurseRosteringModel(instance)
    solution = model.solve()
    assert solution is not None, "The solution should not be None"
    assert_solution_is_feasible(instance, solution)
```

#### Nurses

| Name & Description                            | Staff/Contractor | Min Rest | Preferences         | Blocked Shifts |
| --------------------------------------------- | ---------------- | -------- | ------------------- | -------------- |
| **Alice** (prefers mornings, no Sundays)      | Staff            | ≥ 10h    | 7 shifts (weight 3) | 3 shifts       |
| **Bob** (prefers nights)                      | Staff            | ≥ 10h    | 7 shifts (weight 3) | —              |
| **Clara** (prefers weekends, blocks weekdays) | Staff            | ≥ 10h    | 6 shifts (weight 2) | 15 shifts      |
| **Dan** (no preferences)                      | Staff            | ≥ 8h     | —                   | —              |
| **Eve** (contractor, prefers day shifts)      | Contractor       | ≥ 10h    | 7 shifts (weight 2) | —              |
| **Frank** (prefers day shifts)                | Staff            | ≥ 10h    | 7 shifts (weight 2) | —              |
| **Grace** (prefers mornings)                  | Staff            | ≥ 10h    | 7 shifts (weight 3) | —              |
| **Heidi** (contractor, no preferences)        | Contractor       | ≥ 8h     | —                   | —              |

#### Shift Coverage

| Day | Morning (S1)        | Day (S2)   | Night (S3) |
| --- | ------------------- | ---------- | ---------- |
| D1  | Alice, Grace        | Dan, Frank | Bob        |
| D2  | Alice, Grace        | Dan, Frank | Bob        |
| D3  | Alice, Grace        | Eve, Frank | Bob        |
| D4  | Alice, Clara, Grace | Dan, Frank | Bob        |
| D5  | Clara, Grace        | Eve, Frank | Bob        |
| D6  | Alice, Grace        | Eve, Frank | Bob        |
| D7  | Alice, Grace        | Dan, Frank | Bob        |

## Automatic Test Extraction from Production

Because we use pydantic for input and output, serializing test cases from
production is straightforward. You can save instances and solutions to JSON and
re-load them later for regression tests.

```python
# export instance and solution to JSON
with open("instance.json", "w") as f:
    f.write(instance.model_dump_json())
with open("solution.json", "w") as f:
    f.write(solution.model_dump_json())
```

You can then load these files in your tests:

```python
from nurserostering.data_schema import NurseRosteringInstance, NurseRosteringSolution

def test_load_instance_and_solution():
    with open("instance.json", "r") as f:
        instance = NurseRosteringInstance.model_validate_json(f.read())
    with open("solution.json", "r") as f:
        solution = NurseRosteringSolution.model_validate_json(f.read())

    assert instance is not None, "Instance should not be None"
    assert solution is not None, "Solution should not be None"
    # should still be feasible
    assert_solution_is_feasible(instance, solution)

    # reoptimize the solution
    model = NurseRosteringModel(instance)
    new_solution = model.solve(max_time_in_seconds=10.0)
    assert new_solution is not None, "New solution should not be None"
    assert_solution_is_feasible(instance, new_solution)
    assert new_solution.objective_value == solution.objective_value, "Objective value should match"
```

Actually, you can also just dump them into a folder and then make the test
iterate over all the files in that folder. Instead of just writing the objective
value into the solution, you could also add the time it took to solve the
instance, which can be useful for performance testing. With a bunch of such
files collected, you could then start to refactor and optimize your code, with a
minimum of regression risk in correctness or performance. However, keep in mind
that the performance of CP-SAT (and other such solvers) can vary between runs,
so do not be too strict with the performance tests.

Instead of relying solely on historical data for testing, you can **shadow**
your production model with a development or experimental model. This approach
allows you not only to verify correctness but also to directly compare the
performance of both models, providing strong confidence that your modifications
enhance the model without disrupting production. If you already have a
monitoring tool in place, integrating _shadow solutions_ is likely
straightforward. This technique is so popular that
[nextmv](https://www.nextmv.io/docs/using-nextmv/experiments/shadow) offers
built-in support for it.

## Property-based Testing

As a final point, I briefly discuss property-based testing. Richard Oberdieck, a
senior optimizer with expertise in testing, favors this approach and considers
unit-based testing less suitable for his purposes. He argues that optimization
models are difficult to decompose and that testing individual equations has
limited value.

The problem in this chapter has been deliberately simplified. In typical
projects, my unit tests target constraints or modules that consist of sets of
lower-level constraints and equations. Many of the tests presented here are
indeed excessive for the simplified setting.

These observations underscore that no single workflow fits all applications; you
should not force my personal style onto your needs. I also vary my approach
substantially depending on the problem and context. Property-based testing may
be a strong fit for your needs; therefore, I now briefly outline its core ideas.

Property-based testing is a methodology in which you specify general properties
that your code must satisfy and then rely on a tool to automatically generate a
wide range of test cases to verify these properties. This approach is
particularly valuable for optimization problems, where the solution space is
large and complex. Conceptually, it resembles automated sampling of possible
inputs and checking whether the corresponding outputs fulfill the required
criteria.

Unlike naive random testing, libraries such as Hypothesis use _strategies_ to
systematically generate inputs and, if a failure occurs, they attempt to
**shrink** the failing case to a minimal counterexample. Hypothesis also stores
examples so that failures can be reproduced deterministically.

If, like me, you were initially taught that tests should be deterministic, this
may appear unsettling. However, in practice you only need to encounter a bug
once; afterward, you can add a deterministic regression test to ensure it does
not reoccur. When you are uncertain which edge cases to test, property-based
testing provides an effective way to uncover them.

One widely used Python library for property-based testing is
[Hypothesis](https://hypothesis.readthedocs.io/en/latest/). It enables you to
define strategies for generating test data and then automatically executes your
tests with a diverse set of inputs.

> [!TIP] A clear and engaging introduction to property-based testing with
> Hypothesis is provided in this
> [21-minute YouTube video](https://www.youtube.com/watch?v=mkgd9iOiICc) by
> ArjanCode.

With property-based testing, the guiding questions typically take the following
form:

- _For any valid instance of my optimization problem, does the solver return a
  feasible solution (or report infeasibility correctly)?_
- _For any valid instance of the nurse rostering problem, is there always
  sufficient staffing to cover every shift?_

The phrase “for any valid instance” is central: you must specify to Hypothesis
how to generate inputs that satisfy schema invariants. Hypothesis then attempts
to falsify your assumption by searching for counterexamples, often targeting
edge cases. This approach **complements unit tests**: you still want a small set
of clear, deterministic unit tests for well-understood components, while using
property-based tests to explore a much wider space of inputs without bloating
the test suite.

Let us begin with a simple example of a property-based test to illustrate the
basic concept. In this case, we test the built-in `sorted` function and verify
three properties:

```python
from collections import Counter
from hypothesis import given, strategies as st

@given(st.lists(st.integers()))
def test_sort_properties(xs):
    sorted_xs = sorted(xs)

    # Property 1: Sorting does not change the length
    assert len(sorted_xs) == len(xs)

    # Property 2: Sorted list is monotonically non-decreasing
    for a, b in zip(sorted_xs, sorted_xs[1:]):
        assert a <= b

    # Property 3: Sorting does not lose or duplicate elements
    assert Counter(sorted_xs) == Counter(xs)
```

In this example, we verify that _for any list of integers_, applying `sorted`
preserves the list length, produces a sequence in non-decreasing order, and
returns a permutation of the input. Hypothesis automatically generates a wide
variety of integer lists, runs the test against them, and shrinks any failures
to the smallest counterexample.

<details>
<summary>Here would be the inputs that hypothesis tested automatically:</summary>

- `[]`
- `[0]`
- `[26242, -1963]`
- `[-121]`
- `[8436]`
- `[15719]`
- `[-19093982987237563430026067407172463954]`
- `[-3922]`
- `[-3922, 1364]`
- `[-923437505601415702]`
- `[-923437505601415702, 1030000614]`
- `[-923437505601415702, -923437505601415702]`
- `[-28265]`
- `[-30093, -2983, -30440]`
- `[-30093, -30440, -30440]`
- `[-30093]`
- `[-40, 111940892136851798167905802830994768244, -28043, 7, 20215, 1370480367, 7446, -39]`
- `[-40, 111940892136851798167905802830994768244, -28043, 7, 20215, 1370480367, 20215, -39]`
- `[-40, 111940892136851798167905802830994768244, 111940892136851798167905802830994768244, 7, 20215, 1370480367, 20215, -39]`
- `[-40, 111940892136851798167905802830994768244, 111940892136851798167905802830994768244, 7, -39, 1370480367, 20215, -39]`
- `[-40, 111940892136851798167905802830994768244, 111940892136851798167905802830994768244, 7, 111940892136851798167905802830994768244, 1370480367, 20215, -39]`
- `[1370480367, 111940892136851798167905802830994768244, 111940892136851798167905802830994768244, 7, 111940892136851798167905802830994768244, 1370480367, 20215, -39]`
- `[1370480367, 1370480367, 111940892136851798167905802830994768244, 7, 111940892136851798167905802830994768244, 1370480367, 20215, -39]`
- `[8328, 6129]`
- `[8328]`
- `[-114, 12990, -114, 27, -16229, -19256, 928]`
- `[-114, 12990, -114, 27, -16229, -16229, 928]`
- `[-114, 12990, -114, 27, -16229, -114, 928]`
- `[-114, 12990, -114, -114, -16229, -114, 928]`
- `[-114, 12990, -114, -114, -16229, 928, 928]`
- `[-114, 12990, -114, -114, -16229, 928, -114]`
- `[-114, 12990, -114, -114, 928, 928, 928]`
- `[-7, -79, -1133414645]`
- `[-79, -79, -1133414645]`
- `[-79, -79, -79]`
- `[-1482, -30293, -23505, -7340]`
- `[-22323, 93]`
- `[-22323, -22323]`
- `[2353, 13157]`
- `[2353, 2353]`
- `[2353]`
- `[7714]`
- `[13297, -12682, -26, 2588, -5696, 18, 10030, 22]`
- `[13297, -12682, -26, 2588, -5696, 18, 22, 22]`
- `[13297, -12682, -26, 2588, -5696, 18]`
- `[13297, 2588, -26, 2588, -5696, 18]`
- `[13297, 2588, -26]`
- `[23480, -82, 46, 26111, 32207, -3830610785522322019, 63408623014671325114394083743435908480, 61, -20775, -1100012486, 0, -5724957629946085877, -1248, 64, 21, 13771, 721, 4, 81, -11615, -75, -31640, -15547, -5831, 2113]`
- `[23480, -82, 46, 26111, 32207, -3830610785522322019, 63408623014671325114394083743435908480, 61, -20775, -1100012486, 0, -5724957629946085877, -1248, 64, 21, 2113, 721, 4, 81, -11615, -75, -31640, -15547, -5831, 2113]`
- `[23480, -82, 46, 26111, 32207, -3830610785522322019, 63408623014671325114394083743435908480, 61, -20775, -1100012486, 0, -5724957629946085877, -1248, 64, 21]`
- `[23480, -82, 46, 26111, 32207, -3830610785522322019, 63408623014671325114394083743435908480, 61, -20775, -1100012486, 0, -5724957629946085877, -1248, 21, 21]`
- `[23480, -82, -1248, 26111, 32207, -3830610785522322019, 63408623014671325114394083743435908480, 61, -20775, -1100012486, 0, -5724957629946085877, -1248, 21, 21]`
- `[23480, -82, -1248, 26111, 32207, -3830610785522322019, 63408623014671325114394083743435908480, 61, -20775, -1100012486, 0, -5724957629946085877, -1248, 61, 21]`
- `[23480, -82, -1248, 26111, 63408623014671325114394083743435908480, -3830610785522322019, 63408623014671325114394083743435908480, 61, -20775, -1100012486, 0, -5724957629946085877, -1248, 61, 21]`
- `[-78711666441691544779522005139678058413, 9413, -28, -25429, 1138913225, 119, 15206, -14631, 13620, 22066, 73, -930]`
- `[-78711666441691544779522005139678058413, 22066, -28, -25429, 1138913225, 119, 15206, -14631, 13620, 22066, 73, -930]`
- `[-78711666441691544779522005139678058413, 22066, -28, 119, 1138913225, 119, 15206, -14631, 13620, 22066, 73, -930]`
- `[-78711666441691544779522005139678058413, 15206, -28, 119, 1138913225, 119, 15206, -14631, 13620, 22066, 73, -930]`
- `[119, 15206, -28, 119, 1138913225, 119, 15206, -14631, 13620, 22066, 73, -930]`
- `[119, 15206, -28, 73, 1138913225, 119, 15206, -14631, 13620, 22066, 73, -930]`
- `[119, 15206, -28, 73, 1138913225, 73, 15206, -14631, 13620, 22066, 73, -930]`
- `[-10367, -28534]`
- `[-10367, -10367]`
- `[-15, -97, 20993, 86, -3483807830384175452, 17981, 5590988155335024430, 21910677380750136143640822796681648827, -11734, 10, -23457]`
- `[-15, -97, 20993, 86, -3483807830384175452, 17981, 5590988155335024430, -11734, -11734, 10, -23457]`
- `[-15, -97, 20993, 86, -3483807830384175452, 17981, 5590988155335024430, -23457, -11734, 10, -23457]`
- `[-15, 10, 20993, 86, -3483807830384175452, 17981, 5590988155335024430, -23457, -11734, 10, -23457]`
- `[-15, 10, 20993, 86, -3483807830384175452, 17981, 5590988155335024430, -11734, -11734, 10, -23457]`
- `[-15, 10, 20993, 86, -3483807830384175452, 17981, 5590988155335024430, -11734, 17981, 10, -23457]`
- `[29141, -30, -5793, 102, -16130, -5, -9949, 676613804, -61, 12368]`
- `[29141, -30, -5793, 102, 676613804, -5, -9949, 676613804, -61, 12368]`
- `[-61, -30, -5793, 102, 676613804, -5, -9949, 676613804, -61, 12368]`
- `[-61, -9949, -5793, 102, 676613804, -5, -9949, 676613804, -61, 12368]`
- `[-61, -9949, 12368, 102, 676613804, -5, -9949, 676613804, -61, 12368]`
- `[-61, -9949, 12368, 102, 676613804, -5, -61, 676613804, -61, 12368]`
- `[105, -124, 29994, 4704, 23985, 5651302969633935431, -21152, 476047859, 23285, 7392, 12]`
- `[23285, -124, 29994, 4704, 23985, 5651302969633935431, -21152, 476047859, 23285, 7392, 12]`
- `[23285, -124, 29994, 4704, 5651302969633935431, 5651302969633935431, -21152, 476047859, 23285, 7392, 12]`
- `[23285, -124, 29994, 23285, 5651302969633935431, 5651302969633935431, -21152, 476047859, 23285, 7392, 12]`
- `[23285, -124, 29994, 23285, 7392, 5651302969633935431, -21152, 476047859, 23285, 7392, 12]`
- `[23285, -124, 29994, 7392, 7392, 5651302969633935431, -21152, 476047859, 23285, 7392, 12]`
- `[2105491908, 8597804526551328604, 7275042865703570734]`
- `[2105491908, 2105491908, 7275042865703570734]`
- `[2105491908, 7275042865703570734, 7275042865703570734]`
- `[7275042865703570734, 2105491908, 7275042865703570734]`
- `[2105491908, 2105491908, 2105491908]`
- `[29243, -1704064901, 29484]`
- `[29243, 29484, 29484]`
- `[29484, 29484, 29484]`
- `[-19703, -88, -6578, 121]`
- `[1070832594, 17504]`
- `[1070832594, 1070832594]`
- `[-69]`
- `[15301, 479652285201667946]`
- `[479652285201667946, 479652285201667946]`
- `[479652285201667946]`
- `[516195269, 10059, -61, -106, 6213, -83, -15699]`
- `[6213, 10059, -61, -106, 6213, -83, -15699]`
- `[6213, 10059, -61, -106, 6213, -83, -83]`
- `[6213, 10059, -61, -106, -83, -83, -83]`
</details>

We now apply property-based testing to the nurse rostering problem. The central
challenge is to define a strategy that generates valid instances of the problem.
In particular, the generated instances must satisfy the data schema: unique
UIDs; valid time intervals for shifts; and consistent references between nurses,
shifts, and assignments. Because constructing instances that are always feasible
is difficult, we instead check the following property: within a fixed time
limit, the solver either returns a feasible solution that passes an independent
validator or reports the instance as infeasible or unknown. This choice may miss
false infeasibilities but suffices for this illustrative example.

```python
from datetime import datetime, timedelta
from hypothesis import given, strategies as st
from hypothesis.strategies import composite
from nurserostering.data_schema import NurseRosteringInstance, Shift, Nurse
from nurserostering.solver import NurseRosteringModel
from nurserostering.validation import assert_solution_is_feasible


# --- Helper strategies ---

# A datetime in Jan 2025
_dt_jan_2025 = st.datetimes(
    min_value=datetime(2025, 1, 1, 0, 0, 0),
    max_value=datetime(2025, 1, 31, 23, 59, 59),
)

@composite
def shift_strategy(draw):
    """
    Build a Shift with end_time > start_time.
    """
    name = draw(st.text(min_size=1, max_size=10))
    start = draw(_dt_jan_2025)

    # Duration between 4h and 12h
    duration_hours = draw(st.integers(min_value=4, max_value=12))
    end = start + timedelta(hours=duration_hours)

    # Demand can be zero per schema (NonNegativeInt); keep small
    demand = draw(st.integers(min_value=0, max_value=3))

    # uid is auto-generated by schema default_factory
    return Shift(
        name=name,
        start_time=start,
        end_time=end,
        demand=demand,
    )

def _subset_of_uids(shift_uids, max_size=5):
    """
    Produce a strategy for a set subset of the given shift_uids.
    """
    # sampled_from requires a sequence, not a set
    return st.sets(
        st.sampled_from(list(shift_uids)),
        max_size=max_size,
    )

@composite
def nurse_strategy(draw, shift_uids):
    """
    Build a Nurse whose preferred/blocked sets are subsets of the provided shift_uids.
    """
    name = draw(st.text(min_size=1, max_size=10))
    staff = draw(st.booleans())
    min_tbs = timedelta(hours=8)  # fixed, as in your original
    pref_weight = draw(st.integers(min_value=0, max_value=5))  # NonNegativeInt

    # Independent subsets; may overlap (schema does not forbid)
    preferred = draw(_subset_of_uids(shift_uids, max_size=5))
    blocked = draw(_subset_of_uids(shift_uids, max_size=5))

    # uid is auto-generated by schema default_factory
    return Nurse(
        name=name,
        preferred_shifts=preferred,
        blocked_shifts=blocked,
        staff=staff,
        min_time_between_shifts=min_tbs,
        preferred_shift_weight=pref_weight,
    )

@composite
def instance_strategy(draw):
    """
    Build a NurseRosteringInstance that passes all schema validators:
    - Unique nurse/shift UIDs (handled by defaults).
    - Shifts sorted by start_time.
    - Nurses' preference/blocked sets reference existing shift UIDs.
    """
    # Make and sort shifts by start_time
    num_shifts = draw(st.integers(min_value=10, max_value=20))
    shifts = [draw(shift_strategy()) for _ in range(num_shifts)]
    shifts.sort(key=lambda s: s.start_time)

    shift_uids = [s.uid for s in shifts]

    # Build nurses referencing these shift_uids
    num_nurses = draw(st.integers(min_value=5, max_value=10))
    nurses = [draw(nurse_strategy(shift_uids)) for _ in range(num_nurses)]

    staff_weight = draw(st.integers(min_value=0, max_value=5))

    return NurseRosteringInstance(
        nurses=nurses,
        shifts=shifts,
        staff_weight=staff_weight,
    )


# --- Property test ---

@given(instance=instance_strategy())
def test_solver_finds_feasible_solution(instance):
    model = NurseRosteringModel(instance)
    try:
        solution = model.solve(max_time_in_seconds=10.0)
        assert_solution_is_feasible(instance, solution)
    except ValueError:
        # If the model is infeasible, we accept that as a valid outcome.
        # Ensuring that the input is feasible would be a little more complex.
        pass
```

> [!NOTE]
>
> See Richard Oberdieck’s
> [example repository](https://github.com/RichardOberdieck/opti_test), which
> demonstrates property-based testing for an optimization problem using
> Hypothesis. Consult the
> [/docs](https://github.com/RichardOberdieck/opti_test/tree/main/docs)
> directory for additional textual explanation; note that the documentation is
> incomplete at present.

## Conclusion

In this chapter, we developed a complete nurse rostering solver using CP-SAT
within a test-driven framework. The modular design enabled us to separate
constraints from objectives, create targeted tests, and iterate with confidence.
While this methodology is not always the fastest path to a working solution, it
proves highly effective for problems that evolve over time.

We also highlighted alternative approaches—such as tabular data representations
and property-based testing—emphasizing that you should select the methods that
best suit your specific context. The key takeaway is that software engineering
principles can be successfully applied to optimization modeling, thereby
enhancing both reliability and maintainability.

> [!TIP]
>
> This chapter primarily emphasized correctness. However, once your solution is
> working correctly, you may discover that it does not scale sufficiently well.
> In the chapter [Benchmarking your Model](#08-benchmarking), you will learn how
> to benchmark models to evaluate improvements in performance and scalability.
> The testing framework developed here helps maintain correctness during
> performance optimization. Frequently, enhancing efficiency involves slight
> modifications to the problem formulation—such as approximating non-linear
> elements with linear ones or relaxing constraints that can usually be repaired
> in postprocessing with minimal loss of solution quality. Adapting these
> changes may require adjustments to your tests, but typically you can reuse
> many of them.

<!-- This file was generated by the `build.py` script. Do not edit it manually. -->
<!-- ./chapters/building_an_optimization_api.md -->
<a name="building_an_optimization_api"></a>

# Building an Optimization API (DRAFT)

In this chapter, we will create a basic optimization service that performs
computations on a cluster rather than on the client side. This service can be
extended with a straightforward frontend, allowing non-technical users to access
the optimization capabilities. By encapsulating your optimization code within an
easy-to-use API, integration into larger systems becomes more streamlined, and
the separation of algorithm development from deployment is achieved.

While this chapter does not cover every aspect of building a production-ready
API, it will address many important points of it. This foundational knowledge
will enable you to collaborate effectively with your integration experts to
finalize the implementation details, or even do it yourself.

To illustrate these principles, we will develop a simple optimization model for
the Traveling Salesman Problem (TSP). Users will be able to submit an instance
of the TSP, and the API will return a solution. The primary challenge, compared
to many other APIs, is that the TSP is an NP-hard problem, and the CP-SAT solver
may need several minutes to solve even moderately sized instances. Additionally,
we cannot run the solver on the web server; instead, we must distribute the
computation across a cluster. If many requests are received simultaneously, a
request may need to wait before computation can start.

Therefore, this will not be a simple "send request, get response" API. Instead,
we will implement a task queue, returning a task ID that users can use to check
the status of their computation and retrieve the result once it is ready. To
enhance user experience, we will allow users to specify a webhook URL, which we
will call once the computation is complete.

You should be able to easily adapt this API to your own optimization problems,
allowing you to quickly service your optimization algorithms to your colleagues.

## Specifying the Essential Endpoints

Before we start coding, we should specify the endpoints our API will expose, so
we know what we need to implement. This is something you can directly share with
the coworkers who will implement the frontend or other parts of the system, so
they know what to expect and can start working on their parts. It is usually
simple to change the details of the payloads later, but changing the flow of the
API can be much more complex.

The fundamental operations we will support are:

1. **POST /jobs**: This endpoint will accept a JSON payload containing the TSP
   instance. The API will create a new task, store the instance, and return a
   task ID. The payload will also allow users to specify a webhook URL to call
   once the computation is complete.
2. **GET /jobs/{task_id}**: This endpoint will return the status of the task
   with the given ID.
3. **GET /jobs/{task_id}/solution**: This endpoint will return the solution of
   the task with the given ID, once it is available.
4. **DELETE /jobs/{task_id}**: This endpoint will cancel the task with the given
   ID.
5. **GET /jobs**: This endpoint will return a list of all tasks, including their
   status and metadata.

By defining these endpoints, we ensure that our API is robust and capable of
handling the core functionalities required for managing and solving TSP
instances. This structure will facilitate user interactions, from submitting
tasks to retrieving solutions and monitoring the status of their requests.

Once we have successfully launched or TSP optimization service, we can
anticipate requests to extend our optimization capabilities to other problems.
Therefore, we should add the prefix `/tsp_solver/v1` to all endpoints to
facilitate future expansions of our API with additional solvers, e.g.,
`knapsack_solver/v1`, or `/tsp_solver/v2_experimental`.

You may ask why we do not just create a new project for each solver and then
just stick them together on a higher level. The reason is that we may want to
share the same infrastructure for all solvers, especially the task queue and the
worker cluster. This can not only be easier to maintain, but also cheaper as
resources can be shared. Therefore, it makes sense to keep them in the same
project. However, it will make sense to separate the actual algorithms from the
API code, and only import the algorithms into our API project. We will not do
this in this chapter, but I personally prefer the algorithms to be as separated
as possible as they are often complex enough on their own.

## Architecture

Having outlined the requirements, we will now consider the architecture of our
system. The system will incorporate the following components:

1. **FastAPI for implementing the endpoints**: FastAPI is a modern,
   high-performance web framework for building APIs with Python. We will use
   FastAPI to define API endpoints and handle HTTP requests due to its
   simplicity, speed, and automatic interactive API documentation.

2. **Redis as a database and communication interface with the workers**: Redis
   is an in-memory data structure store that can function as a database, cache,
   and message broker. We will utilize Redis for its speed and efficiency in
   storing and sharing tasks and solutions, which allows quick access and
   automatic expiration of data when it is no longer needed.

3. **Workers managed with RQ (Redis Queue)**: RQ is a simple Python library for
   queuing jobs and processing them in the background with workers. This enables
   our API to handle tasks asynchronously, offloading computationally expensive
   processes to background workers and thereby improving the API's
   responsiveness.

To easily manage these components, we will use Docker and Docker Compose to
containerize the API, Redis, and worker instances. This will allow us to quickly
set up and run the service either locally or in a cloud environment.

> [!WARNING]
>
> We will ignore security aspects in this chapter. This service should be only
> for internal use within the own network and not be exposed to the internet. If
> you want to expose it, you should add authentication, rate limiting, and other
> security measures.

### Project Structure

As we only have a single solver in this project, we will neither separate the
solver from the API nor encapsulate the API, but use a simple, flat structure.
You can find the complete project in
[./examples/optimization_api](https://github.com/d-krupke/cpsat-primer/blob/main/examples/optimization_api).

```text
├── app
│   ├── __init__.py
│   ├── config.py
│   ├── db.py
│   ├── main.py
│   ├── models.py
│   ├── solver.py
│   └── tasks.py
├── docker-compose.yml
├── Dockerfile
└── requirements.txt
```

Let us quickly go through the components of the project:

1. **Requirements**: We define the necessary Python packages in a
   `requirements.txt` file to ensure that the environment can be easily set up
   and replicated. This file includes all dependencies needed for the project.
   `requirements.txt` are rather outdated, but they are the simplest way to just
   install the dependencies in our container.

2. **Docker Environment**:

   - `Dockerfile`: The Dockerfile specifies the Docker image and environment
     setup for the API. It ensures that the application runs in a consistent
     environment across different machines.
   - `docker-compose.yml`: This file configures the services required for the
     project, including the API, Redis, and worker instances. Docker Compose
     simplifies the process of managing multiple containers, ensuring they are
     correctly built and started in the right order. A simple
     `docker-compose up -d --build` will get the whole system up and running.

3. **Solver Implementation**:

   - `./app/solver.py`: This module contains the implementation of the TSP
     solver using CP-SAT. It also specifies the expected input and output data.

4. **Request and Response Models**:

   - `./app/models.py`: This module specifies further data models for API
     requests and responses.

5. **Database**:

   - `./app/db.py`: This module implements a proxy class to interact with Redis,
     abstracting database operations for storing and retrieving job requests,
     statuses, and solutions.

6. **Config**:

   - `./app/config.py`: This module provides configuration functions to set up
     the database connection and task queue. By centralizing configuration, we
     ensure that other parts of the application do not need to manage connection
     details, making the codebase more modular and easier to maintain.

7. **Tasks**:

   - `./app/tasks.py`: This module defines the tasks to be outsourced to
     workers, which right now only includes the optimization job. Our web server
     will only need to get a reference to the task functions in order to queue
     them, but not actually run anything of this code. For the workers, this
     file will be the entry point.

8. **API**:
   - `./app/main.py`: This module implements the FastAPI application with routes
     for submitting jobs, checking job statuses, retrieving solutions, and
     canceling jobs. This is the entry point for the web server.

### Running the Application

To run the application, we use Docker and Docker Compose to build and run the
containers. This ensures the API and its dependencies are correctly set up. Once
the containers are running, you can interact with the API via HTTP requests.

## Docker Environment

We use Docker to ensure a consistent development and production environment.
Docker allows us to package our application with all its dependencies into a
standardized unit for software development. Docker Compose is used to manage
multi-container applications, defining and running multi-container Docker
applications. As the web server and the workers essentially share the same code,
just with different entry points, we can use the same Docker image for both. The
different entry points will be specified in the `docker-compose.yml`.

### Dockerfile

```dockerfile
# Use an official Python runtime as a parent image
FROM python:3.12-slim

# Set the working directory in the container
WORKDIR /app

# Copy the requirements file into the container at /app
COPY requirements.txt /

# Install any needed packages specified in requirements.txt
RUN pip install --no-cache-dir -r /requirements.txt

# Copy the current directory contents into the container at /app
COPY ./app /app
```

### docker-compose.yml

To get our composition of containers, with the API, Redis, and the workers up
and running, we use the following `docker-compose.yml` file:

```yaml
services:
  optimization_api_fastapi: # The web server
    build: .
    container_name: optimization_api_fastapi
    ports: # exposing the API on port 80. Change this if you want to use a different port.
      - "80:80"
    depends_on: # Ensuring that the web server starts after the database.
      - optimization_api_redis
    command: python3 -m uvicorn main:app --host 0.0.0.0 --port 80 --reload

  optimization_api_redis: # The database. We use the official Redis image.
    image: redis:latest
    container_name: optimization_api_redis

  optimization_api_worker: # The worker
    build: .
    command: # Running this command will make our container a worker instead of a web server.
      rq worker --with-scheduler --url redis://optimization_api_redis:6379/1
    depends_on: # Ensuring that the worker starts after the database, as it needs to connect to it.
      - optimization_api_redis
    deploy:
      replicas: 2 # Adding two workers for parallel processing
```

The `docker-compose.yml` file sets up three services:

- `optimization_api_fastapi`: This service builds the FastAPI application,
  exposes it on port 80, and ensures it starts after Redis is available.
- `optimization_api_redis`: This service sets up the Redis database from the
  official Redis image. We just need to remember the name of the container to
  connect to it.
- `optimization_api_worker`: This service builds the worker, which processes
  tasks from the queue. We can scale the number of workers by increasing the
  number of replicas. Theoretically, these workers could be run on different
  machines to scale horizontally.

### Solver

In this section, we will explore the implementation of the optimization
algorithm that we will deploy as an API. Specifically, we will focus on a simple
implementation of the Traveling Salesman Problem (TSP) using the `add_circuit`
constraint from the CP-SAT solver in OR-Tools.

The solver is the core component of our application, responsible for finding the
optimal solution to the TSP instance provided by the user. The algorithm is
implemented directly in the API project for simplicity. However, for more
complex optimization algorithms, it is advisable to separate the algorithm into
a distinct module or project. This separation facilitates isolated testing and
benchmarking of the algorithm and improves the development process, especially
when working in a team where different teams might maintain the API and the
optimization algorithm.

```python
# ./app/solver.py
from typing import Callable
from ortools.sat.python import cp_model
from pydantic import BaseModel, Field

# ---------------------------------------------------------------------
# A precise definition of the input and output data for the TSP solver.
# ---------------------------------------------------------------------


class DirectedEdge(BaseModel):
    source: int = Field(..., ge=0, description="The source node of the edge.")
    target: int = Field(..., ge=0, description="The target node of the edge.")
    cost: int = Field(..., ge=0, description="The cost of traversing the edge.")


class TspInstance(BaseModel):
    num_nodes: int = Field(
        ..., gt=0, description="The number of nodes in the TSP instance."
    )
    edges: list[DirectedEdge] = Field(
        ..., description="The directed edges of the TSP instance."
    )


class OptimizationParameters(BaseModel):
    timeout: int = Field(
        default=60,
        gt=0,
        description="The maximum time in seconds to run the optimization.",
    )


class TspSolution(BaseModel):
    node_order: list[int] | None = Field(
        ..., description="The order of the nodes in the solution."
    )
    cost: float = Field(..., description="The cost of the solution.")
    lower_bound: float = Field(..., description="The lower bound of the solution.")
    is_infeasible: bool = Field(
        default=False, description="Whether the instance is infeasible."
    )


# ---------------------------------------------------------------------
# The TSP solver implementation using the CP-SAT solver from OR-Tools.
# ---------------------------------------------------------------------


class TspSolver:
    def __init__(
        self, tsp_instance: TspInstance, optimization_parameters: OptimizationParameters
    ):
        self.tsp_instance = tsp_instance
        self.optimization_parameters = optimization_parameters
        self.model = cp_model.CpModel()
        self.edge_vars = {
            (edge.source, edge.target): self.model.new_bool_var(
                f"x_{edge.source}_{edge.target}"
            )
            for edge in tsp_instance.edges
        }
        self.model.minimize(
            sum(
                edge.cost * self.edge_vars[(edge.source, edge.target)]
                for edge in tsp_instance.edges
            )
        )
        self.model.add_circuit(
            [(source, target, var) for (source, target), var in self.edge_vars.items()]
        )

    def solve(self, log_callback: Callable[[str], None] | None = None):
        solver = cp_model.CpSolver()
        solver.parameters.max_time_in_seconds = self.optimization_parameters.timeout
        if log_callback:
            solver.parameters.log_search_progress = True
            solver.log_callback = log_callback
        status = solver.Solve(self.model)
        if status in (cp_model.OPTIMAL, cp_model.FEASIBLE):
            return TspSolution(
                node_order=[
                    source
                    for (source, target), var in self.edge_vars.items()
                    if solver.value(var)
                ],
                cost=solver.objective_value,
                lower_bound=solver.best_objective_bound,
            )
        if status == cp_model.INFEASIBLE:
            return TspSolution(
                node_order=None,
                cost=float("inf"),
                lower_bound=float("inf"),
                is_infeasible=True,
            )
        return TspSolution(
            node_order=None,
            cost=float("inf"),
            lower_bound=solver.best_objective_bound,
        )
```

> [!TIP]
>
> CP-SAT itself uses Protobuf for its input, output, and configuration. Having
> well-defined data models can help prevent many "garbage in, garbage out"
> issues and ease integration with other systems. It also facilitates testing
> and debugging, as you can simply serialize a specific scenario. For
> configuration, having default values is very helpful, as it allows you to
> extend the configuration without breaking backward compatibility. This can be
> a significant advantage, as you usually do not know all requirements upfront.
> Pydantic performs this job very well and can be used for the web API as well.
> Protobuf, while not Python-specific and therefore more versatile, is more
> complex to use and lacks the same flexibility as Pydantic.

## Request and Response Models

In this section, we will define the request and response models for the API.
These models will facilitate the communication between the client and the server
by ensuring that the data exchanged is structured and validated correctly.

The models are defined in the `models.py` file and include the necessary data
structures for submitting a TSP job request and tracking the status of the job.

```python
# ./app/models.py
"""
This file contains the implementation of additional data models for the optimization API.
"""

from datetime import datetime
from pydantic import BaseModel, HttpUrl, Field
from uuid import UUID, uuid4
from solver import OptimizationParameters, TspInstance
```

The `TspJobRequest` model encapsulates the information required to submit a TSP
job to the API. It includes the TSP instance, optimization parameters, and an
optional webhook URL for notifications upon job completion.

```python
class TspJobRequest(BaseModel):
    """
    A request model for a TSP job.
    """

    tsp_instance: TspInstance = Field(..., description="The TSP instance to solve.")
    optimization_parameters: OptimizationParameters = Field(
        default_factory=OptimizationParameters,
        description="The optimization parameters.",
    )
    webhook_url: HttpUrl | None = Field(
        default=None, description="The URL to call once the computation is complete."
    )
```

An request could look as follows:

```json
{
    "tsp_instance": {
        "num_nodes": 4,
        "edges": [
            {"source": 0, "target": 1, "cost": 1},
            {"source": 1, "target": 2, "cost": 2},
            {"source": 2, "target": 3, "cost": 3},
            {"source": 3, "target": 0, "cost": 4},
        ],
    },
    "optimization_parameters": {"timeout": 5},
    "webhook_url": null,
},
```

The `TspJobStatus` model is used to track the status of a TSP job. It provides
fields to monitor various stages of the job lifecycle, from submission to
completion.

```python
class TspJobStatus(BaseModel):
    """
    A response model for the status of a TSP job.
    """

    task_id: UUID = Field(default_factory=uuid4, description="The ID of the task.")
    status: str = Field(default="Submitted", description="The status of the task.")
    submitted_at: datetime = Field(
        default_factory=datetime.now, description="The time the task was submitted."
    )
    started_at: datetime | None = Field(
        default=None, description="The time the task was started."
    )
    completed_at: datetime | None = Field(
        default=None, description="The time the task was completed."
    )
    error: str | None = Field(
        default=None, description="The error message if the task failed."
    )
```

These models ensure that the data exchanged between the client and the server is
well-defined and validated.

## Database

In this section, we will implement a database proxy to store the tasks and
solutions. For simplicity, we use Redis, which serves as both our database and
task queue. This approach minimizes the need to set up additional databases and
leverages Redis's key-value storage and automatic data expiration features.

The `TspJobDbConnection` class encapsulates the interactions with the Redis
database. It provides methods to register new jobs, update job statuses,
retrieve job requests, statuses, and solutions, list all jobs, and delete jobs.

```python
# ./app/db.py
"""
This file contains a proxy class to interact with the database.
We are using Redis as the database for this example, but the implementation
can be easily adapted to other databases, as the proxy class abstracts the
database operations.
"""

import json
from models import TspJobStatus, TspJobRequest
from solver import TspSolution
from uuid import UUID
import redis
from typing import Optional, List
import logging
```

The class is initialized with a Redis client and an expiration time for the
stored data. The `_get_data` method is a helper that retrieves and parses JSON
data from Redis by key.

```python
class TspJobDbConnection:
    def __init__(self, redis_client: redis.Redis, expire_time: int = 24 * 60 * 60):
        """Initialize the Redis connection and expiration time."""
        self._redis = redis_client
        self._expire_time = expire_time
        logging.basicConfig(level=logging.INFO)

    def _get_data(self, key: str) -> Optional[dict]:
        """Get data from Redis by key and parse JSON."""
        try:
            data = self._redis.get(key)
            if data is not None:
                return json.loads(data)
        except redis.RedisError as e:
            logging.error(f"Redis error: {e}")
        return None
```

The `get_request`, `get_status`, and `get_solution` methods retrieve a TSP job
request, status, and solution, respectively, by their task ID.

```python
def get_request(self, task_id: UUID) -> Optional[TspJobRequest]:
    """Retrieve a TSP job request by task ID."""
    data = self._get_data(f"request:{task_id}")
    return TspJobRequest(**data) if data else None


def get_status(self, task_id: UUID) -> Optional[TspJobStatus]:
    """Retrieve a TSP job status by task ID."""
    data = self._get_data(f"status:{task_id}")
    return TspJobStatus(**data) if data else None


def get_solution(self, task_id: UUID) -> Optional[TspSolution]:
    """Retrieve a TSP solution by task ID."""
    data = self._get_data(f"solution:{task_id}")
    return TspSolution(**data) if data else None
```

The `set_solution` method stores a TSP solution in Redis with an expiration
time. The `register_job` method registers a new TSP job request and status in
Redis.

```python
def set_solution(self, task_id: UUID, solution: TspSolution) -> None:
    """Set a TSP solution in Redis with an expiration time."""
    try:
        self._redis.set(
            f"solution:{task_id}", solution.model_dump_json(), ex=self._expire_time
        )
    except redis.RedisError as e:
        logging.error("Redis error: %s", e)


def register_job(self, request: TspJobRequest) -> TspJobStatus:
    """Register a new TSP job request and status in Redis."""
    job_status = TspJobStatus()
    try:
        pipeline = self._redis.pipeline()
        pipeline.set(
            f"status:{job_status.task_id}",
            job_status.model_dump_json(),
            ex=self._expire_time,
        )
        pipeline.set(
            f"request:{job_status.task_id}",
            request.model_dump_json(),
            ex=self._expire_time,
        )
        pipeline.execute()
    except redis.RedisError as e:
        logging.error("Redis error: %s", e)

    return job_status
```

The `update_job_status` method updates the status of an existing TSP job. The
`list_jobs` method lists all TSP job statuses.

```python
def update_job_status(self, job_status: TspJobStatus) -> None:
    """Update the status of an existing TSP job."""
    try:
        self._redis.set(
            f"status:{job_status.task_id}",
            job_status.model_dump_json(),
            ex=self._expire_time,
        )
    except redis.RedisError as e:
        logging.error("Redis error: %s", e)


def list_jobs(self) -> List[TspJobStatus]:
    """List all TSP job statuses."""
    try:
        status_keys = self._redis.keys("status:*")
        data = self._redis.mget(status_keys)
        return [TspJobStatus(**json.loads(status)) for status in data if status]
    except redis.RedisError as e:
        logging.error("Redis error: %s", e)

        return []
```

The `delete_job` method deletes a TSP job request, status, and solution from
Redis.

```python
def delete_job(self, task_id: UUID) -> None:
    """Delete a TSP job request, status, and solution from Redis."""
    try:
        pipeline = self._redis.pipeline()
        pipeline.delete(f"status:{task_id}")
        pipeline.delete(f"request:{task_id}")
        pipeline.delete(f"solution:{task_id}")
        pipeline.execute()
    except redis.RedisError as e:
        logging.error("Redis error: %s", e)
```

## Configuration

The database and task queue require a connection to be established before they
can be used. We provide `get_db_connection` and `get_task_queue` functions in
the `config.py` file for three primary reasons:

- To ensure that the database and task queue are properly set up with the
  correct connection details. If we change the Redis host, we only need to
  update it in one place.
- To integrate these functions into FastAPI's dependency injection system,
  ensuring that the database and task queue are available to the API endpoints
  without establishing the connection in each endpoint. This approach also
  facilitates testing with a different database.
- To allow both the FastAPI application and the workers to use the same
  configuration functions, despite having different entry points.

```python
# ./app/config.py
"""
This file contains the configuration for the optimization API.
For this simple project, it only sets up the database connection and the task queue.
The other parts of the API should not be aware of the specific connection details.
"""

from db import TspJobDbConnection
import redis
from rq import Queue


def get_db_connection() -> TspJobDbConnection:
    """Provides a TspJobDbConnection instance."""
    redis_client = redis.Redis(
        host="optimization_api_redis", port=6379, decode_responses=True, db=0
    )
    return TspJobDbConnection(redis_client=redis_client)


def get_task_queue() -> Queue:
    """Provides a Redis Queue instance."""
    redis_client = redis.Redis(host="optimization_api_redis", port=6379, db=1)
    return Queue(connection=redis_client)
```

## Tasks

With the database in place, we can create the tasks that will run the
optimization. The optimization will run in a separate process and use the
database to communicate with the web server. To keep things simple, we will pass
only the job reference to the task. The task will fetch the necessary data from
the database and update the database with the results. Additionally, by
including an `if __name__ == "__main__":` block, we allow the tasks to be run
via an external task queue as system commands.

The `tasks.py` file contains functions and logic for running the optimization
job in a separate worker process.

```python
# ./app/tasks.py
"""
This file is responsible for running the optimization job in a separate worker.
"""

from config import get_db_connection
from models import TspJobRequest, TspJobStatus
from solver import TspSolver
from datetime import datetime
from uuid import UUID
from db import TspJobDbConnection
import httpx
import logging
```

The `send_webhook` function sends a POST request to the specified webhook URL
with the job status. This allows for asynchronous notifications when the
computation is complete.

```python
def send_webhook(job_request: TspJobRequest, job_status: TspJobStatus) -> None:
    if job_request.webhook_url:
        try:
            # Send a POST request to the webhook URL
            response = httpx.post(
                url=f"{job_request.webhook_url}", json=job_status.model_dump_json()
            )
            response.raise_for_status()  # Raise an error for bad responses
        except httpx.HTTPStatusError as e:
            logging.error(
                f"HTTP error occurred: {e.response.status_code} - {e.response.text}"
            )
        except Exception as e:
            logging.error(f"An error occurred: {e}")
```

The `run_optimization_job` function fetches the job request from the database,
runs the optimization algorithm, and stores the solution back in the database.
It also updates the job status and sends a webhook notification upon completion.

```python
def run_optimization_job(
    job_id: UUID, db_connection: TspJobDbConnection | None = None
) -> None:
    """
    Will fetch the job request from the database, run the optimization algorithm,
    and store the solution back in the database. Finally, it will send a webhook
    to the URL specified in the job. This function may be run on a separate worker,
    which is why we do not pass or return data directly, but rather use the database.
    """
    if db_connection is None:
        db_connection = get_db_connection()
    job_status = db_connection.get_status(job_id)
    job_request = db_connection.get_request(job_id)
    if job_status is None or job_request is None:
        return  # job got deleted
    job_status.status = "Running"
    job_status.started_at = datetime.now()
    db_connection.update_job_status(job_status)
    solver = TspSolver(job_request.tsp_instance, job_request.optimization_parameters)
    solution = solver.solve(log_callback=print)
    db_connection.set_solution(job_id, solution)
    job_status.status = "Completed"
    job_status.completed_at = datetime.now()
    db_connection.update_job_status(job_status)
    send_webhook(job_request, job_status)
```

## API

In this final section, we will build the actual API using FastAPI. This API will
expose endpoints to submit TSP job requests, check job statuses, retrieve
solutions, cancel jobs, and list all jobs. FastAPI provides an efficient and
easy-to-use framework for building web APIs with Python.

The `main.py` file contains the FastAPI application setup and the API routes.
For simplicity, all routes are included in a single file, but in larger
projects, it is advisable to separate them into different modules.

```python
# ./app/main.py
"""
This file contains the main FastAPI application.
For a larger project, we would move the routes to separate files, but for this example, we keep everything in one file.
"""

from uuid import UUID
from fastapi import FastAPI, APIRouter, HTTPException, Depends

from models import TspJobRequest, TspJobStatus
from solver import TspSolution
from config import get_db_connection, get_task_queue
from tasks import run_optimization_job
```

The FastAPI application is initialized with a title and description. An API
router is created to group the routes related to the TSP solver.

```python
app = FastAPI(
    title="My Optimization API",
    description="This is an example on how to deploy an optimization algorithm based on CP-SAT as an API.",
)

tsp_solver_v1_router = APIRouter(tags=["TSP_solver_v1"])
```

The `post_job` endpoint allows users to submit a new TSP job. The job is
registered in the database, and the optimization task is enqueued in the task
queue for asynchronous processing.

```python
@tsp_solver_v1_router.post("/jobs", response_model=TspJobStatus)
def post_job(
    job_request: TspJobRequest,
    db_connection=Depends(get_db_connection),
    task_queue=Depends(get_task_queue),
):
    """
    Submit a new job to solve a TSP instance.
    """
    job_status = db_connection.register_job(job_request)
    # enqueue the optimization job in the task queue.
    # Will return immediately, the job will be run in a separate worker.
    task_queue.enqueue(
        run_optimization_job,
        job_status.task_id,
        # adding a 60 second buffer to the job timeout
        job_timeout=job_request.optimization_parameters.timeout + 60,
    )
    return job_status
```

The `get_job` endpoint returns the status of a specific job identified by its
task ID.

```python
@tsp_solver_v1_router.get("/jobs/{task_id}", response_model=TspJobStatus)
def get_job(task_id: UUID, db_connection=Depends(get_db_connection)):
    """
    Return the status of a job.
    """
    status = db_connection.get_status(task_id)
    if status is None:
        raise HTTPException(status_code=404, detail="Job not found")
    return status
```

The `get_solution` endpoint returns the solution of a specific job if it is
available.

```python
@tsp_solver_v1_router.get("/jobs/{task_id}/solution", response_model=TspSolution)
def get_solution(task_id: UUID, db_connection=Depends(get_db_connection)):
    """
    Return the solution of a job, if available.
    """
    solution = db_connection.get_solution(task_id)
    if solution is None:
        raise HTTPException(status_code=404, detail="Solution not found")
    return solution
```

The `cancel_job` endpoint deletes or cancels a job. It does not immediately stop
the job if it is already running.

```python
@tsp_solver_v1_router.delete("/jobs/{task_id}")
def cancel_job(task_id: UUID, db_connection=Depends(get_db_connection)):
    """
    Deletes/cancels a job. This will *not* immediately stop the job if it is running.
    """
    db_connection.delete_job(task_id)
```

The `list_jobs` endpoint returns a list of all jobs and their statuses.

```python
@tsp_solver_v1_router.get("/jobs", response_model=list[TspJobStatus])
def list_jobs(db_connection=Depends(get_db_connection)):
    """
    List all jobs.
    """
    return db_connection.list_jobs()
```

Finally, we include the API router in the FastAPI application under the
`/tsp_solver/v1` prefix.

```python
app.include_router(tsp_solver_v1_router, prefix="/tsp_solver/v1")
```

### Running the Application

After you have run `docker-compose up -d --build`, you can access the API at
`http://localhost:80/docs`. This will open the Swagger UI, where you can test
the API. You can submit a job, check the status, and retrieve the solution. You
can also cancel a job or list all jobs.

| ![Swagger UI](https://raw.githubusercontent.com/d-krupke/cpsat-primer/main/images/swagger_optimization_api.png) |
| :-------------------------------------------------------------------------------------------------------------: |
|               FastAPI comes with a built-in Swagger UI that allows you to interact with the API.                |

| ![Swagger UI - Job Submission](https://raw.githubusercontent.com/d-krupke/cpsat-primer/main/images/swagger_try_it_out.png) |
| :------------------------------------------------------------------------------------------------------------------------: |
|                           By clicking on "try it out" you can directly submit a job to the API.                            |

<details>
<summary>
Here is an instance to try it out: (click to expand)
</summary>

```json
{
  "optimization_parameters": {
    "timeout": 5
  },
  "tsp_instance": {
    "num_nodes": 15,
    "edges": [
      { "source": 0, "target": 1, "cost": 82 },
      { "source": 1, "target": 0, "cost": 82 },
      { "source": 0, "target": 2, "cost": 35 },
      { "source": 2, "target": 0, "cost": 35 },
      { "source": 0, "target": 3, "cost": 58 },
      { "source": 3, "target": 0, "cost": 58 },
      { "source": 0, "target": 4, "cost": 9 },
      { "source": 4, "target": 0, "cost": 9 },
      { "source": 0, "target": 5, "cost": 13 },
      { "source": 5, "target": 0, "cost": 13 },
      { "source": 0, "target": 6, "cost": 91 },
      { "source": 6, "target": 0, "cost": 91 },
      { "source": 0, "target": 7, "cost": 72 },
      { "source": 7, "target": 0, "cost": 72 },
      { "source": 0, "target": 8, "cost": 16 },
      { "source": 8, "target": 0, "cost": 16 },
      { "source": 0, "target": 9, "cost": 50 },
      { "source": 9, "target": 0, "cost": 50 },
      { "source": 0, "target": 10, "cost": 80 },
      { "source": 10, "target": 0, "cost": 80 },
      { "source": 0, "target": 11, "cost": 92 },
      { "source": 11, "target": 0, "cost": 92 },
      { "source": 0, "target": 12, "cost": 28 },
      { "source": 12, "target": 0, "cost": 28 },
      { "source": 0, "target": 13, "cost": 17 },
      { "source": 13, "target": 0, "cost": 17 },
      { "source": 0, "target": 14, "cost": 97 },
      { "source": 14, "target": 0, "cost": 97 },
      { "source": 1, "target": 2, "cost": 14 },
      { "source": 2, "target": 1, "cost": 14 },
      { "source": 1, "target": 3, "cost": 32 },
      { "source": 3, "target": 1, "cost": 32 },
      { "source": 1, "target": 4, "cost": 41 },
      { "source": 4, "target": 1, "cost": 41 },
      { "source": 1, "target": 5, "cost": 52 },
      { "source": 5, "target": 1, "cost": 52 },
      { "source": 1, "target": 6, "cost": 58 },
      { "source": 6, "target": 1, "cost": 58 },
      { "source": 1, "target": 7, "cost": 20 },
      { "source": 7, "target": 1, "cost": 20 },
      { "source": 1, "target": 8, "cost": 1 },
      { "source": 8, "target": 1, "cost": 1 },
      { "source": 1, "target": 9, "cost": 54 },
      { "source": 9, "target": 1, "cost": 54 },
      { "source": 1, "target": 10, "cost": 75 },
      { "source": 10, "target": 1, "cost": 75 },
      { "source": 1, "target": 11, "cost": 15 },
      { "source": 11, "target": 1, "cost": 15 },
      { "source": 1, "target": 12, "cost": 45 },
      { "source": 12, "target": 1, "cost": 45 },
      { "source": 1, "target": 13, "cost": 94 },
      { "source": 13, "target": 1, "cost": 94 },
      { "source": 1, "target": 14, "cost": 41 },
      { "source": 14, "target": 1, "cost": 41 },
      { "source": 2, "target": 3, "cost": 82 },
      { "source": 3, "target": 2, "cost": 82 },
      { "source": 2, "target": 4, "cost": 44 },
      { "source": 4, "target": 2, "cost": 44 },
      { "source": 2, "target": 5, "cost": 83 },
      { "source": 5, "target": 2, "cost": 83 },
      { "source": 2, "target": 6, "cost": 91 },
      { "source": 6, "target": 2, "cost": 91 },
      { "source": 2, "target": 7, "cost": 78 },
      { "source": 7, "target": 2, "cost": 78 },
      { "source": 2, "target": 8, "cost": 51 },
      { "source": 8, "target": 2, "cost": 51 },
      { "source": 2, "target": 9, "cost": 6 },
      { "source": 9, "target": 2, "cost": 6 },
      { "source": 2, "target": 10, "cost": 81 },
      { "source": 10, "target": 2, "cost": 81 },
      { "source": 2, "target": 11, "cost": 77 },
      { "source": 11, "target": 2, "cost": 77 },
      { "source": 2, "target": 12, "cost": 93 },
      { "source": 12, "target": 2, "cost": 93 },
      { "source": 2, "target": 13, "cost": 97 },
      { "source": 13, "target": 2, "cost": 97 },
      { "source": 2, "target": 14, "cost": 33 },
      { "source": 14, "target": 2, "cost": 33 },
      { "source": 3, "target": 4, "cost": 66 },
      { "source": 4, "target": 3, "cost": 66 },
      { "source": 3, "target": 5, "cost": 47 },
      { "source": 5, "target": 3, "cost": 47 },
      { "source": 3, "target": 6, "cost": 54 },
      { "source": 6, "target": 3, "cost": 54 },
      { "source": 3, "target": 7, "cost": 39 },
      { "source": 7, "target": 3, "cost": 39 },
      { "source": 3, "target": 8, "cost": 98 },
      { "source": 8, "target": 3, "cost": 98 },
      { "source": 3, "target": 9, "cost": 90 },
      { "source": 9, "target": 3, "cost": 90 },
      { "source": 3, "target": 10, "cost": 5 },
      { "source": 10, "target": 3, "cost": 5 },
      { "source": 3, "target": 11, "cost": 27 },
      { "source": 11, "target": 3, "cost": 27 },
      { "source": 3, "target": 12, "cost": 61 },
      { "source": 12, "target": 3, "cost": 61 },
      { "source": 3, "target": 13, "cost": 95 },
      { "source": 13, "target": 3, "cost": 95 },
      { "source": 3, "target": 14, "cost": 19 },
      { "source": 14, "target": 3, "cost": 19 },
      { "source": 4, "target": 5, "cost": 34 },
      { "source": 5, "target": 4, "cost": 34 },
      { "source": 4, "target": 6, "cost": 10 },
      { "source": 6, "target": 4, "cost": 10 },
      { "source": 4, "target": 7, "cost": 20 },
      { "source": 7, "target": 4, "cost": 20 },
      { "source": 4, "target": 8, "cost": 44 },
      { "source": 8, "target": 4, "cost": 44 },
      { "source": 4, "target": 9, "cost": 33 },
      { "source": 9, "target": 4, "cost": 33 },
      { "source": 4, "target": 10, "cost": 29 },
      { "source": 10, "target": 4, "cost": 29 },
      { "source": 4, "target": 11, "cost": 36 },
      { "source": 11, "target": 4, "cost": 36 },
      { "source": 4, "target": 12, "cost": 62 },
      { "source": 12, "target": 4, "cost": 62 },
      { "source": 4, "target": 13, "cost": 77 },
      { "source": 13, "target": 4, "cost": 77 },
      { "source": 4, "target": 14, "cost": 63 },
      { "source": 14, "target": 4, "cost": 63 },
      { "source": 5, "target": 6, "cost": 73 },
      { "source": 6, "target": 5, "cost": 73 },
      { "source": 5, "target": 7, "cost": 6 },
      { "source": 7, "target": 5, "cost": 6 },
      { "source": 5, "target": 8, "cost": 91 },
      { "source": 8, "target": 5, "cost": 91 },
      { "source": 5, "target": 9, "cost": 5 },
      { "source": 9, "target": 5, "cost": 5 },
      { "source": 5, "target": 10, "cost": 61 },
      { "source": 10, "target": 5, "cost": 61 },
      { "source": 5, "target": 11, "cost": 11 },
      { "source": 11, "target": 5, "cost": 11 },
      { "source": 5, "target": 12, "cost": 91 },
      { "source": 12, "target": 5, "cost": 91 },
      { "source": 5, "target": 13, "cost": 7 },
      { "source": 13, "target": 5, "cost": 7 },
      { "source": 5, "target": 14, "cost": 88 },
      { "source": 14, "target": 5, "cost": 88 },
      { "source": 6, "target": 7, "cost": 52 },
      { "source": 7, "target": 6, "cost": 52 },
      { "source": 6, "target": 8, "cost": 86 },
      { "source": 8, "target": 6, "cost": 86 },
      { "source": 6, "target": 9, "cost": 48 },
      { "source": 9, "target": 6, "cost": 48 },
      { "source": 6, "target": 10, "cost": 13 },
      { "source": 10, "target": 6, "cost": 13 },
      { "source": 6, "target": 11, "cost": 31 },
      { "source": 11, "target": 6, "cost": 31 },
      { "source": 6, "target": 12, "cost": 91 },
      { "source": 12, "target": 6, "cost": 91 },
      { "source": 6, "target": 13, "cost": 62 },
      { "source": 13, "target": 6, "cost": 62 },
      { "source": 6, "target": 14, "cost": 30 },
      { "source": 14, "target": 6, "cost": 30 },
      { "source": 7, "target": 8, "cost": 79 },
      { "source": 8, "target": 7, "cost": 79 },
      { "source": 7, "target": 9, "cost": 94 },
      { "source": 9, "target": 7, "cost": 94 },
      { "source": 7, "target": 10, "cost": 58 },
      { "source": 10, "target": 7, "cost": 58 },
      { "source": 7, "target": 11, "cost": 12 },
      { "source": 11, "target": 7, "cost": 12 },
      { "source": 7, "target": 12, "cost": 81 },
      { "source": 12, "target": 7, "cost": 81 },
      { "source": 7, "target": 13, "cost": 2 },
      { "source": 13, "target": 7, "cost": 2 },
      { "source": 7, "target": 14, "cost": 89 },
      { "source": 14, "target": 7, "cost": 89 },
      { "source": 8, "target": 9, "cost": 15 },
      { "source": 9, "target": 8, "cost": 15 },
      { "source": 8, "target": 10, "cost": 94 },
      { "source": 10, "target": 8, "cost": 94 },
      { "source": 8, "target": 11, "cost": 23 },
      { "source": 11, "target": 8, "cost": 23 },
      { "source": 8, "target": 12, "cost": 50 },
      { "source": 12, "target": 8, "cost": 50 },
      { "source": 8, "target": 13, "cost": 79 },
      { "source": 13, "target": 8, "cost": 79 },
      { "source": 8, "target": 14, "cost": 65 },
      { "source": 14, "target": 8, "cost": 65 },
      { "source": 9, "target": 10, "cost": 68 },
      { "source": 10, "target": 9, "cost": 68 },
      { "source": 9, "target": 11, "cost": 81 },
      { "source": 11, "target": 9, "cost": 81 },
      { "source": 9, "target": 12, "cost": 34 },
      { "source": 12, "target": 9, "cost": 34 },
      { "source": 9, "target": 13, "cost": 21 },
      { "source": 13, "target": 9, "cost": 21 },
      { "source": 9, "target": 14, "cost": 16 },
      { "source": 14, "target": 9, "cost": 16 },
      { "source": 10, "target": 11, "cost": 10 },
      { "source": 11, "target": 10, "cost": 10 },
      { "source": 10, "target": 12, "cost": 12 },
      { "source": 12, "target": 10, "cost": 12 },
      { "source": 10, "target": 13, "cost": 60 },
      { "source": 13, "target": 10, "cost": 60 },
      { "source": 10, "target": 14, "cost": 61 },
      { "source": 14, "target": 10, "cost": 61 },
      { "source": 11, "target": 12, "cost": 36 },
      { "source": 12, "target": 11, "cost": 36 },
      { "source": 11, "target": 13, "cost": 78 },
      { "source": 13, "target": 11, "cost": 78 },
      { "source": 11, "target": 14, "cost": 79 },
      { "source": 14, "target": 11, "cost": 79 },
      { "source": 12, "target": 13, "cost": 54 },
      { "source": 13, "target": 12, "cost": 54 },
      { "source": 12, "target": 14, "cost": 33 },
      { "source": 14, "target": 12, "cost": 33 },
      { "source": 13, "target": 14, "cost": 29 },
      { "source": 14, "target": 13, "cost": 29 }
    ]
  }
}
```

</details>

<!-- This file was generated by the `build.py` script. Do not edit it manually. -->
<!-- chapters/machine_learning.md -->
## Classical Optimization vs. Machine Learning (and the impact of Quantum Computing)

<a name="chapters-machine-learning"></a>

A prevalent discussion in today's landscape revolves around whether Machine
Learning (ML) or Quantum Computing (QC) could replace classical optimization
methods such as CP-SAT. In this chapter, we will explore the fundamental
differences between Machine Learning and Optimization, demonstrating that these
fields are not interchangeable but rather complementary to each other. By
understanding their distinct strengths and applications, we can better leverage
each approach to solve complex problems effectively.

Following our discussion on these differences, a common question arises: will
Quantum Computing render classical optimization techniques obsolete? To address
this, we will delve into the basic challenges facing Quantum Computing in the
context of Optimization and explain why its impact may be less significant than
often anticipated. This section aims to debunk several myths, some of which are
perpetuated by proponents of Quantum Computing.

Machine Learning excels at **predicting** outcomes based on historical data,
identifying patterns, and making informed guesses, such as estimating the best
solution to an optimization problem based on data patterns. It is adept at
learning and generalizing from data, even if the data is imperfect, provided
there is sufficient quantity. On the other hand, Optimization is powerful for
systematically **searching** for the best solution based on a well-defined
mathematical model, capable of optimizing variables and constraints with
precision, often requiring minimal data. For example, in planning delivery
routes, ML can predict driving times and resource needs based on historical
factors, whereas an optimization solver like CP-SAT is better suited to
determining the most efficient routes by evaluating the interdependencies and
constraints systematically. Both fields enhance decision-making processes when
used together, leveraging ML’s predictive capabilities and Optimization’s
rigorous solution-finding methods.

In the article
[**Four Key Differences Between Mathematical Optimization And Machine Learning**](https://www.forbes.com/councils/forbestechcouncil/2021/06/25/four-key-differences-between-mathematical-optimization-and-machine-learning/),
Edward Rothberg, the CEO of Gurobi, highlights four key differences between
Machine Learning and Optimization:

- **Analytical Focus**: ML is primarily a **predictive** tool that identifies
  patterns in historical data to forecast future events, whereas Optimization is
  a **prescriptive** tool that uses a digital twin of your environment to
  recommend the best possible decisions.
- **Typical Applications**: ML is commonly used for tasks like fraud detection,
  speech recognition, and product recommendations—often consumer-facing
  applications. Optimization is leveraged for operational decision-making in
  areas like production planning, scheduling, and shipment routing.
- **Adaptability**: ML can suffer from "model drift" if the environment changes
  significantly, requiring retraining with new data. Optimization models,
  however, can be updated more seamlessly to reflect changes in real time but
  usually need more upfront effort to build.
- **Maturity**: Both fields have roots tracing back decades, but Optimization
  has largely settled into a "plateau of productivity," while ML is currently at
  the “peak of inflated expectations” and may face a phase of disillusionment
  before stabilizing into broader adoption.

> [!TIP]
>
> You do not have to read this section if you are not interested in my
> arguments. The TL;DR is that neither Machine Learning nor Quantum Computing
> will make CP-SAT (and similar methods) obsolete any time soon, if ever.
> However, Machine Learning is a valuable complement to Optimization.

> [!TIP]
>
> [ML ain't your only hammer: adding mathematical optimisation to the data scientist's toolbox](https://www.youtube.com/watch?v=G0tlyC9Sr3w):
> This 20-minute talk by Dr. Jack Simpson introduces data scientists with a
> machine learning focus to mathematical optimization, highlighting how it
> prescribes optimal decisions under complex constraints and complements ML
> forecasts.

### Using GenAI/LLMs for Optimization

<!-- Concrete example of using ChatGPT for optimizing -->

It is indeed possible to ask ChatGPT (or similar large language models) to solve
certain optimization problems, and in simpler cases (like the Knapsack Problem)
it often succeeds by automatically writing Python code that calls an external
solver (e.g., HiGHs). Although this approach may work for small instances, it
generally runs much slower than a dedicated solver and can introduce subtle
errors. In the example below, ChatGPT took around 10 seconds, whereas a
specialized solver would have solved the same instance almost instantly:

| ![ChatGPT Optimization](https://raw.githubusercontent.com/d-krupke/cpsat-primer/main/images/chatgpt-knapsack_1.png) | ![ChatGPT Optimization Analysis](https://raw.githubusercontent.com/d-krupke/cpsat-primer/main/images/chatgpt-knapsack_2.png) |
| :-----------------------------------------------------------------------------------------------------------------: | :--------------------------------------------------------------------------------------------------------------------------: |
|                      Asking ChatGPT to solve a Knapsack Problem, which it does successfully...                      |                                   ...but under the hood, it relies on an external solver.                                    |

<!-- LLMs can reason but only in short turns -->

More advanced versions of ChatGPT (e.g., ChatGPT 4) can tackle somewhat larger
problems but still fall short of solvers like CP-SAT that systematically
evaluate massive search spaces with efficient backtracking and pruning. Large
language models process information sequentially in short "turns", have limited
context windows, and lack specialized heuristics - factors that make them prone
to logical missteps and slower performance as the problem size grows. Repeatedly
generating code or text also creates overhead, and verifying solutions can
require multiple iterations of prompting, further compounding the time cost.

<!-- LLMs are not a replacement for solvers -->

Because of these limitations, LLMs are unlikely to replace robust solvers for
substantial or complex optimization tasks anytime soon. However, current
research on **hybrid AI-OR methods** aims to combine the flexibility of LLMs
(such as quick prototyping and model building) with the powerful search
capabilities of dedicated solvers. As this field evolves, LLMs may increasingly
assist in formulating or refining optimization models while specialized engines
focus on the computationally intensive search. We will revisit these
possibilities in the upcoming section on "Model Building with GenAI/LLMs".

<!-- Further reading -->

To dig a little deeper into the limitations of LLMs for optimization, consider
the following articles:

- [LLM-ify me - Optimization edition](https://oberdieck.dk/p/llm-in-optimization/):
  A blog post exploring the potential of LLMs for optimization.
- [Mind Evolution and the frontier of LLM-based optimization solvers](https://open.substack.com/pub/feasible/p/64-mind-evolution-and-the-frontier?r=49480z&utm_campaign=post&utm_medium=email):
  An article from the Feasible newsletter discussing the potential of LLMs for
  optimization.
- [Why Solving Multi-agent Path Finding with Large Language Models has not Succeeded Yet](https://arxiv.org/pdf/2401.03630)
- [Look Further Ahead: Testing the Limits of GPT-4 in Path Planning](https://arxiv.org/pdf/2406.12000)
- [Extracting Problem Structure with LLMs for Optimized SAT Local Search](https://arxiv.org/pdf/2501.14630):
  This paper demonstrates how an LLM can be used to automatically generate
  **start heuristics** from Python code that models a problem as a SAT instance
  using the PySAT library. These start heuristics provide the **initial phase**
  for a SAT solver, helping it begin the search from a more promising assignment
  and enabling it to solve additional instances that would remain unsolved
  otherwise.

### Reinforcement Learning

In some cases, an actually viable alternative to optimization solvers like
CP-SAT is Reinforcement Learning. Reinforcement learning can be highly effective
for optimizing very complex problems that are too intricate to model with simple
mathematical formulations. During my dissertation, I applied reinforcement
learning to optimize a multi-agent system where developing a comprehensive
mathematical model was infeasible due to the excessive number of variables and
constraints required to capture the system’s dynamics. Additionally, manually
crafted heuristics proved unable to compete with the performance of a
straightforward reinforcement learning agent, which I implemented with minimal
effort using
[Stable Baselines](https://stable-baselines.readthedocs.io/en/master/). However,
despite reinforcement learning agents being capable of performing many more
iterations to learn about the solution space compared to large language models
(LLMs), they still lack the structured and efficient search capabilities
inherent in classical solvers. Furthermore, designing an appropriate reward
function for reinforcement learning can be challenging and often involves
significant trial and error.

#### Combining Machine Learning and Optimization

Instead of trying to replace optimization solvers like CP-SAT with machine
learning, a more promising approach is to combine the two fields. This can be
achieved in several ways, such as using machine learning to predict parameters
for optimization problems, building optimization proxies, or integrating machine
learning within solvers to guide internal decisions. These methods leverage the
strengths of both fields to enhance decision-making processes and improve
solution quality.

##### Predict-Then-Optimize Variants

<!-- Basic Variant-->

Predict-Then-Optimize is a framework that combines machine learning with
optimization. The basic version involves two simple steps: predict and then
optimize. First, a standard ML model (e.g., a regression) is trained to estimate
unknown parameters of the optimization problem, such as costs or demands, using
conventional loss functions like mean squared error. Next, these predicted
parameters are passed to an optimization solver (such as CP-SAT), which produces
a best-possible solution—say, a schedule, route, or resource allocation—based on
the estimated inputs. This approach is effective when the model’s predictive
accuracy is reasonably high, but it can falter if small errors in the
predictions cause large downstream impacts on the decision.

<!-- Improved Variants -->

To improve decision quality, more advanced, "decision-focused" variants of
Predict-Then-Optimize incorporate the solver's objective directly into the ML
training process. Rather than merely minimizing standard predictive error, these
methods seek to minimize "regret"—the gap between the cost of the solver's
solution under predicted parameters and the cost of the true optimal solution.
By repeatedly using the solver (or an approximation) during training, they
compute how prediction mistakes translate into suboptimal decisions, and feed
this information back to the ML model's parameters. As a result, the model
learns to predict in a way that preserves or improves the final solution's
quality, even if the raw predictive accuracy on each parameter is not perfectly
precise.

<!-- References -->

Check out
[this great lecture by Elias Khalil](https://www.youtube.com/watch?v=pZqm-i57gxk)
which was part of a summer school.

> [!TIP]
>
> Uncertainty and unknown parameters frequently arise in optimization problems.
> While the **predict-then-optimize** framework offers a straightforward
> approach, its more advanced variants can help address some of its limitations.
> For even greater robustness, techniques such as **robust optimization**,
> **stochastic programming**, and others provide more effective solutions,
> especially in highly uncertain environments, though they come with increased
> complexity. Numerous research studies explore these and additional methods,
> with the optimal choice depending heavily on the specific application.

##### Optimization Proxies

<!-- basic idea of optimization proxies -->

An optimization proxy is a machine learning model trained to approximate the
input-output behavior of an optimization solver, enabling near-instant decisions
once deployed. Typically, one gathers a large set of problem instances, solves
them offline using a traditional solver to generate "ground truth" solutions,
and then trains an ML model to map inputs (e.g., demands, costs) to outputs (the
solver's decisions). In real-time or large-scale simulation settings—such as
power systems, scheduling, or routing—using the learned proxy bypasses the usual
heavy solve times, providing solutions (or near-solutions) almost instantly.
Because the training data comes directly from the solver, no manual labeling is
required; any number of instances can be generated offline.

<!-- Pros and Cons -->

However, optimization proxies excel only when repeatedly solving relatively
similar models under stable conditions, and they can struggle when complex
feasibility constraints or drastically changing problem parameters arise. Though
they have found very useful applications in areas like power networks, many
other optimization contexts involve too many shifting variables or intricate
constraints for a simple proxy to handle reliably. Substantial changes to the
problem's structure often require retraining or extensive model adaptation. As a
result, while proxies can be a powerful add-on to speed up certain classes of
problem instances, they are by no means a universal replacement for classical
solvers.

<!-- Further Reading -->

A [short 4min explanation](https://www.youtube.com/watch?v=UAwEZi56cb8) is given
by Pascal Van Hentenryck. And a longer version can be found
[here](https://www.youtube.com/watch?v=NlwxEGtw4QY).

##### Model Building with GenAI/LLMs

An increasingly valuable application of LLMs (or generative AI) in optimization
is assisting with the model building process. Rather than trying to solve an
optimization problem directly, which is often ineffective, these models can help
set up the initial model that a specialized solver will handle. Many
optimization models share similar structures and differ only in certain details,
making LLMs useful for producing core components. Tools like GitHub Co-Pilot can
already generate complex parts of a model, yet they may also introduce subtle
errors that are hard to detect, such as off by one mistakes, inverted
constraints, or swapped indices. It is therefore best to use LLMs as a source of
inspiration and verify their output carefully; otherwise, the time you save
coding might be spent on debugging.

Moreover, your optimization model often represents the backbone of a real world
problem, so it is crucial to understand how it aligns with the underlying
operational or business context. While LLMs can expedite coding, they cannot
replace the human expertise needed to approximate and simplify real world
complexities. If the scenario is critical, you may not want to rely too heavily
on an AI-based approach at this stage. That said, several research projects and
commercial products are already exploring this idea:

1. [A Research Project at Stanford](https://web.stanford.edu/~udell/project-modeling.html)
2. [Gurobi AI Modeling](https://gurobi-ai-modeling.readthedocs.io/en/latest/index.html)
   ([Quick Overview](https://www.youtube.com/watch?v=8hr_23zdRV4))
3. [Quantagonia](https://www.quantagonia.com/decisionai) provides a solver you
   can interact with via chat
4. [Robust and Adaptive Optimization under a Large Language Model Lens](https://arxiv.org/pdf/2501.00568):
   A research paper exploring using LLMs for robust optimization.
5. [DualSchool: How Reliable are LLMs for Optimization Education?](https://arxiv.org/pdf/2505.21775):
   This paper shows that LLMs still struggle with simple, recipe-based tasks
   like dualizing linear programs.

##### Learning instead of Guessing

Machine learning can also be integrated _inside_ solvers, guiding internal
decisions such as branching strategies, cut selection, or matrix scaling. Rather
than relying on hand-tuned rules alone, the solver gathers data across diverse
problem instances and learns which algorithmic choices best reduce run time or
improve numerical stability. For instance, a model can predict whether "local"
or "global" cutting planes will be more effective on a given instance, or
whether certain scaling methods will avoid ill-conditioned bases. By treating
these decisions as regression tasks - estimating speedup or stability
improvements - machine learning lets the solver adapt and self-tune, ultimately
performing better on a wide spectrum of problems without sacrificing generality.

This
[lecture by Timo Berthold (FICO)](https://www.youtube.com/watch?v=xYKNH3Pqq9A)
gives a good overview of the topic. It has been part of the CO@Work 2024 summer
school, which I actually attended and consider to be absolutely amazing and if
you get the chance to attend, I highly recommend it (as long as you already are
on PhD-level, as it is intense).

A three-hour tutorial by various experts on the topic (including Elias Khalil
and Andrea Lodi), can be found
[here](https://www.youtube.com/watch?v=XVLd7hf6y6M&list=LL&index=20). I highly
recommend watching it, if you are interested in the topic as I had many "aha"
moments during this tutorial.

> [!NOTE]
>
> - [Machine learning augmented branch and bound for mixed integer linear programming](https://link.springer.com/article/10.1007/s10107-024-02130-y):
>   This recent paper from 2024 surveys ideas for using machine learning to
>   improve branch-and-bound solvers for mixed-integer linear programming.

### Why Quantum Computing Will (Probably) Not Have a Big Impact on Optimization

Before closing this chapter, let us also discuss the impact of Quantum Computing
on Optimization, as this is a question I am frequently asked, usually directly
after having explained why ChatGPT cannot replace CP-SAT.

<!-- Dangerous Claims -->

You often hear claims that quantum computing will revolutionize optimization,
especially regarding the Traveling Salesman Problem (TSP). These claims
frequently state that a new quantum algorithm can solve TSP (a challenging yet
practically important combinatorial optimization problem) for small instance
sizes, while a classical computer would supposedly need billions of years to
handle as few as 20 nodes. (In reality, some published papers still only address
four nodes.) Unfortunately, such claims usually hinge on a theoretical
worst-case runtime of around $O(n^2 2^n)$ for the TSP, which is not
representative of how the problem is handled in practice.

> [!NOTE]
>
> For an accessible and insightful discussion on the myths and exaggerated
> expectations surrounding quantum computing, consult the freely available book
> [_What You Shouldn't Know About Quantum Computers_](https://arxiv.org/abs/2405.15838)
> by Chris Ferrie. This resource offers an excellent opportunity to critically
> examine common misconceptions often perpetuated by science fiction and popular
> science literature.

<!-- Worst-Case vs. Real-World -->

Although the best-known quantum algorithm runs in $O(1.728^n)$, which is
somewhat better than $O(n^2 2^n)$, it remains exponential and grows very
quickly. Since the TSP is NP-hard, it is unlikely we will ever discover a
(quantum or classical) algorithm whose worst-case runtime does not explode with
instance size. Moreover, real-world or average-case performance can be vastly
different from worst-case performance. In fact, TSP can already be solved
effectively for large instances on classical computers, so many bold claims
about quantum computing's purported advantages in optimization can be misleading
or simply incorrect.

<!-- TL;DR -->

To date, there is no strong evidence suggesting that quantum computing will have
a major impact on optimization. Many experts believe that, at best, quantum
computing might offer only a modest performance advantage in this domain, though
it may have significant implications for cryptology.

> [!TIP]
>
> At a recent consortium meeting, a consultant from a logistics optimization
> firm made a particularly noteworthy remark. According to them, even with the
> advent of a fully functional quantum computer equipped with thousands of
> flawless qubits, its primary utility would lie in marketing. Beyond that, it
> would be little more than "metal trash," offering no tangible value for their
> customers' use cases. This statement prompted humorous objections from quantum
> experts regarding the "metal trash" comment. Nevertheless, the broader
> sentiment that quantum computing is overhyped in the optimization domain was
> widely shared.

<!-- Quantum Computers are currently worse than Pen&Paper -->

To put the Traveling Salesman Problem's difficulty into historical perspective:
In the mid-20th century, the TSP attracted attention through challenges offering
substantial prize money for solving relatively small instances of 33 to 49
cities - already far larger than those currently tackled by many quantum
researchers. As Newsweek reported in **1954**:

> "By an ingenious application of linear programming - a mathematical tool
> recently used to solve production-scheduling problems - it took only a few
> weeks for the California experts to calculate by hand the shortest route to
> cover the 49 cities."

Remarkably, they not only found the shortest route, but also proved it was the
shortest, all by hand in the 1950s. You can read more details in
[this blog post](https://www.math.uwaterloo.ca/tsp/us/history.html). Nowadays,
there is even
[an iPhone app](https://apps.apple.com/us/app/concorde-tsp/id498366515) that can
solve instances of around 1,000 TSP cities to optimality in mere seconds.
[Larger-scale instances](https://www.math.uwaterloo.ca/tsp/optimal/index.html)
(up to 85,900 nodes, solved in 2006) and near-optimal solutions for millions of
cities illustrate how far classical methods have come. In that sense, quantum
computers have a considerable way to go before they can beat even a human with
pen and paper, let alone a classical computer.

<!-- Anecdote of a wrong complexity estimate leading to financial loss -->

Misjudging the difficulty of certain combinatorial problems famously led one
puzzle inventor into unexpected financial trouble. His creation,
[_The Eternity Puzzle_](https://en.wikipedia.org/wiki/Eternity_puzzle), offered
a £1,000,000 prize to anyone who could solve it—a sum that some early estimates
suggested might never be claimed in a human lifespan, given the vast number of
possible configurations. However, instead of brute-forcing every possibility,
two Cambridge mathematicians employed advanced techniques to dramatically narrow
the search space. Similarly, CP-SAT leverages a variety of behind-the-scenes
strategies to tackle complex problems more efficiently than most would
imagine—indeed, many of the methods used to solve The Eternity Puzzle resemble
what CP-SAT does in a more general way.

Thanks to these refined methods, the puzzle was solved in under 18 months - much
sooner than anticipated. Although rumors circulated that the puzzle's inventor,
Christopher Monckton, was forced to sell his mansion to pay the prize, this
appears to have been more of a publicity stunt; in reality, he could afford to
cover the loss. He later released a successor puzzle, which has proven far more
difficult and remains unsolved.

<!-- Basic Quantum Computing and Advantage -->

Quantum computers exploit superposition and entanglement to evaluate multiple
solutions in parallel. However, they do not simply evaluate all $n!$
permutations at once and automatically return the best one - an assumption that,
unfortunately, is still common. Once you measure the output of a quantum
algorithm, you effectively collapse the wavefunction, ending up with a single
measured state. Thus, careful algorithm design is required to boost the
probability of measuring the correct solution, often requiring many repeated
measurements. A relevant quantum algorithm in this context is Grover's
Algorithm, which offers a quadratic speedup in unstructured searches (e.g., from
$O(2^n)$ to $O(\sqrt{2^n})$). However, TSPs and other optimization problems have
enough internal structure in practice that classical approaches can exploit it,
often rendering Grover's quadratic speedup unimpressive by comparison.

<!-- Shortcomings of Quantum Computers compared to Classical Computers -->

Quantum computers also come with significant drawbacks relative to classical
computers. Their quantum state collapses upon measurement, preventing techniques
like "early abort" or classical branch-and-bound pruning, where large portions
of the search space can be discarded based on intermediate results. Classical
algorithms rely on this kind of dynamic pruning to speed up the search. Quantum
computing sacrifices flexibility for parallel evaluation—an advantage in
unstructured or purely guesswork-based problems, but most practical optimization
problems have exploitable structure. While there may be ways around these
limitations and, in theory, quantum computers are more powerful than classical
ones, whether this yields substantial real-world benefits for optimization
remains unclear.

<!-- Comparison to GP-GPU -->

In some sense, quantum computers face challenges reminiscent of GPU computing:
both process many data points in parallel (Single-Instruction, Multiple-Data),
but lose out on some flexibility since every thread must follow identical
instructions. Even for GPUs, applying them effectively to large-scale
optimization has proven tricky, though progress continues.

<!-- Some Resources -->

If you want more perspectives on the topic, the following articles may be of
interest:

- [Challenges and Opportunities in Quantum Optimization](https://arxiv.org/pdf/2312.02279):
  This preprint gives on 72 pages an extensive and well-written overview of the
  state of the art in quantum optimization. While the conclusion sounds quite
  optimistic, the paper is very clear about the current limitations and
  challenges. while it caters a scientific audience, it is still quite
  accessible.
- [The travelling salesperson problem and the challenges of near-term quantum advantage](https://iopscience.iop.org/article/10.1088/2058-9565/add61d):
  In this paper, Smith-Miles et al. argue why the TSP is unlikely to benefit
  from quantum computing in the foreseeable future. They also draw parallels to
  the failed attempts to solve the TSP with neural networks.
- [Understanding instance hardness for optimisation algorithms: Methodologies, open challenges and post-quantum implications](https://www.sciencedirect.com/science/article/pii/S0307904X2500040X):
  This paper states that "it seems likely that there will be no quantum
  advantage for the TSP" due to challenges in tuning the parameters of QUBOs to
  even yield feasible solutions. However, it considers unconstrained
  optimization problems such as the MAX-CUT to have a higher chance of
  benefiting from quantum computing.
- [Disentangling Hype from Practicality: On Realistically Achieving Quantum Advantage](https://cacm.acm.org/research/disentangling-hype-from-practicality-on-realistically-achieving-quantum-advantage/#R3)
  Gives strong arguments why it can be hard to achieve quantum advantage in
  practice, especially why quadratic speedup algorithms like Grover's Algorithm
  will not suffice.
- [Quantum advantage for NP approximation? For REAL this time?](https://scottaaronson.blog/?p=8375):
  A blog post by Scott Aaronson, a well-known quantum computing expert, offering
  a critical take on the QAOA algorithm and its claimed advantages.
- [Challenges and opportunities in quantum optimization](https://www.nature.com/articles/s42254-024-00770-9):
  A balanced discussion by a group of researchers, highlighting potential
  opportunities without making unfounded claims.
- [Quantum Annealing versus Digital Computing: An Experimental Comparison](https://www.researchgqate.net/publication/353155344_Quantum_Annealing_versus_Digital_Computing_An_Experimental_Comparison):
  This paper compares quantum annealing to classical computing for optimization
  problems and found no indication of a quantum advantage.

<!-- Disclaimer that I am not an expert -->

> [!WARNING]
>
> I do not claim to be an expert in quantum computing, so please interpret my
> remarks with appropriate caution. This book is an open-source project;
> therefore, if you have any corrections or suggestions to help improve the
> material for the community, feel free to open an issue or submit a pull
> request on [GitHub](https://github.com/d-krupke/cpsat-primer/).

<!-- This file was generated by the `build.py` script. Do not edit it manually. -->
<!-- ./chapters/08_benchmarking.md -->
<!-- EDIT THIS PART VIA 08_benchmarking.md -->

<a name="08-benchmarking"></a>

## Benchmarking your Model


This chapter explores methods for comparing the performance of different models
applied to complex problems, where the basic model leaves room for improvement —
either in runtime or in solution quality, especially when the model cannot
always be solved to optimality. As a scientist writing a paper on a new model
(or, more likely, a new algorithm that internally uses a model), this will be
the default case as research on a problem that can already be solved well is
hard to publish. Whether you aim merely to evaluate whether your new approach
outperforms the current one or intend to prepare a formal scientific
publication, you face the same challenges; in the latter case, however, the
process becomes more extensive and formalized (but this may also be true for the
first case depending on your manager).

> [!WARNING]
>
> In some cases, the primary performance bottleneck may not lie within CP-SAT
> itself but rather in the **Python code used to generate the model**.
> Identifying the most resource-intensive segments of your Python code is
> therefore essential. The profiler
> [Scalene](https://github.com/plasma-umass/scalene) has proven to be
> particularly effective for pinpointing such issues. In many situations, simple
> logging statements (e.g.,
> `logging.info("Building circuit constraint on graph with %d nodes and %d edges", n, m)`)
> can also be sufficient to reveal fundamental performance problems. It is easy
> to underestimate the size or construction cost of auxiliary structures, which
> can have a significant impact on overall runtime.

During the explorative phase, when you probe different ideas, you will likely
select one to five instances that you can run quickly and compare. However, for
most applications, this number is insufficient, and you risk overfitting your
model to these instances — gaining performance improvements on them but
sacrificing performance on others. You may even limit your model’s ability to
solve certain instances.

A classic example involves deactivating specific CP-SAT search strategies or
preprocessing steps that have not yielded benefits on the selected instances. If
your instance set is large enough, the risk is low; however, if you have only a
few instances, you may remove the single strategy necessary to solve a
particular class of problems. Modern solvers include features that impose a
modest overhead on simple instances but enable solving otherwise intractable
cases. This trade-off is worthwhile: **do not sacrifice the ability to solve
complex instances for a marginal performance gain on simple ones**. Therefore,
always benchmark your changes properly before deploying them to production, even
if you do not plan to publish your results scientifically.

Note that this chapter focuses solely on improving the performance of your model
with respect to its specific formulation; it does not address the evaluation of
the model's accuracy or its business value. When tackling a real-world problem,
where your model is merely an approximation
[of reality](https://en.wikipedia.org/wiki/All_models_are_wrong), it is
essential to also consider refining the approximation and monitoring the
real-world performance of the resulting solutions. In some cases, simpler
formulations not only yield better outcomes but are also easier to optimize for.

### No-Free-Lunch Theorem and Timeouts

The **no‐free‐lunch theorem** and timeouts complicate benchmarking more than you
might have anticipated. The no‐free‐lunch theorem asserts that no single
algorithm outperforms all others across every instance, which is especially true
for NP‐hard problems. Consequently, improving performance on some instances
often coincides with degradations on others. It is essential to assess whether
the gains justify the losses.

Another challenge arises when imposing a time limit to prevent individual
instances from running indefinitely. Without such a limit, benchmark runs can
become prohibitively long. However, including aborted runs in the dataset
complicates performance evaluation, as it remains unclear whether a solver would
have found a solution shortly after the timeout or was trapped in an infinite
loop. Discarding all instances that timed out on a particular model restricts
the evaluation to simpler instances, even though the more complex ones are often
of greater interest. Conversely, discarding all models that timed out on any
instance may leave no viable candidates, as any solver is likely to fail on at
least one instance in a sufficiently large benchmark set. Whether the goal is to
find a provably optimal solution, the best solution within a fixed time limit,
or simply any feasible solution, it is essential to enable comparisons over data
sets that include unknown outcomes.

### Example: Nurse Rostering Problem Benchmark

Let us examine the performance of CP-SAT, Gurobi, and Hexaly on a Nurse
Rostering Problem to illustrate the additional challenge of selecting an
appropriate time limit. Nurse rostering is a complex yet common problem in which
nurses must be assigned to shifts while satisfying a variety of constraints.
Since CP-SAT, Gurobi, and Hexaly differ significantly in their underlying
algorithms, the comparison reveals pronounced performance differences. However,
such patterns can also be observed when using the same solver across instances,
albeit usually not as pronounced.

The following two plots illustrate the value of the incumbent solution (i.e.,
the best solution found so far) and the best proven lower bound during the
search. These are challenging instances, and only Gurobi is able to find an
optimal solution.

Notably, the best-performing solver changes depending on the allotted
computation time. For this problem, Hexaly excels at finding good initial
solutions quickly but tends to stall thereafter. CP-SAT requires slightly more
time to get started but demonstrates steady progress. In contrast, Gurobi begins
slowly but eventually makes substantial improvements.

So, which solver is best for this problem?

|                                                                                              ![NRP Instance 19](https://github.com/d-krupke/cpsat-primer/blob/main/images/nrp_19.png?raw=true)                                                                                               |
| :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: |
| Performance comparison of CP-SAT, Gurobi, and Hexaly on instance 19 of the Nurse Rostering Problem Benchmark. Hexaly starts strong but is eventually overtaken by CP-SAT. Gurobi surpasses Hexaly near the end by a small margin. CP-SAT and Gurobi converge to nearly the same lower bound. |

|                                                                                                                                                                               ![NRP Instance 20](https://github.com/d-krupke/cpsat-primer/blob/main/images/nrp_20.png?raw=true)                                                                                                                                                                               |
| :-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: |
| Performance comparison of CP-SAT, Gurobi, and Hexaly on instance 20 of the Nurse Rostering Problem Benchmark. Hexaly again performs well early but is outperformed by CP-SAT. Gurobi maintains a poor incumbent value for most of the runtime but eventually makes a significant improvement and proves optimality. The optimal solution is visibly superior to CP-SAT's best solution. CP-SAT is unable to prove a meaningful lower bound for this instance. |

> [!WARNING]
>
> These two plots (and even this specific problem) are insufficient to draw
> definitive conclusions about the overall performance of the solvers.
> Nevertheless, it is remarkable that our beloved open-source solver, CP-SAT,
> performs so well against the commercial solvers Gurobi and Hexaly in this
> context.

If provably optimal solutions are required, Gurobi may be the most suitable
choice; however, the likelihood of achieving optimality is low for most
instances. If your instances are expected to grow in size and require fast
solutions, Hexaly might be preferable, as it appears highly effective at finding
good solutions quickly. This observation is also supported by preliminary
results on larger instances, for which neither CP-SAT nor Gurobi find any
feasible solution. CP-SAT, by contrast, offers a strong compromise between the
two: although it starts more slowly, it maintains consistent progress throughout
the search.

> [!TIP]
>
> A commonly used metric for convergence is the
> [**primal integral**](https://www.sciencedirect.com/science/article/abs/pii/S0167637713001181),
> which measures the area under the curve of the incumbent solution value over
> time. It provides a single scalar that summarizes how quickly a solver
> improves its best-known solution. CP-SAT reports a related metric: the
> integral of the logarithm of the optimality gap, which also accounts for the
> quality of the bound. These metrics offer an objective measure of solver
> progress over time, though they may not fully capture problem-specific or
> subjective priorities.

### Defining Your Benchmarking Goals

The first step is to determine your specific requirements and how best to
measure solver performance accordingly. It is not feasible to manually plot
performance for every instance and assign scores based on subjective
impressions; such an approach does not scale and lacks objectivity and
reproducibility. Instead, you should define a concrete metric that accurately
reflects your goals. One strategy is to carefully select benchmark instances
that are still likely to be solved to optimality, with the expectation that
performance trends will generalize to larger instances. Another to decide for a
fixed time limit we are willing to wait for a solution, and then measure how
well each solver performs under these constraints. While no evaluation method
will be perfect, it is essential to remain aware of potential threats to the
validity of your results. Let us go through some common scenarios.

> [!NOTE]
>
> Empirical studies on algorithms have historically faced some tension within
> the academic community, where theoretical results are often viewed as more
> prestigious or fundamental. The paper
> _[Needed: An Empirical Science of Algorithms](https://pubsonline.informs.org/doi/epdf/10.1287/opre.42.2.201)_
> by John Hooker (1994) offers a valuable historical and philosophical
> perspective on this issue.

## Common Benchmarking Scenarios and Visualization Techniques

Several common benchmarking scenarios arise in practice. To select an
appropriate visualization or evaluation method, it is important to first
identify which scenario applies to your case and to recognize which tools are
better suited for other contexts. Avoid choosing the most visually appealing or
complex plot by default; instead, select the one that best serves your
analytical goals. Keep in mind that the primary purpose of a plot is to make
tabular data more accessible and easier to interpret. It does not replace the
underlying tables, nor does it provide definitive answers.

1. **Instances are always solved to optimality, and only runtime matters.** This
   is the simplest benchmarking scenario. If every instance can be solved to
   optimality and your only concern is runtime, you can summarize performance
   using the mean (relative) runtime or visualize it using a basic box plot. The
   primary challenge here lies in choosing the appropriate type of mean (e.g.,
   arithmetic, geometric, harmonic) and selecting representative instances that
   reflect production-like conditions. For this case, the rest of the chapter
   may be skipped.

2. **Optimal or feasible solutions are sought, but may not always be found
   within the time limit.** When timeouts occur, runtimes for unsolved instances
   become unknown, making traditional means unreliable. In such cases, **cactus
   plots** are an effective way to visualize solver performance, even in the
   presence of incomplete data.

3. **The goal is to find the best possible solution within a fixed time limit.**
   Here, the focus is on **solution quality under time constraints**, rather
   than on whether optimality is reached. **Performance plots** are especially
   suitable for this purpose, as they reveal how closely each solver or model
   approaches the best-known solution across the benchmark set.

4. **Scalability analysis: how performance evolves with instance size.** If you
   are analyzing how well a model scales, i.e., how large an instance it can
   solve to optimality and how the optimality gap grows thereafter, **split
   plots** are a good choice. They show runtime for solved instances and
   optimality gap for those that exceed the time limit, allowing for a unified
   view of scalability.

5. **Multi-metric performance comparison against a baseline.** When you want a
   quick, intuitive overview of how your model performs across several metrics,
   such as runtime, objective value, and lower bound, **scatter plots with
   performance zones** are ideal. They provide a clear comparative
   visualization, making it easy to spot outliers and trade-offs across
   dimensions.

> [!TIP]
>
> Use the
> [SIGPLAN Empirical Evaluation Checklist](https://raw.githubusercontent.com/SIGPLAN/empirical-evaluation/master/checklist/checklist.pdf)
> if your evaluation has to satisfy academic standards.

### Quickly Comparing to a Baseline Using Scatter Plots

Scatter plots with performance zones are, in my experience, highly effective for
quickly comparing the performance of a prototype against a baseline across
multiple metrics. While these plots do not provide a formal quantitative
evaluation, they offer a clear visual overview of how performance has shifted.
Their key advantages are their intuitive readability and their ability to
accommodate `NaN` values. They are particularly useful for identifying outliers,
though they can be less effective when too many points overlap or when data
ranges vary significantly (sometimes, a log scale can help here).

Consider the following example table, which compares a basic optimization model
with a prototype model in terms of runtime, objective value, and lower bound.
The runtime is capped at 90 seconds, and if no optimal solution is found within
this limit, the objective value is set to `NaN`. A run only terminates before
the time limit if an optimal solution is found.

<details><summary>Example Data</summary>

| instance_name | strategy  | runtime |   objective | lower_bound |
| :------------ | :-------- | ------: | ----------: | ----------: |
| att48         | Prototype | 89.8327 |       33522 |       33522 |
| att48         | Baseline  | 90.1308 |       33522 |       33369 |
| eil101        | Prototype | 90.0948 |         629 |         629 |
| eil101        | Baseline  | 43.8567 |         629 |         629 |
| eil51         | Prototype | 84.8225 |         426 |         426 |
| eil51         | Baseline  | 3.05334 |         426 |         426 |
| eil76         | Prototype | 90.2696 |         538 |         538 |
| eil76         | Baseline  | 4.09839 |         538 |         538 |
| gil262        | Prototype | 90.3314 |       13817 |        2368 |
| gil262        | Baseline  | 90.8782 |        3141 |        2240 |
| kroA100       | Prototype | 90.5127 |       21282 |       21282 |
| kroA100       | Baseline  | 90.0241 |       22037 |       20269 |
| kroA150       | Prototype |  90.531 |       27249 |       26420 |
| kroA150       | Baseline  | 90.3025 |       27777 |       24958 |
| kroA200       | Prototype | 90.0019 |      176678 |       29205 |
| kroA200       | Baseline  | 90.7658 |       32749 |       27467 |
| kroB100       | Prototype | 90.1334 |       22141 |       22141 |
| kroB100       | Baseline  | 90.5845 |       22729 |       21520 |
| kroB150       | Prototype | 90.7107 |      128751 |       26016 |
| kroB150       | Baseline  | 90.9659 |       26891 |       25142 |
| kroB200       | Prototype | 90.7931 |      183078 |       29334 |
| kroB200       | Baseline  | 90.3594 |       34481 |       27708 |
| kroC100       | Prototype | 90.5131 |       20749 |       20749 |
| kroC100       | Baseline  | 90.3035 |       21118 |       20125 |
| kroD100       | Prototype | 90.0728 |       21294 |       21294 |
| kroD100       | Baseline  | 90.2563 |       21294 |       20267 |
| kroE100       | Prototype | 90.4515 |       22068 |       22053 |
| kroE100       | Baseline  | 90.6112 |       22341 |       21626 |
| lin105        | Prototype | 90.4714 |       14379 |       14379 |
| lin105        | Baseline  | 90.6532 |       14379 |       13955 |
| lin318        | Prototype | 90.8489 |      282458 |       41384 |
| lin318        | Baseline  | 90.5955 |      103190 |       39016 |
| linhp318      | Prototype | 90.9566 |         nan |       41412 |
| linhp318      | Baseline  | 90.7038 |       84918 |       39016 |
| pr107         | Prototype | 90.3708 |       44303 |       44303 |
| pr107         | Baseline  | 90.4465 |       45114 |       27784 |
| pr124         | Prototype | 90.1689 |       59167 |       58879 |
| pr124         | Baseline  | 90.8673 |       60760 |       52392 |
| pr136         | Prototype | 90.0296 |       96781 |       96772 |
| pr136         | Baseline  | 90.2636 |       98850 |       89369 |
| pr144         | Prototype | 90.3141 |       58537 |       58492 |
| pr144         | Baseline  | 90.6465 |       59167 |       33809 |
| pr152         | Prototype | 90.4742 |       73682 |       73682 |
| pr152         | Baseline  | 90.8629 |       79325 |       46604 |
| pr226         | Prototype | 90.1845 | 1.19724e+06 |       74474 |
| pr226         | Baseline  | 90.6676 |      103271 |       55998 |
| pr264         | Prototype | 90.4012 |      736226 |       41020 |
| pr264         | Baseline  | 90.9642 |       68802 |       37175 |
| pr299         | Prototype | 90.3325 |         nan |       47375 |
| pr299         | Baseline  |   90.19 |      120489 |       45594 |
| pr439         | Prototype | 90.5761 |         nan |       95411 |
| pr439         | Baseline  |  90.459 |      834126 |       93868 |
| pr76          | Prototype | 90.2718 |      108159 |      107727 |
| pr76          | Baseline  | 90.2951 |      110331 |      105340 |
| st70          | Prototype | 90.2824 |         675 |         675 |
| st70          | Baseline  | 90.1484 |         675 |         663 |

</details>

From the table, we can already spot some fundamental issues. For example, the
prototype fails on three instances, and several instances yield significantly
worse results than the baseline. However, when we turn to the scatter plots with
performance zones, such anomalies become immediately apparent.

|                                                                                                                                              ![Scatter Plot with Performance Zones](https://raw.githubusercontent.com/d-krupke/cpsat-primer/main/images/scatter_tsp.png)                                                                                                                                              |
| :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: |
| Scatter plot comparing the performance of a prototype model against a baseline model across three metrics: runtime, objective value, and lower bound. The x-axis represents the baseline model's performance; the y-axis shows the prototype model's performance. Color-coded zones indicate relative performance levels, making it easier to identify where the prototype outperforms or underperforms the baseline. |

For runtime, both models typically hit the time limit, so there is limited
variation to observe. However, the baseline model solves a few instances
significantly faster, whereas the prototype consistently uses the full time
limit. For the objective value, both models produce similar results on most
instances. Yet, particularly on the larger instances, the prototype yields
either very poor or no solutions at all.

Interestingly, the lower bounds produced by the prototype are much better for
some instances. This improvement was not obvious from a cursory review of the
table but becomes immediately noticeable in the plots.

Scatter plots are also highly effective when working with multiple performance
metrics, particularly when you want to ensure that gains in one metric do not
come at the expense of unacceptable losses in another. In practice, it is often
difficult to precisely quantify the relative importance of each metric from the
outset. The intuitive nature of these plots offers a valuable overview, serving
as a visual aid before you commit to a specific performance metric. The example
below illustrates a hypothetical scenario involving a vehicle routing problem.

|                                                                                                                                                             ![Scatter Plot for Multi-Objectives](https://raw.githubusercontent.com/d-krupke/cpsat-primer/main/images/scatter_performance_zones.png)                                                                                                                                                              |
| :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: |
| Scatter plots illustrating performance trade-offs across multiple metrics in a hypothetical vehicle routing problem. These plots help assess whether improvements in one metric come at the cost of significant regressions in another. Their intuitive layout makes them especially useful when metric priorities are not yet clearly defined, offering a quick overview of relative performance and highlighting outliers across different algorithm versions. |

<details>
<summary>Here is the code I used to generate the plots. You can freely copy and use it.</summary>

```python
"""
This module contains functions to plot a scatter comparison of baseline and new values with performance areas highlighted.

You can freely use and distribute this code under the MIT license.

Changelog:
    2024-08-27: First version
    2024-08-29: Added lines to the diagonal to help with reading the plot
    2025-06-07: Basic improvements and fixing issue with index comparison.

(c) 2025 Dominik Krupke, https://github.com/d-krupke/cpsat-primer
"""

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd


def plot_performance_scatter(
    ax,
    baseline: pd.Series,
    new_values: pd.Series,
    lower_is_better: bool = True,
    title: str = "",
    **kwargs,
):
    """
    Plot a scatter comparison of baseline and new values with performance areas highlighted.

    Parameters:
        ax (matplotlib.axes.Axes): The axes on which to plot.
        baseline (pd.Series): Series of baseline values.
        new_values (pd.Series): Series of new values.
        lower_is_better (bool): If True, lower values indicate better performance.
        title (str): Title of the plot.
        **kwargs: Additional keyword arguments for customization (e.g., 'color', 'marker').
    """
    if not isinstance(baseline, pd.Series) or not isinstance(new_values, pd.Series):
        raise ValueError("Both baseline and new_values should be pandas Series.")
    if baseline.size != new_values.size:
        raise ValueError("Both Series should have the same length.")

    scatter_kwargs = {
        "color": kwargs.get("color", "blue"),
        "marker": kwargs.get("marker", "x"),
        "label": kwargs.get("label", "Data Points"),
    }

    line_kwargs = {
        "color": kwargs.get("line_color", "k"),
        "linestyle": kwargs.get("line_style", "--"),
        "label": kwargs.get("line_label", "No Change"),
    }

    fill_improve_kwargs = {
        "color": kwargs.get("improve_color", "green"),
        "alpha": kwargs.get("improve_alpha", 0.3),
        "label": kwargs.get("improve_label", "Improved Performance"),
    }

    fill_decline_kwargs = {
        "color": kwargs.get("decline_color", "red"),
        "alpha": kwargs.get("decline_alpha", 0.3),
        "label": kwargs.get("decline_label", "Declined Performance"),
    }

    # Replace inf values with NaN
    baseline = baseline.replace([np.inf, -np.inf], np.nan)
    new_values = new_values.replace([np.inf, -np.inf], np.nan)

    max_val = max(baseline.max(skipna=True), new_values.max(skipna=True)) * 1.05
    min_val = min(baseline.min(skipna=True), new_values.min(skipna=True)) * 0.95

    # get indices of NA values
    na_indices = baseline.isna() | new_values.isna()

    if lower_is_better:
        # replace NA values with max_val
        baseline = baseline.fillna(max_val)
        new_values = new_values.fillna(max_val)
    else:
        # replace NA values with min_val
        baseline = baseline.fillna(min_val)
        new_values = new_values.fillna(min_val)

    # plot the na_indices with a different marker
    if na_indices.any():
        ax.scatter(
            baseline[na_indices],
            new_values[na_indices],
            marker="s",
            color=scatter_kwargs["color"],
            label="N/A Values",
            zorder=2,
        )

    # add the rest of the data points
    ax.scatter(
        baseline[~na_indices], new_values[~na_indices], **scatter_kwargs, zorder=2
    )

    ax.plot([min_val, max_val], [min_val, max_val], zorder=1, **line_kwargs)

    x = np.linspace(min_val, max_val, 500)
    if lower_is_better:
        ax.fill_between(x, min_val, x, zorder=0, **fill_improve_kwargs)
        ax.fill_between(x, x, max_val, zorder=0, **fill_decline_kwargs)
    else:
        ax.fill_between(x, x, max_val, zorder=0, **fill_improve_kwargs)
        ax.fill_between(x, min_val, x, zorder=0, **fill_decline_kwargs)

    # draw thin lines to the diagonal to help with reading the plot.
    # A problem without lines is that one tends to use the distance
    # to the diagonal as a measure of performance, which is not correct.
    # Instead, it is `y-x` that should be used.
    for old_val, new_val in zip(baseline, new_values):
        if pd.isna(old_val) and pd.isna(new_val):
            continue
        if pd.isna(old_val):
            old_val = min_val if lower_is_better else max_val
        if pd.isna(new_val):
            new_val = min_val if lower_is_better else max_val
        if lower_is_better and new_val < old_val:
            ax.plot(
                [old_val, old_val],
                [old_val, new_val],
                color="green",
                linewidth=1.0,
                zorder=1,
            )
        elif not lower_is_better and new_val > old_val:
            ax.plot(
                [old_val, old_val],
                [old_val, new_val],
                color="green",
                linewidth=1.0,
                zorder=1,
            )
        elif lower_is_better and new_val > old_val:
            ax.plot(
                [old_val, old_val],
                [old_val, new_val],
                color="red",
                linewidth=1.0,
                zorder=1,
            )
        elif not lower_is_better and new_val < old_val:
            ax.plot(
                [old_val, old_val],
                [old_val, new_val],
                color="red",
                linewidth=1.0,
                zorder=1,
            )

    ax.set_xlim(min_val, max_val)
    ax.set_ylim(min_val, max_val)
    ax.set_xlabel(kwargs.get("xlabel", "Baseline"))
    ax.set_ylabel(kwargs.get("ylabel", "New Values"))
    if title:
        ax.set_title(title)
    ax.legend()


def plot_comparison_grid(
    baseline_data: pd.DataFrame,
    new_data: pd.DataFrame,
    metrics: list[tuple[str, str]],
    n_cols: int = 4,
    figsize: tuple[int, int] | None = None,
    suptitle: str = "",
    subplot_kwargs: dict | None = None,
    **kwargs,
):
    """
    Plot a grid of performance comparisons for multiple metrics.

    Parameters:
        baseline_data (pd.DataFrame): DataFrame containing the baseline data.
        new_data (pd.DataFrame): DataFrame containing the new data.
        metrics (list of tuple of str): List of tuples containing column names and comparison direction ('min' or 'max').
        n_cols (int): Number of columns in the grid.
        figsize (tuple of int): Figure size (width, height).
        suptitle (str): Title for the entire figure.
        **kwargs: Additional keyword arguments to pass to individual plot functions.

    Returns:
        fig (matplotlib.figure.Figure): The figure object containing the plots.
        axes (np.ndarray): Array of axes objects corresponding to the subplots.
    """
    n_metrics = len(metrics)
    n_cols = min(n_cols, n_metrics)
    n_rows = (n_metrics + n_cols - 1) // n_cols  # Ceiling division

    # Validate columns and directions
    for column, direction in metrics:
        if direction not in {"min", "max"}:
            raise ValueError("The direction should be either 'min' or 'max'.")
        if column not in baseline_data.columns or column not in new_data.columns:
            raise ValueError(f"Column '{column}' not found in the data.")

    # Validate index alignment
    if set(baseline_data.index) != set(new_data.index):
        raise ValueError("Indices of the DataFrames do not match (different values).")


    if figsize is None:
        figsize = (5 * n_cols, 5 * n_rows)

    fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)
    axes = axes.flatten()

    for ax, (column_name, direction) in zip(axes, metrics):
        # Merge kwargs and subplot_kwargs[column_name] (if present) into a new dict
        merged_kwargs = dict(kwargs)
        if subplot_kwargs and column_name in subplot_kwargs:
            merged_kwargs.update(subplot_kwargs[column_name])
        plot_performance_scatter(
            ax,
            baseline_data[column_name],
            new_data[column_name],
            lower_is_better=(direction == "min"),
            title=column_name,
            **merged_kwargs,
        )

    # Turn off any unused subplots
    for ax in axes[n_metrics:]:
        ax.axis("off")

    if suptitle:
        fig.suptitle(suptitle, fontsize=16)

    plt.tight_layout(rect=[0, 0, 1, 0.96])

    return fig, axes
```

</details>

### Success-Based Benchmarking: Cactus Plots and PAR Metrics

The SAT community frequently uses cactus plots (also known as survival plots) to
effectively compare the time to success of different solvers on a benchmark set,
even when timeouts occur. If you are dealing with a pure constraint satisfaction
problem, this approach is directly applicable. However, it can also be extended
to other binary success indicators — such as proving optimality, even under
optimality tolerances.

Additionally, the **PAR10** metric is commonly used to summarize solver
performance on a benchmark set. It is defined as the average time a solver takes
to solve an instance, where unsolved instances (within the time limit) are
penalized by assigning them a runtime equal to 10 times the cutoff. Variants
like **PAR2**, which use a penalty factor of 2 instead of 10, are also
encountered. While a factor of 10 is conventional, it remains an arbitrary
choice. Ultimately, you must decide how to handle unknowns (instances not solved
within the time limit) since you only know that their actual runtime exceeds the
cutoff. If an explicit performance metric is required to declare a winner,
PAR-style metrics are widely accepted but come with notable limitations.

To gain a more nuanced view of solver performance, **cactus plots** are often
employed. In these plots, each solver is represented by a line where each point
$(x, y)$ indicates that $y$ benchmark instances were solved within $x$ seconds
(there exists also the reversed version).

| ![Cactus Plot 1](https://github.com/d-krupke/cpsat-primer/blob/main/evaluations/tsp/2023-11-18_random_euclidean/PUBLIC_DATA/cactus_plot.png?raw=true) |
| :---------------------------------------------------------------------------------------------------------------------------------------------------: |
|                                     Each point $(x, y)$ shows that $x$ instances were solved within $y$ seconds.                                      |

The mean PAR10 scores for the four strategies in the example above are as
follows:

| Strategy             |       PAR10 |
| :------------------- | ----------: |
| AddCircuit           |  512.133506 |
| Dantzig (Gurobi)     |   66.452202 |
| Iterative Dantzig    |  752.412118 |
| Miller-Tucker-Zemlin | 1150.014846 |

In case you are wondering, this is some data on solving the Traveling Salesman
Problem (TSP) with different strategies. Gurobi dominates, but it is well-known
that Gurobi is excellent at solving TSP.

If the number of solvers or models under comparison is not too large, you can
also use a variation of the cactus plot to show solver performance under
different **optimality tolerances**. This allows you to examine how much
performance improves when the tolerance is relaxed. However, if your primary
interest lies in **solution quality**, performance plots are likely to be more
appropriate.

In the following example, different optimality tolerances reveal a visible
performance improvement for the strategies `AddCircuit` and
`Miller-Tucker-Zemlin`. For the other two strategies, the impact of tolerance
changes is minimal. This variation of the cactus plot can also be applied to
compare solver performance across different benchmark sets, especially if you
suspect significant variation across instance categories.

| ![Cactus Plot with Optimality Tolerances](https://github.com/d-krupke/cpsat-primer/blob/main/evaluations/tsp/2023-11-18_random_euclidean/PUBLIC_DATA/cactus_plot_opt_tol.png?raw=true) |
| :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: |
|             Each line style represents an optimality tolerance. The plot shows how many instances ($y$) can be solved within a given time limit ($x$) for each tolerance.              |

It is also common practice to include a **virtual best** line in the cactus
plot. This line indicates, for each instance, the best time achieved by any
solver. Although it does not represent an actual solver, it serves as a valuable
reference to evaluate the potential for solver complementarity. If one solver
clearly dominates, the virtual best line will coincide with its curve. However,
if the lines diverge, it suggests that no single solver is universally
superior—a case of the “no free lunch” principle. Even if one solver performs
best on 90% of instances, the remaining 10% may be better handled by
alternatives. The greater the gap between the best actual solver and the virtual
best, the stronger the case for a portfolio approach.

> [!NOTE]
>
> A more detailed discussion on this type of plot can be found in the referenced
> academic paper:
> [Benchmarking Solvers, SAT-style by Brain, Davenport, and Griggio](http://www.sc-square.org/CSA/workshop2-papers/RP3-FinalVersion.pdf)

### Performance Plots for Solution Quality within a Time Limit

When dealing with instances that typically cannot be solved to optimality,
**performance plots** are often more appropriate than cactus plots. These plots
illustrate the relative performance of different models or solvers on a set of
instances, usually under a fixed time limit. At the leftmost point of the plot
(where $x = 1$), each solver’s line indicates the proportion of instances for
which it achieved the best-known solution (not necessarily exclusively). Then
its $(x,y)$ coordinates indicate the proportion $y$ of instances for which the
solver achieved a solution that is at most $x$ times worse than the best known
solution. For example, if a solver has a point at $(1.05, 0.8)$, it means that
it found a solution within 5% of the best-known solution for 80% of the
instances. Often, a logarithmic scale is used for the x-axis, especially when
the performance ratios vary widely. However, down below we use a linear scale
because the values are close to 1.

In the example below, based on the **Capacitated Vehicle Routing Problem
(CVRP)**, the performance plots compare three different models across a
benchmark set. These plots offer a clear visual summary of how closely each
model approaches the best solution.

|                                                                                                                                 ![Performance Plot Objective](https://github.com/d-krupke/cpsat-primer/blob/main/images/performance_plot_objective.png?raw=true)                                                                                                                                  |
| :-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: |
| Performance plot comparing the objective values of different CVRP models on a benchmark set. The Miller–Tucker–Zemlin model performs best on most instances and remains close to the best on the rest. The other two models find the best solution in only about 10% of instances but solve roughly 70% within 2% of the best known solution, with `multiple_circuit` showing a slight advantage. |

This can of course also be done for the lower bounds produced by each model.

|                                                                               ![Performance Plot Lower Bound](https://github.com/d-krupke/cpsat-primer/blob/main/images/performance_plot_bound.png?raw=true)                                                                               |
| :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: |
| Performance plot comparing the lower bounds produced by each CVRP model. The `add_circuit` model consistently achieves the best bounds, while the other two models yield bounds that are up to 20% worse in the best case and up to 100% worse (i.e., half the quality) on some instances. |

<details>
<summary>Here is the code I used to generate the plots. You can freely copy and use it.</summary>

```python
# MIT License
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.axes import Axes


def plot_performance_profile(
    data: pd.DataFrame,
    instance_column: str,
    strategy_column: str,
    metric_column: str,
    direction: str,
    comparison: str = "relative",
    title: str | None = None,
    highlight_best: bool = False,
    ax: Axes | None = None,
    scale: str | None = None,
    log_base: int = 2,
    figsize: tuple = (9, 6),
) -> Axes:
    """
    Plot a performance profile, either on a relative-ratio basis or absolute-difference basis:
      - For comparison="relative":
          x-axis: performance ratio τ (log scale if τ_max > 10)
          τ = (value / best) if direction="min", or τ = (best / value) if direction="max".
      - For comparison="absolute":
          x-axis: absolute difference Δ = (value - best) if direction="min",
                                      or Δ = (best - value) if direction="max".
      - y-axis: proportion of problems with τ (or Δ) ≤ x for each solver.
      - If highlight_best=True, detect and bold the dominating solver curve (AUC in appropriate space).
      - Ensures a reasonable number of ticks on the x-axis.

    Args:
        data: DataFrame with columns [instance, strategy, metric].
        instance_column: column name identifying each problem instance.
        strategy_column: column name identifying each solver/strategy.
        metric_column: column name of the performance metric (e.g. runtime or cost).
        direction: "min" if lower metric → better, "max" if higher → better.
        comparison: "relative" or "absolute".
        title: Optional plot title.
        highlight_best: If True, find the solver with largest AUC and draw it in bold.
        ax: An existing matplotlib Axes to draw into. If None, a new Figure+Axes will be created using figsize.
        scale: x-axis scale override ("linear" or "log"); if None, chosen automatically.
        log_base: base for log scale if used (default 2).
        figsize: Tuple (width, height). Only used if ax is None.

    Returns:
        The matplotlib Axes containing the performance profile.
    """
    if direction not in ("min", "max"):
        raise ValueError("`direction` must be 'min' or 'max'.")
    if comparison not in ("relative", "absolute"):
        raise ValueError("`comparison` must be 'relative' or 'absolute'.")

    # 1) Compute best value per instance
    best_val = data.groupby(instance_column)[metric_column].agg(direction)

    # 2) Pivot to get per-instance × per-strategy medians
    pivot = (
        data.groupby([instance_column, strategy_column])[metric_column]
        .median()
        .unstack(fill_value=np.nan)
    )

    # 3) Build comparison matrix C[p, s]
    comp = pd.DataFrame(index=pivot.index, columns=pivot.columns, dtype=float)

    if comparison == "relative":
        for strat in pivot.columns:
            if direction == "min":
                comp[strat] = pivot[strat] / best_val
            else:  # direction == "max"
                comp[strat] = best_val / pivot[strat]
        comp = comp.replace([np.inf, -np.inf, 0.0], np.nan)

    else:  # comparison == "absolute"
        for strat in pivot.columns:
            if direction == "min":
                comp[strat] = pivot[strat] - best_val
            else:  # direction == "max"
                comp[strat] = best_val - pivot[strat]
        comp = comp.replace([np.inf, -np.inf], np.nan)

    # 4) Collect all distinct x-values (τ or Δ), including baseline
    all_vals = comp.values.flatten()
    finite_vals = all_vals[np.isfinite(all_vals)]
    baseline = 1.0 if comparison == "relative" else 0.0
    all_x = np.unique(np.sort(finite_vals))
    all_x = np.concatenate(([baseline], all_x))
    all_x = np.unique(np.sort(all_x))

    # 5) Build performance-profile DataFrame ρ(x)
    n_instances = comp.shape[0]
    profile = pd.DataFrame(index=all_x, columns=comp.columns, dtype=float)

    for x in all_x:
        leq = (comp <= x).sum(axis=0)
        profile.loc[x] = leq / n_instances

    # 6) Identify dominating solver if requested (max AUC)
    best_solver = None
    if highlight_best:
        if comparison == "relative":
            # integrate ρ(τ) w.r.t. log(τ)
            log_x = np.log(all_x)
            areas = {}
            for strat in profile.columns:
                y = profile[strat].astype(float).values
                areas[strat] = np.trapz(y, x=log_x)
            best_solver = max(areas, key=areas.get)
        else:
            # integrate ρ(Δ) w.r.t. Δ
            areas = {}
            for strat in profile.columns:
                y = profile[strat].astype(float).values
                areas[strat] = np.trapz(y, x=all_x)
            best_solver = max(areas, key=areas.get)

    # 7) Create or use existing Axes
    if ax is None:
        fig, ax = plt.subplots(figsize=figsize)
    else:
        fig = ax.figure

    # 8) Determine scale if not overridden
    if scale is None:
        if comparison == "relative" and all_x[-1] > 10:
            use_log = True
        else:
            use_log = False
    else:
        use_log = scale == "log"

    # 9) Plot each solver’s curve
    for strat in profile.columns:
        y = profile[strat].astype(float)
        if highlight_best and strat == best_solver:
            ax.step(all_x, y, where="post", label=strat, linewidth=3.0, alpha=1.0)
        else:
            ax.step(
                all_x,
                y,
                where="post",
                label=strat,
                linewidth=1.5,
                alpha=0.6 if highlight_best else 1.0,
            )

    # 10) Axis scaling and limits
    if comparison == "relative":
        if use_log:
            ax.set_xscale("log", base=log_base)
            ax.set_xlim(all_x[1], all_x[-1] * 1.1)
        else:
            ax.set_xscale("linear")
            ax.set_xlim(1.0, all_x[-1] * 1.1)
        xlabel = (
            f"Within this factor of the best (log{log_base} scale)"
            if use_log
            else "Within this factor of the best (linear scale)"
        )
    else:  # absolute
        ax.set_xscale("linear")
        ax.set_xlim(0.0, all_x[-1] * 1.1)
        xlabel = "Absolute difference from the best"

    ax.set_ylim(0.0, 1.02)
    ax.set_xlabel(xlabel, fontsize=12)
    ax.set_ylabel("Proportion of problems", fontsize=12)

    if title:
        ax.set_title(title, fontsize=14, pad=14)
    else:
        ax.set_title("Performance Profile", fontsize=14, pad=14)

    ax.axvline(x=baseline, color="gray", linestyle="--", alpha=0.7)
    ax.grid(True, which="both", linestyle=":", linewidth=0.5)

    # 11) Legend inside lower right
    ax.legend(loc="lower right", frameon=False)

    fig.tight_layout()
    return ax
```

</details>

> [!NOTE]
>
> Tangi Migot has written an excellent article on
> [Performance Plots](https://tmigot.github.io/posts/2024/06/teaching/). Also
> take a look on the original paper
> [Benchmarking optimization software with performance profiles (Dolan & Moré 2002)](https://link.springer.com/article/10.1007/s101070100263)

### Analyzing the Scalability of a Single Model

When working with a single model and aiming to analyze its **scalability**, a
**split plot** can serve as an effective visualization. This type of plot shows
the model’s runtime across instances of varying size, under a fixed time limit.
If an instance is solved within the time limit, its actual runtime is shown. If
not, the point is plotted above the time limit on a **transformed y-axis** that
now displays the **optimality gap** instead of runtime.

An example of such a plot is shown below. Since aggregating this data into a
line plot can be challenging, the visualization may become cluttered if too many
instances are included or if multiple models are compared simultaneously.

|                                                                                                  ![Split Plot](https://raw.githubusercontent.com/d-krupke/cpsat-primer/main/images/split_plot.png)                                                                                                   |
| :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: |
| Split plot illustrating runtime (for solved instances) and optimality gap (for unsolved instances). The y-axis is divided into two regions: one showing actual runtimes for instances solved within the time limit, and one showing optimality gaps for instances where the time limit was exceeded. |

> [!WARNING]
>
> For many problems, there is no single instance size metric to compare over.
> Usually, you can still classify the instances into size categories. However,
> for especially complex problems, it may be best to just provide a table with
> the results for the largest instances to give an idea of the model's
> scalability.

### Importance of Including Tables

Tables offer a concise and detailed view of benchmarking results. They allow
readers to verify the accuracy of reported data, inspect individual instances,
and complement high-level visual summaries such as plots.

While the previous sections presented insightful plots for visualizing
performance trends, it is essential to also include at least one table that
contains the raw results for the key benchmark instances. Many high-quality
papers rely solely on tables to present their results, as they provide
transparency and precision.

However, avoid including every table with all available data—this applies even
to appendices. Instead, consider what information a critical reader would need
to verify that your plots are not misleading. Focus on presenting the most
relevant and interpretable results. A comprehensive dataset can always be linked
in an external repository, but the tables within your paper should remain clear,
selective, and to the point. Even if you are only optimizing for yourself, use
plots to gain an overview but also check out the data tables.

|                                                       ![Table with Results](https://raw.githubusercontent.com/d-krupke/cpsat-primer/main/images/table_samplns.png)                                                        |
| :-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: |
| Example table from a recent publication, presenting detailed results of a new algorithm across benchmark instances. While less intuitive than plots, such tables enable readers to examine individual outcomes in detail. |

## Distinguishing Exploratory and Workhorse Studies in Benchmarking

Before diving into comprehensive benchmarking for scientific publications, it is
essential to conduct preliminary investigations to assess your model’s
capabilities and identify any foundational issues. This phase, known as
_exploratory studies_, is crucial for establishing the basis for more detailed
benchmarking, subsequently termed as _workhorse studies_. These latter studies
aim to provide reliable answers to specific research questions and are often the
core of academic publications. It is important to explicitly differentiate
between these two study types and maintain their distinct purposes: exploratory
studies for initial understanding and flexibility, and workhorse studies for
rigorous, reproducible research.

> [!NOTE]
>
> For a comprehensive exploration of benchmarking, I highly recommend Catherine
> C. McGeoch's book,
> ["A Guide to Experimental Algorithmics"](https://www.cambridge.org/core/books/guide-to-experimental-algorithmics/CDB0CB718F6250E0806C909E1D3D1082),
> which offers an in-depth discussion on this topic.

### Exploratory Studies: Foundation Building

Exploratory studies serve as a first step toward understanding both your model
and the problem it aims to solve. This phase is focused on building intuition
and identifying key characteristics before committing to formal benchmarking.

- **Objective**: The goal at this stage is to gain early insights — not to draw
  definitive conclusions. Exploratory studies help identify realistic instance
  sizes, anticipate potential challenges, and narrow down hyperparameter search
  spaces.

Avoid setting up elaborate benchmarking frameworks during this phase. Keep the
process lightweight and flexible to enable rapid iteration. If updating your
benchmarks becomes cumbersome each time you adjust your model, it will slow your
progress and — since benchmarking code tends to be tedious — you may lose
motivation quickly.

From personal experience, I observed a significant drop in productivity when I
first learned to build robust benchmarking setups. I began applying the same
level of rigor to exploratory phases, mistakenly treating the setup as a one-off
investment that would pay off in the long run. However, whenever you do
something genuinely interesting, unexpected issues inevitably arise, requiring
further iterations on the setup. In trying to anticipate such surprises, it
becomes tempting to over-engineer the process—spending excessive time
considering what could go wrong and preparing for every contingency, rather than
simply getting started.

Instead, strike a balance: avoid letting things become disorganized, but
postpone formal benchmarking until you are ready to share results. For example,
I used quick exploratory studies in a single jupyter notebook to estimate
appropriate instance sizes for the benchmark plots shown earlier. Not a reliable
part of a pipeline, but it got the job done quickly and only then I set up a
proper pipeline to create my final plots and tables.

### Workhorse Studies: Conducting In-depth Evaluations

Workhorse studies follow the exploratory phase and are characterized by more
structured and meticulous methodologies. This stage is essential for conducting
comprehensive evaluations of your model and collecting substantive data for
analysis.

- **Objective**: These studies aim to answer specific research questions and
  yield meaningful insights. The approach is methodical, emphasizing clearly
  defined objectives. Benchmarks should be well-structured and sufficiently
  large to produce statistically significant results.

While you can convert one of your exploratory studies into a workhorse study, I
strongly recommend starting the data collection process from scratch. Make it as
difficult as possible for outdated or flawed data to enter your benchmarking
setup.

Your exploratory studies should already have provided a reasonable estimate of
the required runtime for benchmarks. Always ensure that you allocate sufficient
time for potential failures and that your setup can resume if, for instance, a
colleague inadvertently terminates your job. Monitor the results while the
benchmarks are running—you do not want to wait a week only to discover that you
forgot to save the solutions.

I personally structure a workhorse study as follows:

1. **Hypothesis or Research Question** Clearly define a hypothesis or research
   question that emerged during the exploratory phase.

2. **Experiment Design** Develop a detailed experimental plan, including the
   instance set, the models/configurations to be evaluated, and the metrics to
   be collected.

3. **Benchmark Setup** Implement a robust benchmarking framework that supports
   reproducibility and efficient execution.

4. **Data Collection** Execute the experiments, ensuring that all relevant data
   is collected and stored in a structured and reliable format.

5. **Data Analysis** Analyze the results using appropriate statistical and
   visualization techniques.

6. **Discussion of Findings** Interpret the results and discuss their
   implications in the context of the initial hypothesis or research question.

7. **Threats to Validity** Reflect on potential threats to the validity of your
   findings, such as biases in instance selection, model assumptions, or
   evaluation procedures.

## Selecting a Benchmark Instance Set

Constructing a benchmark instance set is often more challenging than it first
appears, especially when no established benchmarks exist. Even when such sets
exist, they may be poorly sized or less realistic than anticipated. In fact,
some seemingly realistic datasets may have had portions of the original data
replaced with uniformly random values to preserve confidentiality, often without
realizing that such modifications can substantially alter the problem's
characteristics. Crafting a high-quality benchmark instance set can be an art in
itself. A notable example is the
[MIPLIB collection](https://link.springer.com/article/10.1007/s12532-020-00194-3),
which stands as a scientific contribution in its own right.

If you already have a deployed implementation, the process is fortunately quite
straightforward. You can collect the instances that have been solved in the past
and use them (or a representative subset) as your benchmark set. Performing
basic data analysis to examine the distribution of instance characteristics is
advisable; for example, it may turn out that 99% of the instances are trivial,
while the remaining 1% are significantly more challenging and thus more relevant
for improvement. In most cases, basic domain knowledge and judgment are often
sufficient to construct a useful benchmark set without the need for particularly
creative solutions.

If you are not in this fortunate position, the first step is to check whether
any public data is available for your problem or for a sufficiently similar one.
For instance, although the widely used
[TSPLIB](http://comopt.ifi.uni-heidelberg.de/software/TSPLIB95/) benchmark set
for the Traveling Salesman Problem (TSP) contains only distance information, it
is relatively straightforward to generate Capacitated Vehicle Routing Problem
(CVRP) instances from it, allowing the reuse of well-structured and challenging
inputs for a related problem. This can be done by randomly selecting a depot and
assigning a vehicle capacity based on a fraction of a heuristic TSP solution. If
you obtain readily available instances, be sure to verify whether they remain
challenging; they may originate from a different era or may not have been
well-designed, as not everything published online is of high quality (although I
hope that this Primer is).

If no suitable public benchmarks are available, you will need to generate your
own instances. Even with public benchmarks available, generating your own
instances can still be beneficial to generate additional instances in order to
control specific parameters and systematically evaluate the impact of varying a
single factor on your model's performance. In typical benchmark sets, the
diverse instances can confound the effects of individual parameters, making it
difficult to isolate their impact without large datasets and careful statistical
design. Nevertheless, it is important to maintain diversity within your general
instance set to ensure that your model remains robust and capable of handling a
broad range of scenarios.

> [!TIP]
>
> To deepen your understanding of benchmark instance diversity, consider the
> concept of **Instance Space Analysis**. Kate Smith-Miles offers an insightful
> [30-minute talk on this topic](https://www.youtube.com/watch?v=-2t2c9-snf0),
> exploring how analyzing the space of instances can guide better instance
> selection and generation.

When implementing your own instance generation, it is often possible to leverage
existing tools. For example,
[NetworkX provides a comprehensive collection of random graph generators](https://networkx.org/documentation/stable/reference/generators.html)
that can be adapted to suit a variety of problem settings. An exploratory study
is usually necessary to identify which generator aligns best with the
requirements of your specific problem. For generating other types of values, you
can experiment with different random distributions. One particularly effective
technique is using images to define spatial or value distributions, for example,
treating pixel intensities as sampling probabilities.

> [!TIP]
>
> It is also advisable not to combine all your instances into a single set, but
> instead to evaluate performance separately across different benchmark groups.
> This approach often reveals interesting and meaningful performance
> differences.

A final point worth emphasizing is the importance of generating and storing
proper instance files, rather than relying solely on the seed of a pseudo-random
number generator. This is a recurring concern I have encountered with both
experienced peers and students. While pseudo-random generators are valuable for
introducing randomized but reproducible elements into algorithms, they are not a
substitute for persistently stored data. (That said, I have seen too many cases
where a student unknowingly computed the mean over multiple runs using the same
seed.) Although, in theory, a seed combined with the source code should suffice
to reproduce a complete experiment, in practice, code tends to degrade more
quickly than data. This is especially true for C++ code, which may be less
reproducible than anticipated due to subtle instances of undefined behavior,
even among experienced programmers.

## Efficiently Managing Your Benchmarks

Benchmark data management can quickly become complex, especially when managing
multiple experiments and research questions simultaneously. The following
strategies can help maintain an organized workflow and ensure that your results
remain reliable:

- **Folder Structure:** Maintain a clear and consistent folder hierarchy for
  your experiments. A typical setup includes a top-level `evaluations` directory
  with descriptive subfolders for each experiment. For example:

  ```
  evaluations
  ├── tsp
  │   ├── 2023-11-18_random_euclidean
  │   │   ├── PRIVATE_DATA
  │   │   │   ├── ... all data for debugging and internal use
  │   │   ├── PUBLIC_DATA
  │   │   │   ├── ... curated data intended for sharing
  │   │   ├── _utils               # optional
  │   │   │   ├── ... shared utility functions to keep top level clean
  │   │   ├── README.md            # Brief description of the experiment
  │   │   ├── 00_generate_instances.py
  │   │   ├── 01_run_experiments.py
  │   │   ├── ...
  │   ├── 2023-11-18_tsplib
  │   │   ├── PRIVATE_DATA
  │   │   │   ├── ... debugging data
  │   │   ├── PUBLIC_DATA
  │   │   │   ├── ... selected shareable data
  │   │   ├── README.md
  │   │   ├── 01_run_experiments.py
  │   │   ├── ...
  ```

- **Documentation:** It is easy to forget why or when a particular experiment
  was conducted. Always include a brief `README.md` file with essential notes.
  This document does not need to be polished initially, but it should capture
  the core context. The more important the experiment, the more beneficial it is
  to revisit and enhance the documentation once the experiment is underway and
  you have had time to reflect on its purpose and outcomes.

- **Redundancy:** Excessive concern about redundancy in your data and code is
  generally unnecessary. Evaluation setups are not production systems and are
  not expected to be maintained over the long term. In fact, redundancy,
  particularly in utility functions, can simplify refactoring. Legacy
  experiments can continue using older versions of the code, and updates can be
  applied selectively. It is advisable to include a brief changelog in each
  utility file to indicate the version in use. Consider this a lightweight form
  of dependency management. Although copying and pasting code may feel
  inappropriate to a software engineer trained in best practices, this portion
  of your work is typically intended to be static for reproducibility, rather
  than actively maintained.

- **Extensive Private and Simple Public Data:** Organize your data into two
  sections: one for private use and one for public dissemination. The private
  section should contain all raw and intermediate data to facilitate future
  investigations into anomalies or unexpected behavior. The public section
  should be concise, curated, and optimized for analysis and sharing. If the
  private data grows too large, consider transferring it to external storage and
  leaving a reference or note indicating its location, ideally with the hope
  that it will not be needed again. If your experiments are not huge, you may
  also be able to store all data in the public section.

- **Experiment Flexibility:** Design experiments to be both interruptible and
  extensible. This allows long-running studies to be paused and resumed, and new
  models or configurations to be added without restarting the entire process.
  Such flexibility is particularly valuable in exploratory research, which often
  involves frequent iterations, as well as in large-scale, long-duration runs.
  The longer an experiment runs, the more likely it is that it will be
  interrupted by system updates, network failures, or other unforeseen events.

- **Parallelization:** Obtaining results quickly can help maintain momentum and
  focus. Learn to utilize a computing cluster or cloud infrastructure to
  parallelize experiments. Although there is an initial learning curve, the
  effort required to implement parallelization is usually small in comparison to
  the efficiency gains it provides.

> [!TIP]
>
> Because existing tools did not fully satisfy my requirements, I developed
> [AlgBench](https://github.com/d-krupke/AlgBench) to manage benchmarking
> results and [Slurminade](https://github.com/d-krupke/slurminade) to simplify
> experiment distribution on computing clusters through a decorator-based
> interface. However, more effective solutions may now be available,
> particularly from the machine learning community. If you are aware of tools
> you find useful, I would be very interested in hearing about them and would be
> glad to explore their potential.

<!-- This file was generated by the `build.py` script. Do not edit it manually. -->
<!-- ./chapters/09_lns.md -->
<!-- EDIT THIS PART VIA 08_lns.md -->

<a name="09-lns"></a>

## Using CP-SAT for Bigger Problems with Large Neighborhood Search


CP-SAT is great at solving small and medium-sized problems. But what if you have
a really big problem on your hands? One option might be to use a special kind of
algorithm known as a "meta-heuristic", like a
[genetic algorithm](https://en.wikipedia.org/wiki/Genetic_algorithm). But these
can be hard to set up and might not even give you good results.

Sometimes you will see new algorithms with cool-sounding names in scientific
papers. While tempting, these are often just small twists on older methods and
might leave out key details that make them work. If you are interested, there's
a discussion about this issue in a paper by Sörensen, called
["Metaheuristics – The Metaphor Exposed"](http://onlinelibrary.wiley.com/doi/10.1111/itor.12001).

The good news? You do not have to implement an algorithm that simulates the
mating behavior of forest frogs to solve your problem. If you already know how
to use CP-SAT, you can stick with it to solve big problems without adding
unnecessary complications. Even better? This technique, called Large
Neighborhood Search, often outperforms all other approaches.

### What Sets Large Neighborhood Search Apart?

Many traditional methods generate several "neighbor" options around an existing
solution and pick the best one. However, making each neighbor solution takes
time, limiting how many you can examine.

Large Neighborhood Search (LNS) offers a more efficient approach. Instead of
generating neighbors one by one, LNS formulates a "mini-problem" that modifies
parts of the current solution. This often involves randomly selecting some
variables, resetting them, and using CP-SAT (or a similar tool) to find the
optimal new values within the context of the remaining solution. This method,
known as "destroy and repair," allows for a broader exploration of neighbor
solutions without constructing each one individually.

Moreover, LNS can easily be mixed with other methods like genetic algorithms. If
you are already using a genetic algorithm, you could supercharge it by applying
CP-SAT to find the best possible crossover of two or more existing solutions. It
is like genetic engineering, but without any ethical worries!

When looking into the logs of CP-SAT, you may notice that it uses LNS itself to
find better solutions.

```
8 incomplete subsolvers: [feasibility_pump, graph_arc_lns, graph_cst_lns, graph_dec_lns, graph_var_lns, rins/rens, rnd_cst_lns, rnd_var_lns]
```

Why does it not suffice to just run CP-SAT if it already solves the problem with
LNS? The reason is that CP-SAT has to be relatively problem-agnostic. It has no
way of knowing the structure of your problem and thus cannot use this
information to improve the search. You on the other hand know a lot about your
problem and can use this knowledge to implement a more efficient version.

**Literature:**

- General Paper on LNS-variants:
  [Pisinger and Ropke - 2010](https://backend.orbit.dtu.dk/ws/portalfiles/portal/5293785/Pisinger.pdf)
- A generic variant (RINS), that is also used by CP-SAT:
  [Danna et al. 2005](https://link.springer.com/article/10.1007/s10107-004-0518-7)

We will now look into some examples to see this approach in action.

#### Example 1: Knapsack

You are given a knapsack that can carry a certain weight limit $C$, and you have
various items $I$ you can put into it. Each item $i\in I$ has a weight $w_i$ and
a value $v_i$. The goal is to pick items to maximize the total value while
staying within the weight limit.

```math
\max \sum_{i \in I} v_i x_i
```

```math
\text{s.t.} \sum_{i \in I} w_i x_i \leq C
```

```math
x_i \in \\{0,1\\}
```

This is one of the simplest NP-hard problems and can be solved with a dynamic
programming approach in pseudo-polynomial time. CP-SAT is also able to solve
many large instances of this problem in an instant. However, its simple
structure makes it a good example to demonstrate the use of Large Neighborhood
Search, even if the algorithm will not be of much use for this problem.

A simple idea for the LNS is to delete some elements from the current solution,
compute the remaining capacity after deletion, select some additional items from
the remaining items, and try to find the optimal solution to fill the remaining
capacity with the deleted items and the newly selected items. Repeat this until
you are happy with the solution quality. The number of items you delete and
select can be fixed such that the problem can be easily solved by CP-SAT. You
can find a full implementation under
[examples/lns_knapsack.ipynb](https://github.com/d-krupke/cpsat-primer/blob/main/examples/lns_knapsack.ipynb).

Let us look only on an example here:

Instance: $C=151$,
$I=I_{0}(w=12, v=37),I_{1}(w=16, v=49),I_{2}(w=20, v=53),I_{3}(w=11, v=14),I_{4}(w=19, v=42),$
$\quad I_{5}(w=13, v=53),I_{6}(w=18, v=54),I_{7}(w=16, v=56),I_{8}(w=14, v=45),I_{9}(w=12, v=39),$
$\quad I_{10}(w=11, v=42),I_{11}(w=19, v=43),I_{12}(w=12, v=43),I_{13}(w=19, v=66),I_{14}(w=20, v=54),$
$\quad I_{15}(w=13, v=54),I_{16}(w=12, v=33),I_{17}(w=12, v=38),I_{18}(w=14, v=43),I_{19}(w=15, v=28),$
$\quad I_{20}(w=11, v=47),I_{21}(w=10, v=31),I_{22}(w=20, v=97),I_{23}(w=10, v=35),I_{24}(w=19, v=56),$
$\quad I_{25}(w=11, v=33),I_{26}(w=12, v=38),I_{27}(w=15, v=45),I_{28}(w=17, v=58),I_{29}(w=11, v=48),$
$\quad I_{30}(w=15, v=32),I_{31}(w=17, v=67),I_{32}(w=15, v=43),I_{33}(w=16, v=41),I_{34}(w=18, v=42),$
$\quad I_{35}(w=14, v=44),I_{36}(w=20, v=45),I_{37}(w=13, v=50),I_{38}(w=17, v=57),I_{39}(w=17, v=33),$
$\quad I_{40}(w=17, v=49),I_{41}(w=12, v=21),I_{42}(w=14, v=37),I_{43}(w=20, v=74),I_{44}(w=14, v=55),$
$\quad I_{45}(w=10, v=25),I_{46}(w=16, v=26),I_{47}(w=10, v=37),I_{48}(w=18, v=63),I_{49}(w=16, v=39),$
$\quad I_{50}(w=16, v=57),I_{51}(w=16, v=47),I_{52}(w=10, v=43),I_{53}(w=12, v=30),I_{54}(w=12, v=40),$
$\quad I_{55}(w=19, v=48),I_{56}(w=12, v=39),I_{57}(w=14, v=43),I_{58}(w=17, v=35),I_{59}(w=19, v=51),$
$\quad I_{60}(w=16, v=48),I_{61}(w=19, v=72),I_{62}(w=16, v=45),I_{63}(w=19, v=88),I_{64}(w=15, v=20),$
$\quad I_{65}(w=17, v=49),I_{66}(w=14, v=40),I_{67}(w=14, v=27),I_{68}(w=19, v=51),I_{69}(w=10, v=37),$
$\quad I_{70}(w=15, v=42),I_{71}(w=13, v=29),I_{72}(w=20, v=87),I_{73}(w=13, v=28),I_{74}(w=15, v=38),$
$\quad I_{75}(w=19, v=77),I_{76}(w=13, v=35),I_{77}(w=17, v=55),I_{78}(w=13, v=39),I_{79}(w=10, v=26),$
$\quad I_{80}(w=15, v=32),I_{81}(w=12, v=40),I_{82}(w=11, v=21),I_{83}(w=18, v=82),I_{84}(w=13, v=41),$
$\quad I_{85}(w=12, v=27),I_{86}(w=15, v=35),I_{87}(w=18, v=48),I_{88}(w=15, v=64),I_{89}(w=19, v=62),$
$\quad I_{90}(w=20, v=64),I_{91}(w=13, v=45),I_{92}(w=19, v=64),I_{93}(w=18, v=83),I_{94}(w=11, v=38),$
$\quad I_{95}(w=10, v=30),I_{96}(w=18, v=65),I_{97}(w=19, v=56),I_{98}(w=12, v=41),I_{99}(w=17, v=36)$

Initial solution of value 442:
$\\{I_{0}, I_{1}, I_{2}, I_{3}, I_{4}, I_{5}, I_{6}, I_{7}, I_{8}, I_{9}\\}$

We will now repeatedly delete 5 items from the current solution and try to fill
the newly gained capacity with an optimal solution built from the deleted items
and 10 additional items. Note that this approach essentially considers
$2^{5+10}=32768$ neighbored solutions in each iteration. However, we could
easily scale it up to consider $2^{100+900}\sim 10^{300}$ neighbored solutions
in each iteration thanks to the implicit representation of the neighbored
solutions and CP-SAT ability to prune large parts of the search space.

**Round 1 of LNS algorithm:**

- Deleting the following 5 items from the solution:
  $\\{I_{0}, I_{7}, I_{8}, I_{9}, I_{6}\\}$
- Repairing solution by considering the following subproblem:
  - Subproblem: $C=72$,
    $I=\\{I_{6},I_{9},I_{86},I_{13},I_{47},I_{73},I_{0},I_{8},I_{7},I_{38},I_{57},I_{11},I_{60},I_{14}\\}$
- Computed the following solution of value 244 for the subproblem:
  $\\{I_{8}, I_{9}, I_{13}, I_{38}, I_{47}\\}$
- Combining
  $\\{I_{1}, I_{2}, I_{3}, I_{4}, I_{5}\\}\cup \\{I_{8}, I_{9}, I_{13}, I_{38}, I_{47}\\}$
- New solution of value 455:
  $\\{I_{1}, I_{2}, I_{3}, I_{4}, I_{5}, I_{8}, I_{9}, I_{13}, I_{38}, I_{47}\\}$

**Round 2 of LNS algorithm:**

- Deleting the following 5 items from the solution:
  $\\{I_{3}, I_{13}, I_{2}, I_{9}, I_{1}\\}$
- Repairing solution by considering the following subproblem:
  - Subproblem: $C=78$,
    $I=\\{I_{13},I_{9},I_{84},I_{41},I_{15},I_{42},I_{74},I_{16},I_{3},I_{1},I_{2},I_{67},I_{50},I_{89},I_{43}\\}$
- Computed the following solution of value 275 for the subproblem:
  $\\{I_{1}, I_{15}, I_{43}, I_{50}, I_{84}\\}$
- Combining
  $\\{I_{4}, I_{5}, I_{8}, I_{38}, I_{47}\\}\cup \\{I_{1}, I_{15}, I_{43}, I_{50}, I_{84}\\}$
- New solution of value 509:
  $\\{I_{1}, I_{4}, I_{5}, I_{8}, I_{15}, I_{38}, I_{43}, I_{47}, I_{50}, I_{84}\\}$

**Round 3 of LNS algorithm:**

- Deleting the following 5 items from the solution:
  $\\{I_{8}, I_{43}, I_{84}, I_{1}, I_{50}\\}$
- Repairing solution by considering the following subproblem:
  - Subproblem: $C=79$,
    $I=\\{I_{84},I_{76},I_{34},I_{16},I_{37},I_{20},I_{8},I_{43},I_{50},I_{1},I_{12},I_{35},I_{53}\\}$
- Computed the following solution of value 283 for the subproblem:
  $\\{I_{8}, I_{12}, I_{20}, I_{37}, I_{50}, I_{84}\\}$
- Combining
  $\\{I_{4}, I_{5}, I_{15}, I_{38}, I_{47}\\}\cup \\{I_{8}, I_{12}, I_{20}, I_{37}, I_{50}, I_{84}\\}$
- New solution of value 526:
  $\\{I_{4}, I_{5}, I_{8}, I_{12}, I_{15}, I_{20}, I_{37}, I_{38}, I_{47}, I_{50}, I_{84}\\}$

**Round 4 of LNS algorithm:**

- Deleting the following 5 items from the solution:
  $\\{I_{37}, I_{4}, I_{20}, I_{5}, I_{15}\\}$
- Repairing solution by considering the following subproblem:
  - Subproblem: $C=69$,
    $I=\\{I_{37},I_{4},I_{20},I_{15},I_{82},I_{41},I_{56},I_{76},I_{85},I_{5},I_{32},I_{57},I_{7},I_{67}\\}$
- Computed the following solution of value 260 for the subproblem:
  $\\{I_{5}, I_{7}, I_{15}, I_{20}, I_{37}\\}$
- Combining
  $\\{I_{8}, I_{12}, I_{38}, I_{47}, I_{50}, I_{84}\\}\cup \\{I_{5}, I_{7}, I_{15}, I_{20}, I_{37}\\}$
- New solution of value 540:
  $\\{I_{5}, I_{7}, I_{8}, I_{12}, I_{15}, I_{20}, I_{37}, I_{38}, I_{47}, I_{50}, I_{84}\\}$

**Round 5 of LNS algorithm:**

- Deleting the following 5 items from the solution:
  $\\{I_{38}, I_{12}, I_{20}, I_{47}, I_{37}\\}$
- Repairing solution by considering the following subproblem:
  - Subproblem: $C=66$,
    $I=\\{I_{20},I_{47},I_{37},I_{86},I_{58},I_{56},I_{54},I_{38},I_{12},I_{39},I_{68},I_{75},I_{66},I_{2},I_{99}\\}$
- Computed the following solution of value 254 for the subproblem:
  $\\{I_{12}, I_{20}, I_{37}, I_{47}, I_{75}\\}$
- Combining
  $\\{I_{5}, I_{7}, I_{8}, I_{15}, I_{50}, I_{84}\\}\cup \\{I_{12}, I_{20}, I_{37}, I_{47}, I_{75}\\}$
- New solution of value 560:
  $\\{I_{5}, I_{7}, I_{8}, I_{12}, I_{15}, I_{20}, I_{37}, I_{47}, I_{50}, I_{75}, I_{84}\\}$

#### Example 2: Different Neighborhoods for the Traveling Salesman Problem

Simply removing a portion of the solution and then trying to fix it is not the
most effective approach. In this section, we will explore various neighborhoods
for the Traveling Salesman Problem (TSP). The geometry of TSP not only permits
advantageous neighborhoods but also offers visually appealing representations.
When you have several neighborhood strategies, they can be dynamically
integrated using an Adaptive Large Neighborhood Search (ALNS).

The image illustrates an optimization process for a tour that needs to traverse
the green areas, factoring in turn costs, within an embedded graph (mesh). The
optimization involves choosing specific regions (highlighted in red) and
calculating the optimal tour within them. As iterations progress, the initial
tour generally improves, although some iterations may not yield any enhancement.
Regions in red are selected due to the high cost of the tour within them. Once
optimized, the center of that region is added to a tabu list, preventing it from
being chosen again.

|                                                                   ![Large Neighborhood Search Geometry Example](https://github.com/d-krupke/cpsat-primer/blob/main/images/lns_pcpp.png)                                                                   |
| :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: |
| Large Neighbordhood Search for Coverage Path Planning by repeatedly selecting a geometric region (red) and optimizing the tour within it. The red parts of the tour highlight the changes in the iteration. Read from left to right, and from up to down. |

How can you determine the appropriate size of a region to select? You have two
main options: conduct preliminary experiments or adjust the size adaptively
during the search. Simply allocate a time limit for each iteration. If the
solver does not optimize within that timeframe, decrease the region size.
Conversely, if it does, increase the size. Utilizing exponential factors will
help the size swiftly converge to its optimal dimension. However, it's essential
to note that this method assumes subproblems are of comparable difficulty and
may necessitate additional conditions.

For the Euclidean TSP, as opposed to a mesh, optimizing regions is not
straightforward. Multiple effective strategies exist, such as employing a
segment from the previous tour rather than a geometric region. By implementing
various neighborhoods and evaluating their success rates, you can allocate a
higher selection probability to the top-performing ones. This approach is
demonstrated in an animation crafted by two of my students, Gabriel Gehrke and
Laurenz Illner. They incorporated four distinct neighborhoods and utilized ALNS
to dynamically select the most effective one.

|                                                                                                                                                                         ![ALNS TSP](https://github.com/d-krupke/cpsat-primer/blob/main/images/alns_tsp_compr.gif)                                                                                                                                                                         |
| :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: |
| Animation of an Adaptive Large Neighborhood Search for the classical Traveling Salesman Problem. It uses four different neighborhood strategies which are selected randomly with a probability based on their success rate in previous iterations. If you check the logs of the latest (v9.8) version of CP-SAT, it also rates the performance of its LNS-strategies and uses the best performing strategies more often (UCB1-algorithm). |

#### Multi-Armed Bandit: Exploration vs. Exploitation

Having multiple strategies for each iteration of your Large Neighborhood Search
(LNS) is beneficial, but how do you decide which one to use? While you could
select a strategy at random, this approach is inefficient because it is unlikely
to choose the best one. Alternatively, you could stick to the strategy that
performed well in the past, but there may be a better option you have not tried
yet. This brings us to the classic exploration vs. exploitation dilemma. On one
hand, you want to exploit strategies that have proven successful, but on the
other, you need to explore new strategies to discover potentially better ones.

Fortunately, this issue has been widely studied as the
[Multi-Armed Bandit Problem](https://en.wikipedia.org/wiki/Multi-armed_bandit),
and there are numerous effective solutions available. One popular approach is
the Upper Confidence Bound (UCB1) algorithm. I wanted to highlight this dilemma
to make you aware that many experts have already tackled it and developed
sophisticated strategies.

In practice, CP-SAT schedules its LNS strategies using a simple round-robin
method, as reflected by their equal number of calls in the logs. Whenever a
worker thread finishes its work, it will execute an iteration with the next
strategy in the list, leading to a fair distribution of calls. In this case, we
can see that the `'routing_path_lns'` strategy was the most successful,
improving the incumbent solution 41 times out of 65 calls. There might be room
for performance improvements by employing a more advanced strategy selection
algorithm. However, it is important to recognize the relatively low number of
calls to each strategy in combination with diminishing and noisy returns. If you
only have a few iterations, a more advanced algorithm may not have enough data
to make reliable decisions.

```
LNS stats                Improv/Calls  Closed  Difficulty  TimeLimit
       'graph_arc_lns':          5/65     49%        0.26       0.10
       'graph_cst_lns':          4/65     54%        0.47       0.10
       'graph_dec_lns':          3/65     49%        0.26       0.10
       'graph_var_lns':          4/66     55%        0.56       0.10
           'rins/rens':         23/66     39%        0.03       0.10
         'rnd_cst_lns':         12/66     50%        0.19       0.10
         'rnd_var_lns':          6/66     52%        0.36       0.10
    'routing_path_lns':         41/65     48%        0.10       0.10
  'routing_random_lns':         24/65     52%        0.26       0.10
```

> [!TIP]
>
> We have found the following simple procedure effective:
>
> - Begin with a strategy optimized for low-hanging fruit, i.e., a relatively
>   fast-converging method.
> - If progress stalls, randomly select a new strategy from your predefined
>   pool.
>
> Predicting the optimal strategy at each stage is challenging as the best
> strategy changes during the search, and may not be worth the effort. This
> simple approach exploits a working strategy until it stalls, then explores a
> new one, automatically favoring strategies that yield progress. To avoid
> fixation on a slowly converging method, optionally enforce a switch after a
> predetermined number of iterations.

<!-- This file was generated by the `build.py` script. Do not edit it manually. -->
<!-- ./chapters/mathopt.md -->
## MathOpt as a Modeling Layer

<a name="chapters-mathopt"></a>

Google OR-Tools recently introduced a new modeling layer called
[MathOpt](https://developers.google.com/optimization/math_opt). It provides a
solver-agnostic API for defining and solving mathematical optimization problems,
especially linear programs (LPs) and mixed-integer programs (MIPs). It is meant
as a simpler and more modern alternative to the older `pywraplp` interface, with
a stronger focus on usability and performance.

This is exciting because many optimization problems can naturally be formulated
as LPs or MIPs, and CP-SAT is not always the right tool for those. As discussed
earlier, working with continuous variables and coefficients in CP-SAT is not
very convenient, since they have to be discretized carefully. With MathOpt, you
can directly use continuous variables and floating-point coefficients when using
a solver that supports them (for example, HiGHS or Gurobi). For certain types of
problems, LP/MIP solvers can also be much more efficient than CP-SAT. When you
model your problem with MathOpt, you can easily switch between different solvers
and see which one works best for your case.

What is the catch when using MathOpt? It introduces a small amount of overhead
compared to calling a solver’s native API directly, and it currently supports
only linear constraints—that is, the ones you would add in CP-SAT using the
`add` method, excluding the `!=`, `<`, and `>` operators. MathOpt itself
supports continuous and unbounded variables as well as floating-point
coefficients, but these features are not available when you select CP-SAT as the
backend. If your model contains continuous variables, you will get an error,
since CP-SAT only supports integer variables and coefficients.

If you want to compare the performance of CP-SAT with a MIP solver, you still
need to discretize continuous variables and coefficients when your problem
requires it. Fortunately, many practical problems are purely integral, so you
might not even notice this limitation in practice.

> [!NOTE]
>
> Another modeling language aimed at the constraint programming community is
> [CPMpy](https://cpmpy.readthedocs.io/en/latest/index.html), which directly
> supports CP-SAT as a solver backend. In contrast, modeling tools commonly used
> in the mathematical optimization community—such as
> [Pyomo](https://pyomo.org/), [GAMS](https://www.gams.com/), and
> [AMPL](https://ampl.com/)—do not support CP-SAT.

In the following, I give a brief overview of the MathOpt API.

### Import and Model Creation

As in CP-SAT, you first need to import the MathOpt module and create a model
instance.

```python
from ortools.math_opt.python import mathopt as mo

model = mo.Model(name="optional_name")
```

### Variables

Next, you can start adding variables to the model. MathOpt supports continuous,
binary, and integer variables. By default, continuous and integer variables are
non-negative (i.e., they have a lower bound of 0). You can specify different
bounds using the `lb` and `ub` parameters.

```python
x = model.add_variable(lb=0.0, ub=10.0, name="x")  # Continuous variable in [0, 10]
# Unlike CP-SAT, you do not have to name variables
nameless_x = model.add_variable(lb=0.0, ub=10.0)  # Nameless variable
x_unbounded = model.add_variable(lb=-math.inf, ub=math.inf, name="x_unbounded")  # Unbounded continuous variable
```

To create binary or integer variables, use the corresponding methods:

```python
y = model.add_binary_variable(name="y")  # Binary variable in {0, 1}
z = model.add_integer_variable(lb=0, ub=100, name="z")  # Integer variable in [0, 100]
# Integer variable with no upper bound
z_unbounded = model.add_integer_variable(name="z_unbounded")
# or explicitly
z_unbounded = model.add_integer_variable(lb=0, ub=math.inf, name="z_unbounded")
```

> [!WARNING]
>
> The default lower bound is 0 for all variables, and the upper bound is
> infinity for continuous and integer variables. If you want a variable that can
> take negative values, you must explicitly set the lower bound to `-math.inf`
> or another negative number.

### Constraints

You can add linear constraints to the model using the `add_linear_constraint`
method. There are two ways to do this: the inequality/equality form and the
boxed form.

```python
# Inequality/equality form using Python operators
model.add_linear_constraint(2 * x + 3 * y <= 10, name="constraint1")
model.add_linear_constraint(x + y + z == 5, name="constraint2")
model.add_linear_constraint(z - 2 * x >= 0, name="constraint3")

# Boxed form
model.add_linear_constraint(lb=0, expr=2 * x + 3 * y, ub=10, name="constraint1_boxed")
model.add_linear_constraint(lb=5, expr=x + y + z, ub=5, name="constraint2_boxed")  # equality
model.add_linear_constraint(lb=0, expr=z - 2 * x, ub=math.inf, name="constraint3_boxed")  # inequality

# Constraints do not have to be named
model.add_linear_constraint(4 * x + y <= 20)
```

If you want to sum over a list of terms, you can use standard Python sums as in
CP-SAT. However, MathOpt provides a more efficient function, `mo.fast_sum`,
which is optimized for performance.

```python
terms = [i * x for i in range(1, 11)]  # Create a list of terms
model.add_linear_constraint(mo.fast_sum(terms) <= 100, name="sum_constraint")
```

You can also use expression handles, which can make the model more readable and
easier to maintain.

```python
in_vars = [mo.variable(name=f"in_{i}") for i in range(1, 6)]
out_vars = [mo.variable(name=f"out_{i}") for i in range(1, 6)]
incoming_flow = mo.fast_sum(in_vars)
outgoing_flow = mo.fast_sum(out_vars)
model.add_linear_constraint(incoming_flow == outgoing_flow, name="flow_conservation")
```

### Objective

You can define the model’s objective using the `set_objective` method and
specify whether you want to maximize or minimize it.

```python
model.set_objective(3 * x + 4 * y + 2 * z, is_maximize=True)  # Maximize
model.set_objective(x + 2 * z, is_maximize=False)  # Minimize
```

### Solving

To solve the model, use the `mo.solve` function, which takes the model, the
solver type, and optional solver parameters.

```python
params = mo.SolveParameters(
    time_limit=timedelta(seconds=30),  # Time limit of 30 seconds
    relative_gap_tolerance=0.01,  # 1% relative gap tolerance
    enable_output=True  # Enable solver output
)
result = mo.solve(model, solver_type=mo.SolverType.HIGHS, params=params)
```

MathOpt currently supports the following solvers: `GSCIP`, `GUROBI`, `GLOP`,
`CP_SAT`, `PDLP`, `GLPK`, `OSQP`, `ECOS`, `SCS`, `HIGHS`, and `SANTORINI`. If
you do not have a Gurobi license, I recommend using HiGHS or GSCIP, both of
which are open-source mixed-integer programming solvers.

### Inspecting Results

After solving the model, you can inspect the results through the `SolveResult`
object returned by `mo.solve`.

Check the termination reason:

```python
term = result.termination
print(f"Termination: {term.reason.name}")
if term.detail:
    print(f"Detail: {term.detail}")
```

Check whether a primal feasible solution was found:

```python
if result.has_primal_feasible_solution():
    print(f"Objective value: {result.objective_value()}")
    values = result.variable_values()
    print(f"x: {values.get(x)}, y: {values.get(y)}, z: {values.get(z)}")
else:
    print("No primal feasible solution found.")
```

The `variable_values()` method returns a mapping from variables to their values.
You can also pass a list of variables to get their values in the same order,
which can be convenient if you only need a subset.

```python
values = result.variable_values([x, y, z])
print(f"x: {values[0]}, y: {values[1]}, z: {values[2]}")
```

> [!NOTE]
>
> If you are solving an LP and the underlying solver supports dual values, you
> can also access the dual values of the constraints using the `dual_values()`
> method of the `SolveResult` object. Remember that in this case, you need to
> keep the handle to the constraints when you create them, e.g.,
> `constraint = model.add_linear_constraint(...)`. There are further features
> available, such as callbacks and lazy constraints, which we do not cover here.
> However, the
> [examples](https://github.com/google/or-tools/tree/stable/ortools/math_opt/samples/python)
> show some nice use cases.

### Examples

Let us look at two examples that demonstrate how to model and solve optimization
problems with MathOpt.

#### Simplified Stigler Diet Problem

The **Simplified Stigler Diet Problem** is a classical optimization problem in
which the goal is to select nonnegative servings of various foods to minimize
the total cost while satisfying minimum nutritional requirements for calories,
protein, and calcium. This model serves as a small, illustrative example of how
mathematical optimization can be applied to dietary planning. The units and
values used here are for demonstration purposes only and should not be
interpreted as nutritional facts.

```python
from ortools.math_opt.python import mathopt as mo
from datetime import timedelta
# --- Data -----------------------------------------------------------------
foods = ["Wheat Flour", "Milk", "Cabbage", "Beef"]

# Cost per serving (EUR)
cost = {
    "Wheat Flour": 0.36,
    "Milk": 0.23,
    "Cabbage": 0.10,
    "Beef": 1.20,
}

# Nutrients per serving (approximate / illustrative)
#               Calories  Protein(g)  Calcium(mg)
calories =     {"Wheat Flour": 364.0, "Milk": 150.0, "Cabbage": 25.0,  "Beef": 250.0}
protein =      {"Wheat Flour": 10.0,  "Milk": 8.0,   "Cabbage": 1.3,   "Beef": 26.0}
calcium =      {"Wheat Flour": 15.0,  "Milk": 285.0, "Cabbage": 40.0,  "Beef": 20.0}

# Minimum requirements
req = {
    "Calories": 2000.0,   # kcal
    "Protein": 55.0,      # g
    "Calcium": 800.0,     # mg
}

# --- Model ----------------------------------------------------------------
model = mo.Model(name="stigler_diet")

# Decision: servings of each food (continuous, ≥ 0)
# You could switch to integers to create a MIP variant.
servings = {f: model.add_variable(lb=0.0, name=f"servings[{f}]") for f in foods}

# Optional upper bounds to keep results tidy
for f in foods:
    model.add_linear_constraint(servings[f] <= 20.0, name=f"cap[{f}]")

# --- Nutrient constraints --------------------------------------------------
model.add_linear_constraint(
    mo.fast_sum(calories[f] * servings[f] for f in foods) >= req["Calories"],
    name="nutrients[Calories]",
)
model.add_linear_constraint(
    mo.fast_sum(protein[f] * servings[f] for f in foods) >= req["Protein"],
    name="nutrients[Protein]",
)
model.add_linear_constraint(
    mo.fast_sum(calcium[f] * servings[f] for f in foods) >= req["Calcium"],
    name="nutrients[Calcium]",
)

# --- Objective: minimize total cost ---------------------------------------
model.set_objective(
    mo.fast_sum(cost[f] * servings[f] for f in foods),
    is_maximize=False,
)

# --- Solve ----------------------------------------------------------------
params = mo.SolveParameters(
    time_limit=timedelta(seconds=10),
    relative_gap_tolerance=1e-6,  # LP, so we can be tight
    enable_output=False,
)

result = mo.solve(model, solver_type=mo.SolverType.HIGHS, params=params)

# --- Report ----------------------------------------------------------------
term = result.termination
print(f"Termination: {term.reason.name}")

if not result.has_primal_feasible_solution():
    print("No feasible solution found.")
    return

print(f"Minimum cost: €{result.objective_value():.2f}")

# Extract chosen servings (suppress near-zeros)
values = result.variable_values()
print("\nServings:")
for f in foods:
    qty = values.get(servings[f], 0.0)
    if abs(qty) > 1e-9:
        print(f"  {f:12s}: {qty:8.3f}")

# Compute realized totals
tot_cal = sum(calories[f] * values.get(servings[f], 0.0) for f in foods)
tot_pro = sum(protein[f]  * values.get(servings[f], 0.0) for f in foods)
tot_calcium = sum(calcium[f] * values.get(servings[f], 0.0) for f in foods)

print("\nNutrient totals (minimum required in parentheses):")
print(f"  Calories: {tot_cal:.1f}  ({req['Calories']})")
print(f"  Protein : {tot_pro:.1f}  ({req['Protein']})")
print(f"  Calcium : {tot_calcium:.1f}  ({req['Calcium']})")
```

#### Set Cover

The **Set Cover Problem** is a classic combinatorial optimization problem. Given
a universe $U$ of elements and a collection of subsets $S \subseteq 2^U$, each
with an associated integer cost, the goal is to select a minimum-cost collection
of subsets such that every element in $U$ is covered by at least one selected
subset.

This problem appears in resource allocation, scheduling, and network design. A
standard integer formulation is:

- **Variables:** For each subset $S$, a binary variable $z[S] \in \{0, 1\}$
  indicates whether subset $S$ is chosen.
- **Constraints:** For each element $u \in U$, the sum of $z[S]$ over all
  subsets $S$ containing $u$ must be at least 1.
- **Objective:** Minimize the total cost $\sum_{S} \text{cost}[S] \cdot z[S]$.

Since all variables are integral, this problem can be modeled using CP-SAT and
compared directly with MIP solvers such as Gurobi or HiGHS.

```python
from ortools.math_opt.python import mathopt as mo
from datetime import timedelta

U = {1, 2, 3, 4, 5, 6}
subsets = {
    "S1": {1, 2, 3},
    "S2": {2, 4},
    "S3": {3, 5, 6},
    "S4": {1, 4, 6},
    "S5": {2, 5},
    "S6": {4, 5, 6},
}
cost = {"S1": 4, "S2": 2, "S3": 3, "S4": 3, "S5": 2, "S6": 4}

model = mo.Model(name="set_cover_cp_sat")

# Decision variables
z = {s: model.add_binary_variable(name=f"pick[{s}]") for s in subsets}

# Cover constraints
for u in U:
    model.add_linear_constraint(
        mo.fast_sum(z[s] for s in subsets if u in subsets[s]) >= 1,
        name=f"cover[{u}]",
    )

# Objective
model.set_objective(
    mo.fast_sum(cost[s] * z[s] for s in subsets),
    is_maximize=False,
)

# Solve with CP-SAT
params = mo.SolveParameters(time_limit=timedelta(seconds=10), enable_output=True)
result = mo.solve(model, solver_type=mo.SolverType.CP_SAT, params=params)

print(f"[SetCover] Termination: {result.termination.reason.name}")
if not result.has_primal_feasible_solution():
    print("[SetCover] No feasible solution found.")
    return

vals = result.variable_values()
chosen = [s for s in subsets if int(round(vals.get(z[s], 0.0)))]
total_cost = sum(cost[s] for s in chosen)
print(f"[SetCover] Minimum total cost: {total_cost}")
print("[SetCover] Chosen subsets:", ", ".join(chosen))
```

