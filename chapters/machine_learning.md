## Класична оптимізація vs. машинне навчання (і вплив квантових обчислень)

<a name="chapters-machine-learning"></a>

Поширена дискусія в сучасному середовищі стосується того, чи можуть машинне
навчання (ML) або квантові обчислення (QC) замінити класичні методи оптимізації
на кшталт CP-SAT. У цьому розділі ми розглянемо фундаментальні відмінності між
машинним навчанням і оптимізацією, показавши, що ці напрями не є взаємозамінними,
а радше доповнюють один одного. Розуміння їхніх сильних сторін та застосувань
допомагає ефективніше використовувати кожен підхід для розв’язання складних
задач.

Після обговорення цих відмінностей постає типове запитання: чи зроблять квантові
обчислення класичні методи оптимізації застарілими? Щоб відповісти, ми розглянемо
базові виклики, з якими стикаються квантові обчислення в контексті оптимізації, і
пояснимо, чому їхній вплив може бути меншим, ніж часто очікують. Цей розділ також
розвінчує кілька міфів, які іноді поширюють прихильники квантових обчислень.

Машинне навчання чудово **передбачає** результати на основі історичних даних,
виявляє закономірності й робить обґрунтовані припущення, наприклад оцінює найкраще
розв’язання оптимізаційної задачі за даними з минулого. Воно добре навчається й
узагальнює навіть за наявності недосконалих даних, якщо їх достатньо. Натомість
оптимізація сильна у систематичному **пошуку** найкращого рішення на основі чітко
визначеної математичної моделі, точно оптимізуючи змінні та обмеження і часто
потребуючи мінімуму даних. Наприклад, у плануванні маршрутів доставки ML може
передбачити час у дорозі та потреби в ресурсах на основі історичних факторів, а
оптимізаційний розв’язувач на кшталт CP-SAT краще визначить найефективніші
маршрути, систематично враховуючи взаємозалежності та обмеження. Обидва напрями
покращують процес ухвалення рішень, коли використовуються разом, поєднуючи
прогностичні можливості ML зі строгими методами пошуку рішень в оптимізації.

У статті
[**Four Key Differences Between Mathematical Optimization And Machine Learning**](https://www.forbes.com/councils/forbestechcouncil/2021/06/25/four-key-differences-between-mathematical-optimization-and-machine-learning/)
Едвард Ротберг, CEO компанії Gurobi, виділяє чотири ключові відмінності між
машинним навчанням та оптимізацією:

- **Аналітичний фокус**: ML — переважно **прогностичний** інструмент, що виявляє
  закономірності в історичних даних для прогнозування майбутніх подій, тоді як
  оптимізація — **прескриптивний** інструмент, що використовує цифровий двійник
  вашого середовища для рекомендації найкращих рішень.
- **Типові застосування**: ML часто використовують у задачах на кшталт виявлення
  шахрайства, розпізнавання мовлення та рекомендацій продуктів — зазвичай
  орієнтованих на споживачів. Оптимізацію застосовують для операційних рішень у
  сферах планування виробництва, розкладів і маршрутів перевезень.
- **Адаптивність**: ML може страждати від «дрейфу моделі», якщо середовище
  суттєво змінюється, і потребує перенавчання на нових даних. Оптимізаційні
  моделі, навпаки, можна оновлювати більш безшовно в реальному часі, але вони
  зазвичай потребують більшого попереднього зусилля при побудові.
- **Зрілість**: обидва напрями мають корені, що сягають десятиліть, але
  оптимізація здебільшого вже перейшла до «плато продуктивності», тоді як ML
  зараз перебуває на «піку завищених очікувань» і може пройти через фазу
  розчарування, перш ніж стабілізуватися у ширшому застосуванні.

> [!TIP]
>
> Якщо вас не цікавлять мої аргументи, цю частину можна не читати. TL;DR:
> ні машинне навчання, ні квантові обчислення не зроблять CP-SAT (і подібні
> методи) застарілими в найближчий час, якщо взагалі коли-небудь. Водночас ML є
> цінним доповненням до оптимізації.

> :video:
>
> [ML ain't your only hammer: adding mathematical optimisation to the data scientist's toolbox](https://www.youtube.com/watch?v=G0tlyC9Sr3w):
> Це 20-хвилинна доповідь д-ра Джека Сімпсона, яка знайомить дата-саєнтистів із
> математичною оптимізацією, показуючи, як вона призначає оптимальні рішення за
> складних обмежень і доповнює ML-прогнози.

### Використання GenAI/LLM для оптимізації

<!-- Конкретний приклад використання ChatGPT для оптимізації -->

Справді, можна попросити ChatGPT (або подібні великі мовні моделі) розв’язати
деякі оптимізаційні задачі, і в простіших випадках (наприклад, у задачі про
рюкзак) він часто успішно автоматично пише Python-код, що викликає зовнішній
розв’язувач (наприклад, HiGHs). Хоча такий підхід може працювати для малих
екземплярів, загалом він значно повільніший за спеціалізований розв’язувач і
може містити приховані помилки. У наведеному нижче прикладі ChatGPT витратив
приблизно 10 секунд, тоді як спеціалізований розв’язувач розв’язав би той самий
екземпляр майже миттєво:

| ![ChatGPT Optimization](https://raw.githubusercontent.com/d-krupke/cpsat-primer/main/images/chatgpt-knapsack_1.png) | ![ChatGPT Optimization Analysis](https://raw.githubusercontent.com/d-krupke/cpsat-primer/main/images/chatgpt-knapsack_2.png) |
| :-----------------------------------------------------------------------------------------------------------------: | :--------------------------------------------------------------------------------------------------------------------------: |
|                      Просимо ChatGPT розв’язати задачу про рюкзак — і він успішно це робить...                       |                                 ...але «під капотом» він покладається на зовнішній розв’язувач.                             |

<!-- LLM можуть міркувати, але лише в коротких ходах -->

Більш просунуті версії ChatGPT (наприклад, ChatGPT 4) можуть впоратися з дещо
більшими задачами, але все одно поступаються розв’язувачам на кшталт CP-SAT,
які систематично оцінюють великі простори пошуку за допомогою ефективного
бекстрекінгу та обрізання. Великі мовні моделі обробляють інформацію послідовно
невеликими «ходами», мають обмежене контекстне вікно й не мають спеціалізованих
евристик — усе це робить їх схильними до логічних помилок і повільнішими зі
зростанням розміру задачі. Повторна генерація коду чи тексту створює накладні
витрати, а перевірка рішень може вимагати кількох ітерацій запитів, що ще більше
збільшує час.

<!-- LLM не є заміною розв’язувачів -->

Через ці обмеження LLM навряд чи найближчим часом замінять надійні розв’язувачі
для суттєвих або складних оптимізаційних задач. Утім, сучасні дослідження в
**гібридних AI-OR методах** мають на меті поєднати гнучкість LLM (швидке
прототипування та побудова моделей) із потужними пошуковими можливостями
спеціалізованих розв’язувачів. У міру розвитку цієї галузі LLM дедалі більше
допомагатимуть формулювати або уточнювати оптимізаційні моделі, тоді як
спеціалізовані рушії зосереджуватимуться на обчислювально інтенсивному пошуку.
Ми повернемося до цих можливостей у майбутньому розділі про «Побудову моделей за
допомогою GenAI/LLM».

<!-- Додаткове читання -->

Щоб глибше розібратися в обмеженнях LLM для оптимізації, зверніть увагу на такі
матеріали:

- [LLM-ify me - Optimization edition](https://oberdieck.dk/p/llm-in-optimization/):
  блог-пост про потенціал LLM в оптимізації.
- [Mind Evolution and the frontier of LLM-based optimization solvers](https://open.substack.com/pub/feasible/p/64-mind-evolution-and-the-frontier?r=49480z&utm_campaign=post&utm_medium=email):
  стаття з розсилки Feasible про потенціал LLM для оптимізації.
- [Why Solving Multi-agent Path Finding with Large Language Models has not Succeeded Yet](https://arxiv.org/pdf/2401.03630)
- [Look Further Ahead: Testing the Limits of GPT-4 in Path Planning](https://arxiv.org/pdf/2406.12000)
- [Extracting Problem Structure with LLMs for Optimized SAT Local Search](https://arxiv.org/pdf/2501.14630):
  ця стаття демонструє, як LLM можна використовувати для автоматичного створення
  **стартових евристик** із Python-коду, що моделює задачу як SAT-екземпляр із
  використанням бібліотеки PySAT. Такі евристики забезпечують **початкову фазу**
  для SAT-розв’язувача, допомагаючи починати пошук із більш перспективного
  присвоєння та розв’язувати додаткові екземпляри, які інакше залишилися б
  нерозв’язаними.

### Підкріплювальне навчання

У деяких випадках реальною альтернативою оптимізаційним розв’язувачам на кшталт
CP-SAT є підкріплювальне навчання. Воно може бути дуже ефективним для оптимізації
надзвичайно складних задач, які надто важко змоделювати простими математичними
формулюваннями. Під час своєї дисертації я застосовував підкріплювальне навчання
для оптимізації мультиагентної системи, де створення повної математичної моделі
було неможливим через надмірну кількість змінних та обмежень, потрібних для
опису динаміки системи. Додатково, вручну розроблені евристики не могли
конкурувати з продуктивністю простого агента підкріплювального навчання, якого я
реалізував із мінімальними зусиллями за допомогою
[Stable Baselines](https://stable-baselines.readthedocs.io/en/master/). Втім,
попри здатність агентів підкріплювального навчання виконувати значно більше
ітерацій для вивчення простору рішень порівняно з великими мовними моделями
(LLM), їм усе одно бракує структурованих та ефективних пошукових можливостей,
властивих класичним розв’язувачам. До того ж проєктування адекватної функції
винагороди для підкріплювального навчання може бути складним і часто потребує
значних спроб і помилок.

#### Поєднання машинного навчання та оптимізації

Замість спроб замінити оптимізаційні розв’язувачі на кшталт CP-SAT машинним
навчанням, більш перспективним підходом є поєднання цих двох напрямів. Це можна
зробити кількома способами, наприклад, використовуючи ML для прогнозування
параметрів оптимізаційних задач, будуючи оптимізаційні проксі, або інтегруючи ML
усередині розв’язувачів для спрямування внутрішніх рішень. Такі методи
використовують силу обох напрямів для покращення ухвалення рішень і підвищення
якості розв’язків.

##### Варіанти Predict-Then-Optimize

<!-- Базовий варіант -->

Predict-Then-Optimize — це фреймворк, що поєднує машинне навчання з оптимізацією.
Базова версія складається з двох простих кроків: спершу прогноз, потім
оптимізація. Спочатку стандартна ML-модель (наприклад, регресія) навчається
оцінювати невідомі параметри оптимізаційної задачі, такі як витрати або попит,
використовуючи звичайні функції втрат на кшталт середньоквадратичної помилки.
Далі ці прогнозовані параметри передаються до оптимізаційного розв’язувача (наприклад,
CP-SAT), який продукує найкраще можливе рішення — скажімо, розклад, маршрут чи
розподіл ресурсів — на основі оцінених вхідних даних. Цей підхід ефективний,
коли точність прогнозів досить висока, але може давати збої, якщо невеликі
помилки в прогнозах призводять до значних наслідків у рішенні.

<!-- Покращені варіанти -->

Щоб підвищити якість рішень, більш просунуті, «орієнтовані на рішення» варіанти
Predict-Then-Optimize безпосередньо включають ціль розв’язувача в процес
навчання ML. Замість мінімізації стандартної прогнозної помилки ці методи
намагаються мінімізувати «регрет» — розрив між вартістю рішення, отриманого
розв’язувачем на прогнозних параметрах, та вартістю справжнього оптимального
рішення. Неодноразово використовуючи розв’язувач (або його наближення) під час
навчання, вони обчислюють, як помилки прогнозу перетворюються на субоптимальні
рішення, і повертають цю інформацію в параметри ML-моделі. У результаті модель
вчиться прогнозувати так, щоб зберігати або покращувати якість фінального
рішення, навіть якщо сирі прогнози для кожного параметра не є ідеально точними.

<!-- Посилання -->

Перегляньте
[цю чудову лекцію Еліаса Халіла](https://www.youtube.com/watch?v=pZqm-i57gxk),
яка була частиною літньої школи.

> [!TIP]
>
> Невизначеність і невідомі параметри часто виникають в оптимізаційних задачах.
> Хоча фреймворк **predict-then-optimize** пропонує простий підхід, його
> більш просунуті варіанти можуть допомогти усунути деякі обмеження. Для ще
> більшої стійкості техніки на кшталт **robust optimization**,
> **stochastic programming** та інші дають ефективніші рішення, особливо в умовах
> високої невизначеності, хоч і ціною додаткової складності. Численні дослідження
> вивчають ці та інші методи, а оптимальний вибір значною мірою залежить від
> конкретного застосування.

##### Оптимізаційні проксі

<!-- Основна ідея оптимізаційних проксі -->

Оптимізаційний проксі — це модель машинного навчання, навчена апроксимувати
вхід-вихідну поведінку оптимізаційного розв’язувача, що дозволяє майже миттєві
рішення після розгортання. Зазвичай збирають велику кількість екземплярів задач,
розв’язують їх офлайн традиційним розв’язувачем, щоб отримати «еталонні» рішення,
а потім навчають ML-модель відображати входи (наприклад, попит, витрати) у виходи
(рішення розв’язувача). У режимі реального часу або в масштабних симуляціях —
наприклад, у енергосистемах, плануванні чи маршрутизації — використання такого
проксі обходить звичні тривалі часи розв’язання, забезпечуючи рішення (або
майже рішення) майже миттєво. Оскільки навчальні дані безпосередньо походять від
розв’язувача, ручне маркування не потрібне; можна офлайн згенерувати будь-яку
кількість екземплярів.

<!-- Плюси та мінуси -->

Втім, оптимізаційні проксі найкраще працюють тоді, коли доводиться багато разів
розв’язувати відносно схожі моделі за стабільних умов, і можуть погано
справлятися, коли виникають складні обмеження на допустимість або суттєво
змінюються параметри задачі. Хоча вони знайшли корисні застосування в областях
на кшталт енергомереж, багато інших оптимізаційних контекстів містять надто
багато змінних або складних обмежень, щоб простий проксі був надійним.
Суттєві зміни у структурі задачі часто потребують перенавчання або значної
адаптації моделі. В результаті, хоч проксі й можуть бути потужним доповненням
для прискорення певних класів екземплярів, вони аж ніяк не є універсальною
заміною класичних розв’язувачів.

<!-- Додаткове читання -->

[Коротке 4-хвилинне пояснення](https://www.youtube.com/watch?v=UAwEZi56cb8)
дає Паскаль Ван Хентенрик. Довший варіант можна знайти
[тут](https://www.youtube.com/watch?v=NlwxEGtw4QY).

##### Побудова моделей за допомогою GenAI/LLM

Дедалі ціннішим застосуванням LLM (або генеративного AI) в оптимізації є
допомога в процесі побудови моделей. Замість спроби безпосередньо розв’язувати
оптимізаційну задачу, що часто неефективно, ці моделі можуть допомогти налаштувати
початкову модель, з якою працюватиме спеціалізований розв’язувач. Багато
оптимізаційних моделей мають схожі структури і відрізняються лише в деталях, що
робить LLM корисними для створення базових компонентів. Інструменти на кшталт
GitHub Co-Pilot уже можуть генерувати складні частини моделі, але вони також
можуть вводити приховані помилки, які важко помітити, наприклад помилки «на один»
(off-by-one), інвертовані обмеження або переплутані індекси. Тому LLM варто
використовувати як джерело натхнення та ретельно перевіряти їхній результат;
інакше час, зекономлений на кодуванні, може бути витрачений на налагодження.

Крім того, оптимізаційна модель часто є каркасом реальної задачі, тому критично
важливо розуміти, як вона узгоджується з операційним чи бізнес-контекстом. Хоч
LLM можуть пришвидшити написання коду, вони не замінюють людську експертизу,
необхідну для наближення та спрощення складної реальності. Якщо сценарій
критично важливий, не варто надмірно покладатися на підхід на основі AI на цьому
етапі. Утім, кілька дослідницьких проєктів і комерційних продуктів уже
досліджують цю ідею:

1. [Дослідницький проєкт у Стенфорді](https://web.stanford.edu/~udell/project-modeling.html)
2. [Gurobi AI Modeling](https://gurobi-ai-modeling.readthedocs.io/en/latest/index.html)
   ([Короткий огляд](https://www.youtube.com/watch?v=8hr_23zdRV4))
3. [Quantagonia](https://www.quantagonia.com/decisionai) пропонує розв’язувач,
   з яким можна взаємодіяти через чат
4. [Robust and Adaptive Optimization under a Large Language Model Lens](https://arxiv.org/pdf/2501.00568):
   дослідницька робота про використання LLM у робастній оптимізації.
5. [DualSchool: How Reliable are LLMs for Optimization Education?](https://arxiv.org/pdf/2505.21775):
   ця стаття показує, що LLM усе ще погано справляються з простими «рецептурними»
   задачами, такими як дуалізація лінійних програм.

##### Навчатися замість вгадувати

Машинне навчання також можна інтегрувати _всередину_ розв’язувачів, спрямовуючи
внутрішні рішення, наприклад стратегії розгалуження, відбір відсікальних площин
або масштабування матриць. Замість того щоб покладатися лише на вручну
налаштовані правила, розв’язувач збирає дані з різноманітних екземплярів задач і
вчиться, які алгоритмічні вибори найкраще скорочують час виконання або
покращують чисельну стабільність. Наприклад, модель може передбачити, чи будуть
«локальні» або «глобальні» відсікальні площини ефективнішими для конкретного
екземпляра, або чи певні методи масштабування допоможуть уникнути погано
обумовлених базисів. Розглядаючи ці рішення як задачі регресії — оцінюючи
прискорення або покращення стабільності — машинне навчання дозволяє розв’язувачу
адаптуватися і самоналаштовуватися, зрештою працюючи краще на широкому спектрі
задач без втрати універсальності.

Ця
[лекція Тімо Бертольда (FICO)](https://www.youtube.com/watch?v=xYKNH3Pqq9A)
дає хороший огляд теми. Вона була частиною літньої школи CO@Work 2024, яку я
відвідував і яку вважаю неймовірною; якщо матимете можливість долучитися, дуже
рекомендую (за умови, що ви вже на рівні PhD, адже вона інтенсивна).

Тригодинний туторіал від різних експертів на цю тему (зокрема Еліаса Халіла та
Андреа Лоді) можна знайти
[тут](https://www.youtube.com/watch?v=XVLd7hf6y6M&list=LL&index=20). Дуже
рекомендую переглянути, якщо вас цікавить тема — у мене було багато «ага»-моментів
під час цього туторіалу.

> :reference:
>
> - [Machine learning augmented branch and bound for mixed integer linear programming](https://link.springer.com/article/10.1007/s10107-024-02130-y):
>   Це нещодавня стаття 2024 року, що оглядає ідеї використання машинного
>   навчання для покращення branch-and-bound розв’язувачів для змішаного
>   цілочисельного лінійного програмування.

### Чому квантові обчислення (ймовірно) не матимуть великого впливу на оптимізацію

Перш ніж завершити цей розділ, обговорімо також вплив квантових обчислень на
оптимізацію, адже це питання мені часто ставлять одразу після пояснення, чому
ChatGPT не може замінити CP-SAT.

<!-- Небезпечні твердження -->

Часто можна почути твердження, що квантові обчислення революціонізують
оптимізацію, особливо щодо задачі комівояжера (TSP). Такі твердження нерідко
заявляють, що новий квантовий алгоритм може розв’язати TSP (складну, але
практично важливу комбінаторну оптимізаційну задачу) для малих розмірів
екземплярів, тоді як класичному комп’ютеру нібито знадобляться мільярди років
щоб впоратися лише з 20 вершинами. (Насправді деякі опубліковані роботи досі
розглядають лише чотири вершини.) На жаль, такі твердження зазвичай спираються
на теоретичну оцінку найгіршого часу виконання близько $O(n^2 2^n)$ для TSP, яка
не відображає того, як проблема вирішується на практиці.

> :reference:
>
> Щоб отримати доступне та змістовне обговорення міфів і перебільшених очікувань
> щодо квантових обчислень, зверніть увагу на доступну у відкритому доступі книгу
> [_What You Shouldn't Know About Quantum Computers_](https://arxiv.org/abs/2405.15838)
> Кріса Феррі. Цей ресурс дає чудову можливість критично розглянути поширені
> хибні уявлення, які часто підтримуються науковою фантастикою та популярною
> науковою літературою.

<!-- Найгірший випадок vs. реальний світ -->

Хоча найвідоміший квантовий алгоритм працює за $O(1.728^n)$, що дещо краще за
$O(n^2 2^n)$, це все одно експонента, яка дуже швидко зростає. Оскільки TSP є
NP-складною, малоймовірно, що ми колись знайдемо (квантовий чи класичний)
алгоритм, чий найгірший час виконання не вибухає зі зростанням розміру
екземпляра. Ба більше, продуктивність у реальному світі або в середньому може
кардинально відрізнятися від найгіршої. Насправді TSP вже ефективно розв’язується
для великих екземплярів на класичних комп’ютерах, тож багато гучних заяв про
нібито переваги квантових обчислень в оптимізації можуть бути оманливими або
просто помилковими.

<!-- TL;DR -->

Станом на сьогодні немає переконливих доказів того, що квантові обчислення
матимуть значний вплив на оптимізацію. Багато експертів вважають, що в найкращому
разі квантові обчислення можуть дати лише помірну перевагу в цій сфері, хоча
вони можуть мати суттєві наслідки для криптології.

> [!TIP]
>
> На нещодавній зустрічі консорціуму консультант із логістичної оптимізації
> зробив доволі промовисте зауваження. За його словами, навіть за наявності
> повністю працездатного квантового комп’ютера з тисячами бездоганних кубітів
> його головна користь полягала б у маркетингу. Поза цим, для прикладних потреб
> клієнтів він був би лише «металевим сміттям». Це висловлювання викликало
> жартівливі заперечення квантових експертів щодо фрази «металеве сміття».
> Попри це, загальне відчуття, що квантові обчислення переоцінені в оптимізації,
> було широко підтримане.

<!-- Квантові комп’ютери нині гірші за ручні розрахунки -->

Щоб краще зрозуміти складність задачі комівояжера в історичній перспективі:
у середині XX століття TSP привернула увагу через конкурси з великими грошовими
призами за розв’язання відносно невеликих екземплярів із 33–49 міст — уже значно
більших за ті, які нині беруться розв’язувати багато квантових дослідників. Як
повідомляв Newsweek у **1954** році:

> "By an ingenious application of linear programming - a mathematical tool
> recently used to solve production-scheduling problems - it took only a few
> weeks for the California experts to calculate by hand the shortest route to
> cover the 49 cities."

Дивовижно, але вони не лише знайшли найкоротший маршрут, а й довели, що він
є найкоротшим, і все це вручну у 1950-х. Більше деталей можна знайти в
[цьому блозі](https://www.math.uwaterloo.ca/tsp/us/history.html). Нині існує навіть
[додаток для iPhone](https://apps.apple.com/us/app/concorde-tsp/id498366515), який
може знаходити оптимальні рішення для екземплярів із приблизно 1 000 міст за
лічені секунди.
[Більш масштабні екземпляри](https://www.math.uwaterloo.ca/tsp/optimal/index.html)
(до 85 900 вершин, розв’язані у 2006 році) та майже оптимальні рішення для
мільйонів міст ілюструють, як далеко зайшли класичні методи. У цьому сенсі
квантовим комп’ютерам ще далеко до того, щоб перевершити навіть людину з папером
і ручкою, не кажучи вже про класичний комп’ютер.

<!-- Анекдот про хибну оцінку складності та фінансові втрати -->

Невірна оцінка складності деяких комбінаторних задач свого часу призвела одного
винахідника головоломок до несподіваних фінансових проблем. Його творіння,
[_The Eternity Puzzle_](https://en.wikipedia.org/wiki/Eternity_puzzle),
пропонувало приз £1,000,000 тому, хто зможе його розв’язати — суму, яку деякі
ранні оцінки вважали недосяжною протягом людського життя через колосальну
кількість можливих конфігурацій. Однак замість перебору всіх можливостей двоє
математиків із Кембриджа застосували просунуті техніки, щоб суттєво звузити
простір пошуку. Аналогічно CP-SAT використовує різноманітні приховані стратегії,
щоб ефективніше розв’язувати складні задачі, ніж більшість могла б уявити; у
цьому сенсі багато методів, використаних для розв’язання The Eternity Puzzle,
нагадують те, що CP-SAT робить у більш загальному вигляді.
